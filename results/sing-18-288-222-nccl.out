/usr/local/lib/python3.10/dist-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2024-10-02 15:31:41,800] torch.distributed.run: [WARNING] 
[2024-10-02 15:31:41,800] torch.distributed.run: [WARNING] *****************************************
[2024-10-02 15:31:41,800] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-10-02 15:31:41,800] torch.distributed.run: [WARNING] *****************************************
using world size: 8, data-parallel size: 2, context-parallel size: 1, tensor-model-parallel size: 2, encoder-tensor-model-parallel size: 0, pipeline-model-parallel size: 2, encoder-pipeline-model-parallel size: 0
WARNING: Please specify --split when using --data-path. Using legacy default value of "969, 30, 1"
WARNING: Setting args.overlap_p2p_comm to False since non-interleaved schedule does not support overlapping p2p communication
using torch.float32 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. False
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  add_qkv_bias .................................... False
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  align_grad_reduce ............................... True
  align_param_gather .............................. False
  app_tag_run_name ................................ None
  app_tag_run_version ............................. 0.0.0
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... False
  apply_residual_connection_post_layernorm ........ False
  apply_rope_fusion ............................... True
  async_save ...................................... None
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  auto_detect_ckpt_format ......................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ False
  bias_dropout_fusion ............................. True
  bias_gelu_fusion ................................ True
  bias_swiglu_fusion .............................. True
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  calculate_per_token_loss ........................ False
  check_for_nan_in_loss_and_grad .................. True
  check_weight_hash_across_dp_replicas_interval ... None
  ckpt_assume_constant_structure .................. False
  ckpt_convert_format ............................. None
  ckpt_convert_save ............................... None
  ckpt_convert_update_legacy_dist_opt_format ...... False
  ckpt_format ..................................... torch_dist
  ckpt_fully_parallel_load ........................ False
  ckpt_fully_parallel_save ........................ True
  ckpt_fully_parallel_save_deprecated ............. False
  ckpt_step ....................................... None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  clone_scatter_output_in_embedding ............... True
  config_logger_dir ............................... 
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  context_parallel_size ........................... 1
  create_attention_mask_in_dataloader ............. True
  cross_entropy_loss_fusion ....................... False
  data_cache_path ................................. None
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 2
  data_path ....................................... ['codeparrot_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  ddp_average_in_collective ....................... False
  ddp_bucket_size ................................. None
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  decoupled_lr .................................... None
  decoupled_min_lr ................................ None
  decrease_batch_size_if_needed ................... False
  defer_embedding_wgrad_compute ................... False
  deprecated_use_mcore_models ..................... False
  deterministic_mode .............................. False
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  disable_straggler_on_startup .................... False
  dist_ckpt_format_deprecated ..................... None
  dist_ckpt_strictness ............................ assume_ok_unexpected
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  empty_unused_memory_level ....................... 0
  enable_ft_package ............................... False
  enable_one_logger ............................... True
  encoder_num_layers .............................. 12
  encoder_pipeline_model_parallel_size ............ 0
  encoder_seq_length .............................. 1024
  encoder_tensor_model_parallel_size .............. 0
  end_weight_decay ................................ 0.1
  eod_mask_loss ................................... False
  eval_interval ................................... 200
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  expert_model_parallel_size ...................... 1
  ffn_hidden_size ................................. 3072
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8 ............................................. None
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 288
  gradient_accumulation_fusion .................... True
  group_query_attention ........................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 768
  hybrid_attention_ratio .......................... 0.0
  hybrid_mlp_ratio ................................ 0.0
  hybrid_override_pattern ......................... None
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  kv_channels ..................................... 64
  lazy_mpu_init ................................... None
  load ............................................ /workspace/Megatron-LM/experiments/codeparrot-small
  local_rank ...................................... 0
  log_interval .................................... 1
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_progress .................................... False
  log_straggler ................................... False
  log_throughput .................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  logging_level ................................... None
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.0005
  lr_decay_iters .................................. 150000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. None
  lr_warmup_init .................................. 0.0
  lr_warmup_iters ................................. 2000
  lr_warmup_samples ............................... 0
  lr_wsd_decay_iters .............................. None
  lr_wsd_decay_samples ............................ None
  lr_wsd_decay_style .............................. exponential
  make_vocab_size_divisible_by .................... 128
  manual_gc ....................................... False
  manual_gc_eval .................................. True
  manual_gc_interval .............................. 0
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... True
  max_position_embeddings ......................... 1024
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... gpt2-merges.txt
  micro_batch_size ................................ 18
  min_loss_scale .................................. 1.0
  min_lr .......................................... 0.0
  mmap_bin_files .................................. True
  mock_data ....................................... False
  moe_aux_loss_coeff .............................. 0.0
  moe_expert_capacity_factor ...................... None
  moe_extended_tp ................................. False
  moe_grouped_gemm ................................ False
  moe_input_jitter_eps ............................ None
  moe_layer_recompute ............................. False
  moe_pad_expert_input_to_capacity ................ False
  moe_per_layer_logging ........................... False
  moe_router_load_balancing_type .................. aux_loss
  moe_router_pre_softmax .......................... False
  moe_router_topk ................................. 2
  moe_token_dispatcher_type ....................... allgather
  moe_token_drop_policy ........................... probs
  moe_z_loss_coeff ................................ None
  nccl_communicator_config_path ................... None
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  non_persistent_ckpt_type ........................ None
  non_persistent_global_ckpt_dir .................. None
  non_persistent_save_interval .................... None
  norm_epsilon .................................... 1e-05
  normalization ................................... LayerNorm
  num_attention_heads ............................. 12
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_dataset_builder_threads ..................... 1
  num_experts ..................................... None
  num_layers ...................................... 12
  num_layers_per_virtual_pipeline_stage ........... None
  num_query_groups ................................ 1
  num_workers ..................................... 2
  one_logger_async ................................ False
  one_logger_project .............................. megatron-lm
  one_logger_run_name ............................. None
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_grad_reduce ............................. False
  overlap_p2p_comm ................................ False
  overlap_param_gather ............................ False
  overlap_param_gather_with_optimizer_step ........ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.float32
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 2
  pipeline_model_parallel_split_rank .............. None
  position_embedding_type ......................... learned_absolute
  pretrained_checkpoint ........................... None
  profile ......................................... False
  profile_ranks ................................... [0]
  profile_step_end ................................ 12
  profile_step_start .............................. 10
  qk_layernorm .................................... False
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ None
  renormalize_blend_weights ....................... False
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_attention_gate ............................ 1
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_project_dir ............................... None
  retro_verify_neighbor_count ..................... True
  rotary_base ..................................... 10000
  rotary_interleaved .............................. False
  rotary_percent .................................. 1.0
  rotary_seq_len_interpolation_factor ............. None
  s3_cache_path ................................... None
  sample_rate ..................................... 1.0
  save ............................................ /workspace/Megatron-LM/experiments/codeparrot-small
  save_interval ................................... 2000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 1024
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  skip_train ...................................... False
  skipped_train_samples ........................... 0
  spec ............................................ None
  split ........................................... 969, 30, 1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.1
  straggler_ctrlr_port ............................ 65535
  straggler_minmax_count .......................... 1
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 2
  tensorboard_dir ................................. experiments/tensorboard
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  test_mode ....................................... False
  tiktoken_num_special_tokens ..................... 1000
  tiktoken_pattern ................................ None
  tiktoken_special_tokens ......................... None
  timing_log_level ................................ 0
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  tp_comm_bulk_dgrad .............................. True
  tp_comm_bulk_wgrad .............................. True
  tp_comm_overlap ................................. False
  tp_comm_overlap_ag .............................. True
  tp_comm_overlap_cfg ............................. None
  tp_comm_overlap_rs .............................. True
  tp_comm_overlap_rs_dgrad ........................ False
  tp_comm_split_ag ................................ True
  tp_comm_split_rs ................................ True
  train_data_path ................................. None
  train_iters ..................................... 200
  train_samples ................................... None
  train_sync_interval ............................. None
  transformer_impl ................................ transformer_engine
  transformer_pipeline_model_parallel_size ........ 2
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_cpu_initialization .......................... None
  use_dist_ckpt ................................... True
  use_dist_ckpt_deprecated ........................ False
  use_distributed_optimizer ....................... False
  use_flash_attn .................................. False
  use_legacy_models ............................... False
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  use_tp_pp_dp_mapping ............................ False
  valid_data_path ................................. None
  variable_seq_lengths ............................ False
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... gpt2-vocab.json
  vocab_size ...................................... None
  wandb_exp_name .................................. 
  wandb_project ................................... 
  wandb_save_dir .................................. 
  weight_decay .................................... 0.1
  weight_decay_incr_style ......................... constant
  wgrad_deferral_limit ............................ 0
  world_size ...................................... 8
  yaml_cfg ........................................ None
-------------------- end of arguments ---------------------
INFO:megatron.core.num_microbatches_calculator:setting number of microbatches to constant 8
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 175 dummy tokens (new size: 50432)
> initializing torch distributed ...
> setting tensorboard ...
WARNING: one_logger package is required to enable e2e metrics tracking. please go to https://confluence.nvidia.com/display/MLWFO/Package+Repositories for details to install it
> initialized tensor model parallel with size 2
> initialized pipeline model parallel with size 2
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/workspace/Megatron-LM/megatron/core/datasets'
make: Nothing to be done for 'default'.
make: Leaving directory '/workspace/Megatron-LM/megatron/core/datasets'
>>> done with dataset index builder. Compilation time: 0.030 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
>>> done with compiling and loading fused kernels. Compilation time: 0.604 seconds
Parameters: type(args): <class 'argparse.Namespace'>
num_layers: 12
encoder_num_layers: 12
decoder_num_layers: None
hidden_size: 768
ffn_hidden_size: 3072
num_attention_heads: 12
kv_channels: 64
group_query_attention: False
num_query_groups: 1
max_position_embeddings: 1024
position_embedding_type: learned_absolute
use_rotary_position_embeddings: False
rotary_base: 10000
rotary_percent: 1.0
rotary_interleaved: False
rotary_seq_len_interpolation_factor: None
add_position_embedding: True
make_vocab_size_divisible_by: 128
normalization: LayerNorm
norm_epsilon: 1e-05
apply_layernorm_1p: False
apply_residual_connection_post_layernorm: False
openai_gelu: False
squared_relu: False
swiglu: False
onnx_safe: None
bert_binary_head: True
untie_embeddings_and_output_weights: False
attention_dropout: 0.1
hidden_dropout: 0.1
weight_decay: 0.1
start_weight_decay: 0.1
end_weight_decay: 0.1
weight_decay_incr_style: constant
clip_grad: 1.0
adam_beta1: 0.9
adam_beta2: 0.999
adam_eps: 1e-08
sgd_momentum: 0.9
[rank4]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
micro_batch_size: 18[rank1]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank6]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank3]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())

[rank2]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank7]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
global_batch_size: 288[rank5]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())

rampup_batch_size: None
decrease_batch_size_if_needed: False
recompute_granularity: None
check_for_nan_in_loss_and_grad: True
distribute_saved_activations: False
recompute_method: None
recompute_num_layers: None
clone_scatter_output_in_embedding: True
profile: False
profile_step_start: 10
profile_step_end: 12
profile_ranks: [0]
tp_comm_overlap: False
tp_comm_overlap_cfg: None
tp_comm_overlap_ag: True
tp_comm_overlap_rs: True
tp_comm_overlap_rs_dgrad: False
tp_comm_bulk_dgrad: True
tp_comm_bulk_wgrad: True
use_cpu_initialization: None
empty_unused_memory_level: 0
deterministic_mode: False
check_weight_hash_across_dp_replicas_interval: None
calculate_per_token_loss: False
train_sync_interval: None
train_iters: 200
train_samples: None
log_interval: 1
exit_interval: None
exit_duration_in_mins: None
exit_signal_handler: False
tensorboard_dir: experiments/tensorboard
masked_softmax_fusion: True
bias_gelu_fusion: True
bias_swiglu_fusion: True
bias_dropout_fusion: True
apply_rope_fusion: True
cross_entropy_loss_fusion: False
use_flash_attn: False
add_bias_linear: True
add_qkv_bias: False
optimizer: adam
dataloader_type: single
async_tensor_model_parallel_allreduce: False
no_persist_layer_norm: False
sequence_parallel: False
gradient_accumulation_fusion: True
deprecated_use_mcore_models: False
use_legacy_models: False
manual_gc: False
manual_gc_interval: 0
manual_gc_eval: True
tp_comm_split_ag: True
tp_comm_split_rs: True
seed: 1234
data_parallel_random_init: False
init_method_std: 0.02
init_method_xavier_uniform: False
lr: 0.0005
lr_decay_style: cosine
lr_wsd_decay_style: exponential
lr_decay_iters: 150000
lr_decay_samples: None
lr_wsd_decay_samples: None
lr_wsd_decay_iters: None
lr_warmup_fraction: None
lr_warmup_iters: 2000
lr_warmup_samples: 0
lr_warmup_init: 0.0
min_lr: 0.0
override_opt_param_scheduler: False
use_checkpoint_opt_param_scheduler: False
decoupled_lr: None
decoupled_min_lr: None
save: /workspace/Megatron-LM/experiments/codeparrot-small
save_interval: 2000
no_save_optim: None
no_save_rng: None
load: /workspace/Megatron-LM/experiments/codeparrot-small
no_load_optim: None
no_load_rng: None
non_persistent_save_interval: None
non_persistent_ckpt_type: None
non_persistent_global_ckpt_dir: None
finetune: False
pretrained_checkpoint: None
ckpt_step: None
perform_initialization: True
use_checkpoint_args: False
exit_on_missing_checkpoint: False
use_dist_ckpt_deprecated: False
auto_detect_ckpt_format: False
dist_ckpt_format_deprecated: None
ckpt_format: torch_dist
ckpt_convert_format: None
ckpt_convert_save: None
ckpt_convert_update_legacy_dist_opt_format: False
ckpt_fully_parallel_save_deprecated: False
ckpt_fully_parallel_save: True
async_save: None
ckpt_fully_parallel_load: False
ckpt_assume_constant_structure: False
dist_ckpt_strictness: assume_ok_unexpected
fp16: False
bf16: False
loss_scale: None
initial_loss_scale: 4294967296
min_loss_scale: 1.0
loss_scale_window: 1000
hysteresis: 2
fp32_residual_connection: False
apply_query_key_layer_scaling: False
attention_softmax_in_fp32: False
accumulate_allreduce_grads_in_fp32: False
fp16_lm_cross_entropy: False
tensor_model_parallel_size: 2
encoder_tensor_model_parallel_size: 0
pipeline_model_parallel_size: 2
encoder_pipeline_model_parallel_size: 0
pipeline_model_parallel_split_rank: None
num_layers_per_virtual_pipeline_stage: None
overlap_p2p_comm: False
distributed_backend: nccl
distributed_timeout_minutes: 10
overlap_grad_reduce: False
defer_embedding_wgrad_compute: False
wgrad_deferral_limit: 0
align_grad_reduce: True
ddp_bucket_size: None
ddp_average_in_collective: False
overlap_param_gather: False
overlap_param_gather_with_optimizer_step: False
align_param_gather: False
scatter_gather_tensors_in_pipeline: True
use_ring_exchange_p2p: False
local_rank: 0
lazy_mpu_init: None
standalone_embedding_stage: False
use_distributed_optimizer: False
context_parallel_size: 1
nccl_communicator_config_path: None
use_tp_pp_dp_mapping: False
eval_iters: 10
eval_interval: 200
test_mode: False
skip_train: False
data_path: ['codeparrot_content_document']
renormalize_blend_weights: False
split: 969, 30, 1
train_data_path: None
valid_data_path: None
test_data_path: None
data_cache_path: None
mmap_bin_files: True
mock_data: False
vocab_size: None
vocab_file: gpt2-vocab.json
merge_file: gpt2-merges.txt
vocab_extra_ids: 0
seq_length: 1024
encoder_seq_length: 1024
decoder_seq_length: None
retriever_seq_length: 256
sample_rate: 1.0
mask_prob: 0.15
short_seq_prob: 0.1
num_workers: 2
tokenizer_type: GPT2BPETokenizer
tokenizer_model: None
tiktoken_pattern: None
tiktoken_num_special_tokens: 1000
tiktoken_special_tokens: None
reset_position_ids: False
reset_attention_mask: False
eod_mask_loss: False
create_attention_mask_in_dataloader: True
num_dataset_builder_threads: 1
s3_cache_path: None
adlr_autoresume: False
adlr_autoresume_interval: 1000
ict_head_size: None
biencoder_projection_dim: 0
biencoder_shared_query_context_model: False
ict_load: None
bert_load: None
titles_data_path: None
query_in_block_prob: 0.1
use_one_sent_docs: False
evidence_data_path: None
retriever_report_topk_accuracies: []
retriever_score_scaling: False
block_data_path: None
embedding_path: None
indexer_batch_size: 128
indexer_log_interval: 1000
num_classes: 1000
img_h: 224
img_w: 224
num_channels: 3
patch_dim: 16
classes_fraction: 1.0
data_per_class_fraction: 1.0
data_sharding: True
head_lr_mult: 1.0
vision_pretraining: False
vision_pretraining_type: classify
vision_backbone_type: vit
swin_backbone_type: tiny
mask_type: random
mask_factor: 1.0
iter_per_epoch: 1250
dino_local_img_size: 96
dino_local_crops_number: 10
dino_head_hidden_size: 2048
dino_bottleneck_size: 256
dino_freeze_last_layer: 1
dino_norm_last_layer: False
dino_warmup_teacher_temp: 0.04
dino_teacher_temp: 0.07
dino_warmup_teacher_temp_epochs: 30
qk_layernorm: False
expert_model_parallel_size: 1
num_experts: None
moe_router_load_balancing_type: aux_loss
moe_router_topk: 2
moe_router_pre_softmax: False
moe_grouped_gemm: False
moe_aux_loss_coeff: 0.0
moe_z_loss_coeff: None
moe_input_jitter_eps: None
moe_token_dispatcher_type: allgather
moe_per_layer_logging: False
moe_expert_capacity_factor: None
moe_pad_expert_input_to_capacity: False
moe_token_drop_policy: probs
moe_layer_recompute: False
moe_extended_tp: False
log_params_norm: False
log_num_zeros_in_grad: False
log_throughput: False
log_progress: False
timing_log_level: 0
barrier_with_L1_time: True
timing_log_option: minmax
tensorboard_log_interval: 1
tensorboard_queue_size: 1000
log_timers_to_tensorboard: False
log_loss_scale_to_tensorboard: True
log_validation_ppl_to_tensorboard: False
log_memory_to_tensorboard: False
log_world_size_to_tensorboard: False
wandb_project: 
wandb_exp_name: 
wandb_save_dir: 
logging_level: None
log_straggler: False
disable_straggler_on_startup: False
straggler_ctrlr_port: 65535
straggler_minmax_count: 1
inference_batch_times_seqlen_threshold: 512
max_tokens_to_oom: 12000
output_bert_embeddings: False
bert_embedder_type: megatron
fp8: None
fp8_margin: 0
fp8_interval: 1
fp8_amax_history_len: 1
fp8_amax_compute_algo: most_recent
fp8_wgrad: True
transformer_impl: transformer_engine
retro_project_dir: None
retro_add_retriever: False
retro_cyclic_train_iters: None
retro_encoder_layers: 2
retro_encoder_hidden_dropout: 0.1
retro_encoder_attention_dropout: 0.1
retro_num_neighbors: 2
retro_num_retrieved_chunks: 2
retro_attention_gate: 1
retro_verify_neighbor_count: True
spec: None
hybrid_attention_ratio: 0.0
hybrid_mlp_ratio: 0.0
hybrid_override_pattern: None
yaml_cfg: None
enable_one_logger: True
one_logger_project: megatron-lm
one_logger_run_name: None
one_logger_async: False
app_tag_run_name: None
app_tag_run_version: 0.0.0
enable_ft_package: False
config_logger_dir: 
rank: 0
world_size: 8
use_dist_ckpt: True
transformer_pipeline_model_parallel_size: 2
data_parallel_size: 2
virtual_pipeline_model_parallel_size: None
params_dtype: torch.float32
consumed_train_samples: 0
skipped_train_samples: 0
consumed_valid_samples: 0
variable_seq_lengths: False
padded_vocab_size: 50432
Parameters Done
[rank0]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 16 
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING] due to: 
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/ku/ckunynpgfs4w7f5jpeewoirivdovt7lww3pgs46afxngy5ekosxp.py", line 86, in <module>
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/0/b827059804d55bbe7aa604785b046124/triton_.so: undefined symbol: cuLaunchKernel
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:31:50,856] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 16 
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING] due to: 
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/dh/cdha4qambshsbrw4cuu2dui6cdmq5h222rhn27txowknuj3soaf4.py", line 86, in <module>
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/1/b827059804d55bbe7aa604785b046124/triton_.so: undefined symbol: cuLaunchKernel
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:31:50,863] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 16 
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING] due to: 
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/h7/ch7byjo23b6by3osddus5xygbkbjqmpj2n6pvuupzgrxjtjo5ygw.py", line 86, in <module>
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/4/b827059804d55bbe7aa604785b046124/triton_.so: undefined symbol: cuLaunchKernel
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:31:50,864] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 16 
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING] due to: 
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/2l/c2lybtivowpcgymtamhzky3psrcynwnvwpw4vk6noc4fkxoac3wb.py", line 86, in <module>
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/6/b827059804d55bbe7aa604785b046124/triton_.so: undefined symbol: cuLaunchKernel
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:31:50,875] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 16 
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING] due to: 
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/px/cpxou33334fmwy6ul4mw56xd7dil6uktjrir74ao3diiu4oiuplj.py", line 86, in <module>
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/3/b827059804d55bbe7aa604785b046124/triton_.so: undefined symbol: cuLaunchKernel
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:31:50,888] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 16 
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING] due to: 
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/cc/ccc5b3koxoocgvssmep2tadmxqntmv3mmcp42wbkcrvcakoeuxvz.py", line 86, in <module>
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/2/b827059804d55bbe7aa604785b046124/triton_.so: undefined symbol: cuLaunchKernel
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:31:50,893] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 16 
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING] due to: 
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/cr/ccrqyetyofvkif5xk4vxca3l3seiyu7fj6lxmam55a72aq37qfaj.py", line 86, in <module>
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/5/b827059804d55bbe7aa604785b046124/triton_.so: undefined symbol: cuLaunchKernel
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:31:50,941] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 16 
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING] due to: 
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/ot/cotkzqbihz7l6m6354ap6xcsnaupqmj5pfu2mmpuk7m7ojtnxxgc.py", line 86, in <module>
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/7/b827059804d55bbe7aa604785b046124/triton_.so: undefined symbol: cuLaunchKernel
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:31:51,013] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_train /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 48 
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING] due to: 
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/d4/cd4vrqhjl4f4in7ev43f5u6xvdzjwl4oic3zorpwyag7m2uxt34b.py", line 78, in <module>
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/0/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:31:51,438] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_train /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 48 
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING] due to: 
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/3u/c3u2ba6nbk2clqxcspkzzhqqx4v7mo7uexu5djhemjsojxvdj3ft.py", line 78, in <module>
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/1/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:31:51,443] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_train /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 48 
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING] due to: 
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/u3/cu3rpkz72l7kux2zt7qny2my5muxemxjp32yhyhmazv7tbhkohyb.py", line 78, in <module>
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/4/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:31:51,451] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_train /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 48 
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING] due to: 
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/yd/cydbbgo3gm2sizebyyzuiqlfobrmlifumtfdhfj3ysoyngwqkzfl.py", line 78, in <module>
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/6/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:31:51,476] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_train /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 48 
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING] due to: 
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/rq/crqnjjj66kqnpxhw4bozfq3jfwlelizicktii7hevhvuvzizw3kd.py", line 78, in <module>
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/3/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:31:51,479] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_train /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 48 
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING] due to: 
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/jr/cjrbssozufroouchwqsea6p2ibglgxvyh3arw3aeukljqh4hw2ib.py", line 78, in <module>
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/2/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:31:51,486] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_train /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 48 
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING] due to: 
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/pc/cpcobgsmac6x3r5csyjreek4fdi7ykclnllzzmssr5shw5mku24l.py", line 78, in <module>
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/5/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:31:51,534] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_train /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 48 
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING] due to: 
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/ky/ckypnwknrzqivvmnthk2iiofmtiosa4pstosel3pdjpogn7qeoiz.py", line 78, in <module>
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/7/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:31:51,603] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT _bias_dropout_add_func /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 9 
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING] due to: 
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/3u/c3u2ba6nbk2clqxcspkzzhqqx4v7mo7uexu5djhemjsojxvdj3ft.py", line 78, in <module>
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/1/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:31:51,972] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT _bias_dropout_add_func /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 9 
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING] due to: 
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/d4/cd4vrqhjl4f4in7ev43f5u6xvdzjwl4oic3zorpwyag7m2uxt34b.py", line 78, in <module>
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/0/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:31:51,978] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT _bias_dropout_add_func /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 9 
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING] due to: 
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/u3/cu3rpkz72l7kux2zt7qny2my5muxemxjp32yhyhmazv7tbhkohyb.py", line 78, in <module>
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/4/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:31:51,997] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT _bias_dropout_add_func /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 9 
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING] due to: 
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/yd/cydbbgo3gm2sizebyyzuiqlfobrmlifumtfdhfj3ysoyngwqkzfl.py", line 78, in <module>
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/6/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:31:52,026] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT _bias_dropout_add_func /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 9 
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING] due to: 
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/rq/crqnjjj66kqnpxhw4bozfq3jfwlelizicktii7hevhvuvzizw3kd.py", line 78, in <module>
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/3/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:31:52,027] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT _bias_dropout_add_func /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 9 
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING] due to: 
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/jr/cjrbssozufroouchwqsea6p2ibglgxvyh3arw3aeukljqh4hw2ib.py", line 78, in <module>
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/2/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:31:52,035] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT _bias_dropout_add_func /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 9 
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING] due to: 
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/pc/cpcobgsmac6x3r5csyjreek4fdi7ykclnllzzmssr5shw5mku24l.py", line 78, in <module>
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/5/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:31:52,083] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT _bias_dropout_add_func /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 9 
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING] due to: 
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/ky/ckypnwknrzqivvmnthk2iiofmtiosa4pstosel3pdjpogn7qeoiz.py", line 78, in <module>
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/7/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:31:52,154] torch._dynamo.convert_frame: [WARNING] 
time to initialize megatron (seconds): 3.559
[after megatron is initialized] datetime: 2024-10-02 15:31:52 
building GPT model ...
use_te: True, HAVE_TE: Trueuse_te: True, HAVE_TE: Trueuse_te: True, HAVE_TE: Trueuse_te: True, HAVE_TE: Trueuse_te: True, HAVE_TE: True

use_te: True, HAVE_TE: Trueuse_te: True, HAVE_TE: True
use_te: True, HAVE_TE: True




/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/base.py:643: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/base.py:643: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/base.py:643: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/base.py:643: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/base.py:643: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/base.py:643: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/base.py:643: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/base.py:643: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
 > number of parameters on (tensor, pipeline) model parallel rank (1, 0): 41429760
 > number of parameters on (tensor, pipeline) model parallel rank (1, 1): 40644864
 > number of parameters on (tensor, pipeline) model parallel rank (0, 1): 40644864
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 41429760
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
Params for bucket 1 (40644864 elements):
	decoder.layers.3.self_attention.linear_qkv.bias
	decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.1.self_attention.linear_proj.weight
	decoder.layers.2.mlp.linear_fc2.bias
	decoder.layers.2.mlp.linear_fc2.weight
	decoder.layers.0.mlp.linear_fc2.weight
	decoder.layers.5.mlp.linear_fc1.weight
	decoder.layers.5.self_attention.linear_proj.weight
	decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.3.mlp.linear_fc1.layer_norm_bias
	decoder.layers.0.mlp.linear_fc1.weight
	decoder.layers.5.mlp.linear_fc2.weight
	decoder.layers.4.self_attention.linear_proj.weight
	decoder.layers.3.self_attention.linear_proj.weight
	decoder.layers.2.self_attention.linear_qkv.bias
	decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.0.self_attention.linear_proj.bias
	decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.4.mlp.linear_fc1.weight
	decoder.layers.4.self_attention.linear_qkv.bias
	decoder.layers.3.mlp.linear_fc2.weight
	decoder.layers.1.mlp.linear_fc1.bias
	decoder.layers.0.mlp.linear_fc1.layer_norm_weight
	decoder.layers.1.self_attention.linear_qkv.weight
	decoder.layers.5.mlp.linear_fc1.bias
	decoder.layers.4.mlp.linear_fc2.bias
	decoder.layers.4.mlp.linear_fc1.layer_norm_bias
	decoder.layers.3.mlp.linear_fc1.weight
	decoder.layers.2.self_attention.linear_proj.weight
	decoder.layers.0.mlp.linear_fc2.bias
	decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.1.mlp.linear_fc1.layer_norm_bias
	decoder.layers.1.self_attention.linear_qkv.bias
	decoder.layers.0.self_attention.linear_qkv.weight
	decoder.final_layernorm.weight
	decoder.layers.3.mlp.linear_fc1.layer_norm_weight
	decoder.layers.3.self_attention.linear_proj.bias
	decoder.layers.1.mlp.linear_fc2.weight
	decoder.layers.0.mlp.linear_fc1.bias
	decoder.layers.4.mlp.linear_fc2.weight
	decoder.layers.3.mlp.linear_fc2.bias
	decoder.layers.1.self_attention.linear_proj.bias
	decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.0.self_attention.linear_proj.weight
	decoder.layers.5.self_attention.linear_proj.bias
	decoder.layers.2.mlp.linear_fc1.layer_norm_bias
	decoder.layers.1.mlp.linear_fc1.weight
	decoder.layers.4.mlp.linear_fc1.bias
	decoder.final_layernorm.bias
	decoder.layers.3.mlp.linear_fc1.bias
	decoder.layers.3.self_attention.linear_qkv.weight
	decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.2.self_attention.linear_proj.bias
	decoder.layers.4.mlp.linear_fc1.layer_norm_weight
	decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.0.self_attention.linear_qkv.bias
	decoder.layers.1.mlp.linear_fc2.bias
	decoder.layers.1.mlp.linear_fc1.layer_norm_weight
	decoder.layers.5.mlp.linear_fc2.bias
	decoder.layers.5.mlp.linear_fc1.layer_norm_bias
	decoder.layers.5.mlp.linear_fc1.layer_norm_weight
	decoder.layers.5.self_attention.linear_qkv.bias
	decoder.layers.4.self_attention.linear_proj.bias
	decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.2.mlp.linear_fc1.bias
	decoder.layers.2.mlp.linear_fc1.layer_norm_weight
	decoder.layers.2.self_attention.linear_qkv.weight
	output_layer.weight
	decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.5.self_attention.linear_qkv.weight
	decoder.layers.4.self_attention.linear_qkv.weight
	decoder.layers.2.mlp.linear_fc1.weight
	decoder.layers.0.mlp.linear_fc1.layer_norm_bias
wrap_with_ddp: True
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None, average_in_collective=False)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
Params for bucket 1 (41429760 elements):
	decoder.layers.5.mlp.linear_fc2.weight
	decoder.layers.4.mlp.linear_fc2.weight
	decoder.layers.3.mlp.linear_fc2.bias
	decoder.layers.3.self_attention.linear_qkv.weight
	decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.5.mlp.linear_fc1.layer_norm_weight
	decoder.layers.5.self_attention.linear_qkv.weight
	decoder.layers.2.self_attention.linear_qkv.bias
	decoder.layers.1.self_attention.linear_proj.bias
	decoder.layers.5.mlp.linear_fc2.bias
	decoder.layers.4.mlp.linear_fc1.weight
	decoder.layers.3.mlp.linear_fc2.weight
	decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.2.mlp.linear_fc1.weight
	decoder.layers.2.mlp.linear_fc1.layer_norm_bias
	decoder.layers.1.self_attention.linear_qkv.weight
	decoder.layers.0.self_attention.linear_qkv.weight
	embedding.position_embeddings.weight
	decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.2.mlp.linear_fc2.weight
	decoder.layers.1.mlp.linear_fc1.layer_norm_bias
	decoder.layers.0.self_attention.linear_proj.bias
	decoder.layers.0.mlp.linear_fc1.layer_norm_bias
	decoder.layers.5.mlp.linear_fc1.bias
	decoder.layers.5.self_attention.linear_proj.bias
	decoder.layers.4.self_attention.linear_proj.bias
	decoder.layers.4.self_attention.linear_qkv.weight
	decoder.layers.3.mlp.linear_fc1.layer_norm_bias
	decoder.layers.3.self_attention.linear_qkv.bias
	decoder.layers.1.mlp.linear_fc2.weight
	decoder.layers.1.mlp.linear_fc1.bias
	decoder.layers.1.mlp.linear_fc1.layer_norm_weight
	decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.2.self_attention.linear_proj.weight
	decoder.layers.0.mlp.linear_fc2.weight
	decoder.layers.4.mlp.linear_fc2.bias
	decoder.layers.4.mlp.linear_fc1.layer_norm_bias
	decoder.layers.2.mlp.linear_fc2.bias
	decoder.layers.0.self_attention.linear_qkv.bias
	decoder.layers.5.self_attention.linear_proj.weight
	decoder.layers.3.mlp.linear_fc1.bias
	decoder.layers.3.self_attention.linear_proj.weight
	decoder.layers.0.mlp.linear_fc1.weight
	decoder.layers.5.mlp.linear_fc1.layer_norm_bias
	decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.2.mlp.linear_fc1.bias
	decoder.layers.2.self_attention.linear_qkv.weight
	decoder.layers.1.self_attention.linear_qkv.bias
	decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.0.mlp.linear_fc1.layer_norm_weight
	decoder.layers.4.mlp.linear_fc1.layer_norm_weight
	decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.2.self_attention.linear_proj.bias
	decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.0.self_attention.linear_proj.weight
	decoder.layers.5.mlp.linear_fc1.weight
	decoder.layers.5.self_attention.linear_qkv.bias
	decoder.layers.4.self_attention.linear_qkv.bias
	decoder.layers.3.mlp.linear_fc1.weight
	decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.2.mlp.linear_fc1.layer_norm_weight
	decoder.layers.1.self_attention.linear_proj.weight
	decoder.layers.4.mlp.linear_fc1.bias
	decoder.layers.3.mlp.linear_fc1.layer_norm_weight
	decoder.layers.3.self_attention.linear_proj.bias
	decoder.layers.0.mlp.linear_fc1.bias
	decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.0.mlp.linear_fc2.bias
	decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
	embedding.word_embeddings.weight
	decoder.layers.4.self_attention.linear_proj.weight
	decoder.layers.1.mlp.linear_fc2.bias
	decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.optimizer:Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0005, min_lr=0.0, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.1, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, overlap_param_gather_with_optimizer_step=False, align_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x2b90c81a3af0>, config_logger_dir='')
INFO:megatron.core.optimizer_param_scheduler:> learning rate decay style: cosine
WARNING: could not find the metadata file /workspace/Megatron-LM/experiments/codeparrot-small/latest_checkpointed_iteration.txt
    will not load any checkpoints and will start from random
(min, max) time across ranks (ms):
    load-checkpoint ................................: (3.95, 3.97)
[after model, optimizer, and learning rate scheduler are built] datetime: 2024-10-02 15:31:52 
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      57600
    validation: 5760
    test:       2880
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.969), (0.969, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
INFO:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(57600, 5760, 2880), and config=GPTDatasetConfig(random_seed=1234, sequence_length=1024, blend=(['codeparrot_content_document'], None), blend_per_split=[None, None, None], renormalize_blend_weights=False, split='969, 30, 1', split_matrix=[(0, 0.969), (0.969, 0.999), (0.999, 1.0)], num_dataset_builder_threads=1, path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x2b90c81a34f0>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, s3_cache_path=None)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from codeparrot_content_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 5300000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 5300000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 2722c0bf14f633c0e122b4d76bf46142-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 2722c0bf14f633c0e122b4d76bf46142-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 2722c0bf14f633c0e122b4d76bf46142-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 23120956
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 6159ae0ba58a5d091588dc246df29a5f-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 6159ae0ba58a5d091588dc246df29a5f-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 6159ae0ba58a5d091588dc246df29a5f-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 695029
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from ff96291a8b07e99c71bc8de5f47bb0ac-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from ff96291a8b07e99c71bc8de5f47bb0ac-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from ff96291a8b07e99c71bc8de5f47bb0ac-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 23384
> finished creating GPT datasets ...
[after dataloaders are built] datetime: 2024-10-02 15:31:52 
done with setup ...
(min, max) time across ranks (ms):
    model-and-optimizer-setup ......................: (181.97, 196.88)
    train/valid/test-data-iterators-setup ..........: (26.59, 198.19)
training ...
[before the start of training step] datetime: 2024-10-02 15:31:52 
[rank7]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank5]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank4]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank6]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank3]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank2]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank0]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank1]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank3]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank2]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank0]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank1]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:711: UserWarning: When using async grad allreduce it is recommended to set the environment variable CUDA_DEVICE_MAX_CONNECTIONS to 1 for maximum speedup
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:711: UserWarning: When using async grad allreduce it is recommended to set the environment variable CUDA_DEVICE_MAX_CONNECTIONS to 1 for maximum speedup
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:711: UserWarning: When using async grad allreduce it is recommended to set the environment variable CUDA_DEVICE_MAX_CONNECTIONS to 1 for maximum speedup
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:711: UserWarning: When using async grad allreduce it is recommended to set the environment variable CUDA_DEVICE_MAX_CONNECTIONS to 1 for maximum speedup
  warnings.warn(
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu_back /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 25 
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING] due to: 
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2073, in aot_dispatch_base
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     compiled_fw = compiler(fw_module, updated_flat_args)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/km/ckmqga4yy6jzv5dtxtvzxctrajlpnnsavkprknkgwhdxa3otoea5.py", line 106, in <module>
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/5/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:31:54,851] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu_back /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 25 
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING] due to: 
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2073, in aot_dispatch_base
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     compiled_fw = compiler(fw_module, updated_flat_args)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/ep/cepnm4i67fd3bm54wrvs2e67fnyffwxuhuinjj57azhwwefw4d4q.py", line 106, in <module>
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/7/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:31:54,852] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu_back /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 25 
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING] due to: 
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2073, in aot_dispatch_base
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     compiled_fw = compiler(fw_module, updated_flat_args)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/j6/cj6qakzxs3japz27vbftw43gae65w6u6pul2zp22ex7ftygdyg3b.py", line 106, in <module>
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/4/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:31:54,856] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu_back /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 25 
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING] due to: 
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2073, in aot_dispatch_base
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     compiled_fw = compiler(fw_module, updated_flat_args)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/pl/cpltcn22pbtoxpd6l65abwgtcsbgtgxd4fwzatrogbj5selqs34h.py", line 106, in <module>
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/6/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:31:54,869] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank4]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank6]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank7]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu_back /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 25 
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING] due to: 
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2073, in aot_dispatch_base
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     compiled_fw = compiler(fw_module, updated_flat_args)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/g6/cg6oyy52quyatjq7mmxjoxluh5gy2lzpj3n4peesqjxqxfochht4.py", line 106, in <module>
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/3/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:31:55,726] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu_back /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 25 
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING] due to: 
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2073, in aot_dispatch_base
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     compiled_fw = compiler(fw_module, updated_flat_args)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/o6/co6dwzi45ojb34leicstoz2d6mp7u2spgtuloqzzdq2dbvme5e7p.py", line 106, in <module>
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/1/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:31:55,728] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu_back /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 25 
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING] due to: 
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2073, in aot_dispatch_base
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     compiled_fw = compiler(fw_module, updated_flat_args)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/ma/cmadken4qp3bgzjeyn46zoxqreldjkf6mj45baeint2et2to24tx.py", line 106, in <module>
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/2/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:31:55,767] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu_back /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 25 
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING] due to: 
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2073, in aot_dispatch_base
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     compiled_fw = compiler(fw_module, updated_flat_args)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/d3/cd3w4abt2vgcssmjjhozl5flf3mbtouzneg54jkf3qabe2nfojn6.py", line 106, in <module>
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/0/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:31:55,773] torch._dynamo.convert_frame: [WARNING] 
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2



global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
Number of parameters in transformer layers in billions:  0.08 [2024-10-02 15:31:59] iteration        1/     200 | consumed samples:          288 | elapsed time per iteration (ms): 6677.8 | learning rate: 2.500000E-07 | global batch size:   288 | lm loss: 1.078501E+01 | loss scale: 1.0 | grad norm: 80.158 | number of skipped iterations:   0 | number of nan iterations:   0 |

Number of parameters in embedding layers in billions: 0.04
Total number of parameters in billions: 0.12
Number of parameters in most loaded shard in billions: 0.0406
Number of parameters in other shards in billions: 0.0212
Theoretical memory footprints: weight and optimizer=697.10 MB
[Rank 5] (after 1 iterations) memory (MB) | allocated: 1834.2802734375 | max allocated: 12725.01708984375 | reserved: 14624.0 | max reserved: 14624.0[Rank 1] (after 1 iterations) memory (MB) | allocated: 1630.88671875 | max allocated: 20504.94384765625 | reserved: 22768.0 | max reserved: 22768.0
[Rank 4] (after 1 iterations) memory (MB) | allocated: 1401.2802734375 | max allocated: 12671.0146484375 | reserved: 14516.0 | max reserved: 14516.0
[Rank 0] (after 1 iterations) memory (MB) | allocated: 1631.76171875 | max allocated: 20504.94384765625 | reserved: 22660.0 | max reserved: 22660.0

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2


global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:32:03] iteration        2/     200 | consumed samples:          576 | elapsed time per iteration (ms): 3926.7 | learning rate: 5.000000E-07 | global batch size:   288 | lm loss: 1.079396E+01 | loss scale: 1.0 | grad norm: 76.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2


global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 5, local rank 5, ddp group rank 0/2global rank 7, local rank 7, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:32:07] iteration        3/     200 | consumed samples:          864 | elapsed time per iteration (ms): 3930.5 | learning rate: 7.500000E-07 | global batch size:   288 | lm loss: 1.073469E+01 | loss scale: 1.0 | grad norm: 74.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:32:11] iteration        4/     200 | consumed samples:         1152 | elapsed time per iteration (ms): 3922.4 | learning rate: 1.000000E-06 | global batch size:   288 | lm loss: 1.056782E+01 | loss scale: 1.0 | grad norm: 78.668 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 1, local rank 1, ddp group rank 0/2

global rank 2, local rank 2, ddp group rank 1/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:32:15] iteration        5/     200 | consumed samples:         1440 | elapsed time per iteration (ms): 3923.7 | learning rate: 1.250000E-06 | global batch size:   288 | lm loss: 1.038276E+01 | loss scale: 1.0 | grad norm: 73.770 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:32:18] iteration        6/     200 | consumed samples:         1728 | elapsed time per iteration (ms): 3927.4 | learning rate: 1.500000E-06 | global batch size:   288 | lm loss: 1.011884E+01 | loss scale: 1.0 | grad norm: 71.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:32:22] iteration        7/     200 | consumed samples:         2016 | elapsed time per iteration (ms): 3927.2 | learning rate: 1.750000E-06 | global batch size:   288 | lm loss: 9.788116E+00 | loss scale: 1.0 | grad norm: 67.993 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:32:26] iteration        8/     200 | consumed samples:         2304 | elapsed time per iteration (ms): 3925.8 | learning rate: 2.000000E-06 | global batch size:   288 | lm loss: 9.508053E+00 | loss scale: 1.0 | grad norm: 59.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:32:30] iteration        9/     200 | consumed samples:         2592 | elapsed time per iteration (ms): 3917.3 | learning rate: 2.250000E-06 | global batch size:   288 | lm loss: 9.072193E+00 | loss scale: 1.0 | grad norm: 54.976 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2


global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 6, local rank 6, ddp group rank 1/2global rank 4, local rank 4, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:32:34] iteration       10/     200 | consumed samples:         2880 | elapsed time per iteration (ms): 3926.8 | learning rate: 2.500000E-06 | global batch size:   288 | lm loss: 8.665591E+00 | loss scale: 1.0 | grad norm: 48.590 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:32:38] iteration       11/     200 | consumed samples:         3168 | elapsed time per iteration (ms): 3926.5 | learning rate: 2.750000E-06 | global batch size:   288 | lm loss: 8.296673E+00 | loss scale: 1.0 | grad norm: 41.881 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:32:42] iteration       12/     200 | consumed samples:         3456 | elapsed time per iteration (ms): 3922.0 | learning rate: 3.000000E-06 | global batch size:   288 | lm loss: 7.972933E+00 | loss scale: 1.0 | grad norm: 35.118 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:32:46] iteration       13/     200 | consumed samples:         3744 | elapsed time per iteration (ms): 3922.2 | learning rate: 3.250000E-06 | global batch size:   288 | lm loss: 7.703363E+00 | loss scale: 1.0 | grad norm: 28.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:32:50] iteration       14/     200 | consumed samples:         4032 | elapsed time per iteration (ms): 3920.6 | learning rate: 3.500000E-06 | global batch size:   288 | lm loss: 7.563403E+00 | loss scale: 1.0 | grad norm: 20.181 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2


global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:32:54] iteration       15/     200 | consumed samples:         4320 | elapsed time per iteration (ms): 3926.2 | learning rate: 3.750000E-06 | global batch size:   288 | lm loss: 7.386548E+00 | loss scale: 1.0 | grad norm: 13.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 0, local rank 0, ddp group rank 0/2global rank 1, local rank 1, ddp group rank 0/2

DP USE NCCLDP USE NCCL

 [2024-10-02 15:32:58] iteration       16/     200 | consumed samples:         4608 | elapsed time per iteration (ms): 3923.8 | learning rate: 4.000000E-06 | global batch size:   288 | lm loss: 7.160398E+00 | loss scale: 1.0 | grad norm: 10.858 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:33:02] iteration       17/     200 | consumed samples:         4896 | elapsed time per iteration (ms): 3942.0 | learning rate: 4.250000E-06 | global batch size:   288 | lm loss: 7.260128E+00 | loss scale: 1.0 | grad norm: 13.147 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2


global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:33:06] iteration       18/     200 | consumed samples:         5184 | elapsed time per iteration (ms): 3920.7 | learning rate: 4.500000E-06 | global batch size:   288 | lm loss: 7.165446E+00 | loss scale: 1.0 | grad norm: 14.699 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2



global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:33:10] iteration       19/     200 | consumed samples:         5472 | elapsed time per iteration (ms): 3923.5 | learning rate: 4.750000E-06 | global batch size:   288 | lm loss: 6.922402E+00 | loss scale: 1.0 | grad norm: 11.758 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:33:13] iteration       20/     200 | consumed samples:         5760 | elapsed time per iteration (ms): 3923.6 | learning rate: 5.000000E-06 | global batch size:   288 | lm loss: 7.088161E+00 | loss scale: 1.0 | grad norm: 7.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2


global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
TP USE NCCLglobal rank 6, local rank 6, ddp group rank 1/2

global rank 5, local rank 5, ddp group rank 0/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:33:17] iteration       21/     200 | consumed samples:         6048 | elapsed time per iteration (ms): 3919.5 | learning rate: 5.250000E-06 | global batch size:   288 | lm loss: 6.796494E+00 | loss scale: 1.0 | grad norm: 12.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2


global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:33:21] iteration       22/     200 | consumed samples:         6336 | elapsed time per iteration (ms): 3928.2 | learning rate: 5.500000E-06 | global batch size:   288 | lm loss: 7.002769E+00 | loss scale: 1.0 | grad norm: 15.193 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2


global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 6, local rank 6, ddp group rank 1/2

global rank 4, local rank 4, ddp group rank 0/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:33:25] iteration       23/     200 | consumed samples:         6624 | elapsed time per iteration (ms): 3921.6 | learning rate: 5.750000E-06 | global batch size:   288 | lm loss: 6.911609E+00 | loss scale: 1.0 | grad norm: 14.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:33:29] iteration       24/     200 | consumed samples:         6912 | elapsed time per iteration (ms): 3930.9 | learning rate: 6.000000E-06 | global batch size:   288 | lm loss: 6.585608E+00 | loss scale: 1.0 | grad norm: 11.546 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2


global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2


global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2


TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 4, local rank 4, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 0, local rank 0, ddp group rank 0/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:33:33] iteration       25/     200 | consumed samples:         7200 | elapsed time per iteration (ms): 3920.8 | learning rate: 6.250000E-06 | global batch size:   288 | lm loss: 6.889099E+00 | loss scale: 1.0 | grad norm: 5.378 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:33:37] iteration       26/     200 | consumed samples:         7488 | elapsed time per iteration (ms): 3926.2 | learning rate: 6.500000E-06 | global batch size:   288 | lm loss: 6.584404E+00 | loss scale: 1.0 | grad norm: 6.329 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2


global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:33:41] iteration       27/     200 | consumed samples:         7776 | elapsed time per iteration (ms): 3920.8 | learning rate: 6.750000E-06 | global batch size:   288 | lm loss: 6.512450E+00 | loss scale: 1.0 | grad norm: 7.563 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2


global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2global rank 0, local rank 0, ddp group rank 0/2TP USE NCCL


DP USE NCCLDP USE NCCLglobal rank 3, local rank 3, ddp group rank 1/2


DP USE NCCL
 [2024-10-02 15:33:45] iteration       28/     200 | consumed samples:         8064 | elapsed time per iteration (ms): 3929.7 | learning rate: 7.000000E-06 | global batch size:   288 | lm loss: 6.655983E+00 | loss scale: 1.0 | grad norm: 5.319 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 7, local rank 7, ddp group rank 1/2

global rank 4, local rank 4, ddp group rank 0/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:33:49] iteration       29/     200 | consumed samples:         8352 | elapsed time per iteration (ms): 3926.3 | learning rate: 7.250000E-06 | global batch size:   288 | lm loss: 6.471995E+00 | loss scale: 1.0 | grad norm: 4.680 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2


global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2


global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:33:53] iteration       30/     200 | consumed samples:         8640 | elapsed time per iteration (ms): 3928.0 | learning rate: 7.500000E-06 | global batch size:   288 | lm loss: 6.516239E+00 | loss scale: 1.0 | grad norm: 6.205 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:33:57] iteration       31/     200 | consumed samples:         8928 | elapsed time per iteration (ms): 3935.3 | learning rate: 7.750000E-06 | global batch size:   288 | lm loss: 6.217973E+00 | loss scale: 1.0 | grad norm: 5.995 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:34:01] iteration       32/     200 | consumed samples:         9216 | elapsed time per iteration (ms): 3935.4 | learning rate: 8.000000E-06 | global batch size:   288 | lm loss: 6.398849E+00 | loss scale: 1.0 | grad norm: 3.334 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:34:04] iteration       33/     200 | consumed samples:         9504 | elapsed time per iteration (ms): 3940.3 | learning rate: 8.250000E-06 | global batch size:   288 | lm loss: 6.296744E+00 | loss scale: 1.0 | grad norm: 3.799 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:34:08] iteration       34/     200 | consumed samples:         9792 | elapsed time per iteration (ms): 3933.0 | learning rate: 8.500000E-06 | global batch size:   288 | lm loss: 6.231655E+00 | loss scale: 1.0 | grad norm: 4.187 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2global rank 0, local rank 0, ddp group rank 0/2

DP USE NCCLDP USE NCCL

 [2024-10-02 15:34:12] iteration       35/     200 | consumed samples:        10080 | elapsed time per iteration (ms): 3931.1 | learning rate: 8.750000E-06 | global batch size:   288 | lm loss: 6.266932E+00 | loss scale: 1.0 | grad norm: 2.722 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:34:16] iteration       36/     200 | consumed samples:        10368 | elapsed time per iteration (ms): 3926.1 | learning rate: 9.000000E-06 | global batch size:   288 | lm loss: 6.145153E+00 | loss scale: 1.0 | grad norm: 2.723 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2


global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
TP USE NCCLDP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:34:20] iteration       37/     200 | consumed samples:        10656 | elapsed time per iteration (ms): 3938.8 | learning rate: 9.250000E-06 | global batch size:   288 | lm loss: 6.187675E+00 | loss scale: 1.0 | grad norm: 2.946 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:34:24] iteration       38/     200 | consumed samples:        10944 | elapsed time per iteration (ms): 3937.8 | learning rate: 9.500000E-06 | global batch size:   288 | lm loss: 6.000803E+00 | loss scale: 1.0 | grad norm: 2.229 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 7, local rank 7, ddp group rank 1/2

global rank 5, local rank 5, ddp group rank 0/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:34:28] iteration       39/     200 | consumed samples:        11232 | elapsed time per iteration (ms): 3931.7 | learning rate: 9.750000E-06 | global batch size:   288 | lm loss: 6.270586E+00 | loss scale: 1.0 | grad norm: 2.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:34:32] iteration       40/     200 | consumed samples:        11520 | elapsed time per iteration (ms): 3953.5 | learning rate: 1.000000E-05 | global batch size:   288 | lm loss: 6.026348E+00 | loss scale: 1.0 | grad norm: 2.193 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:34:36] iteration       41/     200 | consumed samples:        11808 | elapsed time per iteration (ms): 3936.7 | learning rate: 1.025000E-05 | global batch size:   288 | lm loss: 5.945368E+00 | loss scale: 1.0 | grad norm: 1.831 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:34:40] iteration       42/     200 | consumed samples:        12096 | elapsed time per iteration (ms): 3947.3 | learning rate: 1.050000E-05 | global batch size:   288 | lm loss: 6.135133E+00 | loss scale: 1.0 | grad norm: 2.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 4, local rank 4, ddp group rank 0/2global rank 6, local rank 6, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:34:44] iteration       43/     200 | consumed samples:        12384 | elapsed time per iteration (ms): 3932.6 | learning rate: 1.075000E-05 | global batch size:   288 | lm loss: 6.040157E+00 | loss scale: 1.0 | grad norm: 2.291 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:34:48] iteration       44/     200 | consumed samples:        12672 | elapsed time per iteration (ms): 3924.7 | learning rate: 1.100000E-05 | global batch size:   288 | lm loss: 5.959186E+00 | loss scale: 1.0 | grad norm: 1.731 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:34:52] iteration       45/     200 | consumed samples:        12960 | elapsed time per iteration (ms): 3926.2 | learning rate: 1.125000E-05 | global batch size:   288 | lm loss: 6.007359E+00 | loss scale: 1.0 | grad norm: 1.773 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:34:56] iteration       46/     200 | consumed samples:        13248 | elapsed time per iteration (ms): 3926.2 | learning rate: 1.150000E-05 | global batch size:   288 | lm loss: 5.925988E+00 | loss scale: 1.0 | grad norm: 2.104 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 1, local rank 1, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:35:00] iteration       47/     200 | consumed samples:        13536 | elapsed time per iteration (ms): 3923.5 | learning rate: 1.175000E-05 | global batch size:   288 | lm loss: 5.897823E+00 | loss scale: 1.0 | grad norm: 1.730 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:35:03] iteration       48/     200 | consumed samples:        13824 | elapsed time per iteration (ms): 3929.7 | learning rate: 1.200000E-05 | global batch size:   288 | lm loss: 5.793961E+00 | loss scale: 1.0 | grad norm: 1.772 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2


global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:35:07] iteration       49/     200 | consumed samples:        14112 | elapsed time per iteration (ms): 3931.4 | learning rate: 1.225000E-05 | global batch size:   288 | lm loss: 5.947432E+00 | loss scale: 1.0 | grad norm: 1.654 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2


global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:35:11] iteration       50/     200 | consumed samples:        14400 | elapsed time per iteration (ms): 3929.8 | learning rate: 1.250000E-05 | global batch size:   288 | lm loss: 5.829659E+00 | loss scale: 1.0 | grad norm: 1.558 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:35:15] iteration       51/     200 | consumed samples:        14688 | elapsed time per iteration (ms): 3941.3 | learning rate: 1.275000E-05 | global batch size:   288 | lm loss: 5.838382E+00 | loss scale: 1.0 | grad norm: 1.700 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 5, local rank 5, ddp group rank 0/2global rank 7, local rank 7, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:35:19] iteration       52/     200 | consumed samples:        14976 | elapsed time per iteration (ms): 3933.8 | learning rate: 1.300000E-05 | global batch size:   288 | lm loss: 5.853933E+00 | loss scale: 1.0 | grad norm: 1.604 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:35:23] iteration       53/     200 | consumed samples:        15264 | elapsed time per iteration (ms): 3931.1 | learning rate: 1.325000E-05 | global batch size:   288 | lm loss: 5.779236E+00 | loss scale: 1.0 | grad norm: 1.578 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:35:27] iteration       54/     200 | consumed samples:        15552 | elapsed time per iteration (ms): 3932.5 | learning rate: 1.350000E-05 | global batch size:   288 | lm loss: 5.890131E+00 | loss scale: 1.0 | grad norm: 1.697 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:35:31] iteration       55/     200 | consumed samples:        15840 | elapsed time per iteration (ms): 3928.7 | learning rate: 1.375000E-05 | global batch size:   288 | lm loss: 5.909459E+00 | loss scale: 1.0 | grad norm: 1.595 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2TP USE NCCL

DP USE NCCLglobal rank 1, local rank 1, ddp group rank 0/2

DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:35:35] iteration       56/     200 | consumed samples:        16128 | elapsed time per iteration (ms): 3937.5 | learning rate: 1.400000E-05 | global batch size:   288 | lm loss: 5.966948E+00 | loss scale: 1.0 | grad norm: 1.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:35:39] iteration       57/     200 | consumed samples:        16416 | elapsed time per iteration (ms): 3930.5 | learning rate: 1.425000E-05 | global batch size:   288 | lm loss: 5.634697E+00 | loss scale: 1.0 | grad norm: 1.523 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:35:43] iteration       58/     200 | consumed samples:        16704 | elapsed time per iteration (ms): 3937.3 | learning rate: 1.450000E-05 | global batch size:   288 | lm loss: 5.643003E+00 | loss scale: 1.0 | grad norm: 1.545 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:35:47] iteration       59/     200 | consumed samples:        16992 | elapsed time per iteration (ms): 3933.1 | learning rate: 1.475000E-05 | global batch size:   288 | lm loss: 5.613538E+00 | loss scale: 1.0 | grad norm: 1.818 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2


global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2


global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:35:51] iteration       60/     200 | consumed samples:        17280 | elapsed time per iteration (ms): 3926.3 | learning rate: 1.500000E-05 | global batch size:   288 | lm loss: 5.754438E+00 | loss scale: 1.0 | grad norm: 1.618 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:35:55] iteration       61/     200 | consumed samples:        17568 | elapsed time per iteration (ms): 3934.4 | learning rate: 1.525000E-05 | global batch size:   288 | lm loss: 5.699882E+00 | loss scale: 1.0 | grad norm: 1.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 0, local rank 0, ddp group rank 0/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

 [2024-10-02 15:35:59] iteration       62/     200 | consumed samples:        17856 | elapsed time per iteration (ms): 3937.8 | learning rate: 1.550000E-05 | global batch size:   288 | lm loss: 5.586374E+00 | loss scale: 1.0 | grad norm: 2.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:36:02] iteration       63/     200 | consumed samples:        18144 | elapsed time per iteration (ms): 3929.9 | learning rate: 1.575000E-05 | global batch size:   288 | lm loss: 5.743446E+00 | loss scale: 1.0 | grad norm: 1.902 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:36:06] iteration       64/     200 | consumed samples:        18432 | elapsed time per iteration (ms): 3930.2 | learning rate: 1.600000E-05 | global batch size:   288 | lm loss: 5.600847E+00 | loss scale: 1.0 | grad norm: 1.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:36:10] iteration       65/     200 | consumed samples:        18720 | elapsed time per iteration (ms): 3928.7 | learning rate: 1.625000E-05 | global batch size:   288 | lm loss: 5.639280E+00 | loss scale: 1.0 | grad norm: 2.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2


global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:36:14] iteration       66/     200 | consumed samples:        19008 | elapsed time per iteration (ms): 3937.8 | learning rate: 1.650000E-05 | global batch size:   288 | lm loss: 5.499788E+00 | loss scale: 1.0 | grad norm: 2.658 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 2, local rank 2, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:36:18] iteration       67/     200 | consumed samples:        19296 | elapsed time per iteration (ms): 3938.4 | learning rate: 1.675000E-05 | global batch size:   288 | lm loss: 5.682741E+00 | loss scale: 1.0 | grad norm: 1.566 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:36:22] iteration       68/     200 | consumed samples:        19584 | elapsed time per iteration (ms): 3937.8 | learning rate: 1.700000E-05 | global batch size:   288 | lm loss: 5.517661E+00 | loss scale: 1.0 | grad norm: 1.291 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:36:26] iteration       69/     200 | consumed samples:        19872 | elapsed time per iteration (ms): 3942.5 | learning rate: 1.725000E-05 | global batch size:   288 | lm loss: 5.431912E+00 | loss scale: 1.0 | grad norm: 1.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2


global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

 [2024-10-02 15:36:30] iteration       70/     200 | consumed samples:        20160 | elapsed time per iteration (ms): 3936.6 | learning rate: 1.750000E-05 | global batch size:   288 | lm loss: 5.506347E+00 | loss scale: 1.0 | grad norm: 1.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2


global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:36:34] iteration       71/     200 | consumed samples:        20448 | elapsed time per iteration (ms): 3925.2 | learning rate: 1.775000E-05 | global batch size:   288 | lm loss: 5.343655E+00 | loss scale: 1.0 | grad norm: 2.293 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:36:38] iteration       72/     200 | consumed samples:        20736 | elapsed time per iteration (ms): 3925.0 | learning rate: 1.800000E-05 | global batch size:   288 | lm loss: 5.534343E+00 | loss scale: 1.0 | grad norm: 1.746 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:36:42] iteration       73/     200 | consumed samples:        21024 | elapsed time per iteration (ms): 3931.2 | learning rate: 1.825000E-05 | global batch size:   288 | lm loss: 5.320119E+00 | loss scale: 1.0 | grad norm: 1.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:36:46] iteration       74/     200 | consumed samples:        21312 | elapsed time per iteration (ms): 3931.9 | learning rate: 1.850000E-05 | global batch size:   288 | lm loss: 5.422258E+00 | loss scale: 1.0 | grad norm: 1.335 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCLTP USE NCCL

global rank 5, local rank 5, ddp group rank 0/2global rank 6, local rank 6, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:36:50] iteration       75/     200 | consumed samples:        21600 | elapsed time per iteration (ms): 3934.3 | learning rate: 1.875000E-05 | global batch size:   288 | lm loss: 5.456491E+00 | loss scale: 1.0 | grad norm: 1.563 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 4, local rank 4, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:36:54] iteration       76/     200 | consumed samples:        21888 | elapsed time per iteration (ms): 3943.4 | learning rate: 1.900000E-05 | global batch size:   288 | lm loss: 5.349910E+00 | loss scale: 1.0 | grad norm: 1.766 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:36:58] iteration       77/     200 | consumed samples:        22176 | elapsed time per iteration (ms): 3939.0 | learning rate: 1.925000E-05 | global batch size:   288 | lm loss: 5.526495E+00 | loss scale: 1.0 | grad norm: 1.585 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2


global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:37:02] iteration       78/     200 | consumed samples:        22464 | elapsed time per iteration (ms): 3936.0 | learning rate: 1.950000E-05 | global batch size:   288 | lm loss: 5.390039E+00 | loss scale: 1.0 | grad norm: 1.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

TP USE NCCLglobal rank 3, local rank 3, ddp group rank 1/2global rank 2, local rank 2, ddp group rank 1/2


global rank 0, local rank 0, ddp group rank 0/2DP USE NCCLDP USE NCCL


DP USE NCCL
 [2024-10-02 15:37:05] iteration       79/     200 | consumed samples:        22752 | elapsed time per iteration (ms): 3932.3 | learning rate: 1.975000E-05 | global batch size:   288 | lm loss: 5.353940E+00 | loss scale: 1.0 | grad norm: 1.381 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2


global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:37:09] iteration       80/     200 | consumed samples:        23040 | elapsed time per iteration (ms): 3926.0 | learning rate: 2.000000E-05 | global batch size:   288 | lm loss: 5.220437E+00 | loss scale: 1.0 | grad norm: 1.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:37:13] iteration       81/     200 | consumed samples:        23328 | elapsed time per iteration (ms): 3920.0 | learning rate: 2.025000E-05 | global batch size:   288 | lm loss: 5.404001E+00 | loss scale: 1.0 | grad norm: 1.291 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:37:17] iteration       82/     200 | consumed samples:        23616 | elapsed time per iteration (ms): 3930.6 | learning rate: 2.050000E-05 | global batch size:   288 | lm loss: 5.339011E+00 | loss scale: 1.0 | grad norm: 1.957 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:37:21] iteration       83/     200 | consumed samples:        23904 | elapsed time per iteration (ms): 3926.0 | learning rate: 2.075000E-05 | global batch size:   288 | lm loss: 5.172428E+00 | loss scale: 1.0 | grad norm: 1.530 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2


global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:37:25] iteration       84/     200 | consumed samples:        24192 | elapsed time per iteration (ms): 3925.7 | learning rate: 2.100000E-05 | global batch size:   288 | lm loss: 5.237123E+00 | loss scale: 1.0 | grad norm: 1.548 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 0, local rank 0, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:37:29] iteration       85/     200 | consumed samples:        24480 | elapsed time per iteration (ms): 3926.0 | learning rate: 2.125000E-05 | global batch size:   288 | lm loss: 5.188566E+00 | loss scale: 1.0 | grad norm: 1.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:37:33] iteration       86/     200 | consumed samples:        24768 | elapsed time per iteration (ms): 3925.7 | learning rate: 2.150000E-05 | global batch size:   288 | lm loss: 5.176205E+00 | loss scale: 1.0 | grad norm: 1.347 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 6, local rank 6, ddp group rank 1/2

global rank 4, local rank 4, ddp group rank 0/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:37:37] iteration       87/     200 | consumed samples:        25056 | elapsed time per iteration (ms): 3923.4 | learning rate: 2.175000E-05 | global batch size:   288 | lm loss: 5.216204E+00 | loss scale: 1.0 | grad norm: 1.388 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
TP USE NCCLDP USE NCCL

global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 4, local rank 4, ddp group rank 0/2global rank 6, local rank 6, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:37:41] iteration       88/     200 | consumed samples:        25344 | elapsed time per iteration (ms): 3932.0 | learning rate: 2.200000E-05 | global batch size:   288 | lm loss: 5.098079E+00 | loss scale: 1.0 | grad norm: 1.308 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:37:45] iteration       89/     200 | consumed samples:        25632 | elapsed time per iteration (ms): 3925.1 | learning rate: 2.225000E-05 | global batch size:   288 | lm loss: 5.199943E+00 | loss scale: 1.0 | grad norm: 1.295 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2


global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:37:49] iteration       90/     200 | consumed samples:        25920 | elapsed time per iteration (ms): 3925.2 | learning rate: 2.250000E-05 | global batch size:   288 | lm loss: 5.111846E+00 | loss scale: 1.0 | grad norm: 1.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:37:53] iteration       91/     200 | consumed samples:        26208 | elapsed time per iteration (ms): 3926.6 | learning rate: 2.275000E-05 | global batch size:   288 | lm loss: 5.197406E+00 | loss scale: 1.0 | grad norm: 1.576 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:37:56] iteration       92/     200 | consumed samples:        26496 | elapsed time per iteration (ms): 3930.0 | learning rate: 2.300000E-05 | global batch size:   288 | lm loss: 5.018854E+00 | loss scale: 1.0 | grad norm: 1.351 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:38:00] iteration       93/     200 | consumed samples:        26784 | elapsed time per iteration (ms): 3918.6 | learning rate: 2.325000E-05 | global batch size:   288 | lm loss: 4.995389E+00 | loss scale: 1.0 | grad norm: 1.869 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 5, local rank 5, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:38:04] iteration       94/     200 | consumed samples:        27072 | elapsed time per iteration (ms): 3923.4 | learning rate: 2.350000E-05 | global batch size:   288 | lm loss: 5.030073E+00 | loss scale: 1.0 | grad norm: 1.536 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:38:08] iteration       95/     200 | consumed samples:        27360 | elapsed time per iteration (ms): 3934.6 | learning rate: 2.375000E-05 | global batch size:   288 | lm loss: 5.056540E+00 | loss scale: 1.0 | grad norm: 1.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2


global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:38:12] iteration       96/     200 | consumed samples:        27648 | elapsed time per iteration (ms): 3923.6 | learning rate: 2.400000E-05 | global batch size:   288 | lm loss: 4.976461E+00 | loss scale: 1.0 | grad norm: 1.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:38:16] iteration       97/     200 | consumed samples:        27936 | elapsed time per iteration (ms): 3919.5 | learning rate: 2.425000E-05 | global batch size:   288 | lm loss: 5.108166E+00 | loss scale: 1.0 | grad norm: 1.550 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2


global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:38:20] iteration       98/     200 | consumed samples:        28224 | elapsed time per iteration (ms): 3924.0 | learning rate: 2.450000E-05 | global batch size:   288 | lm loss: 5.035219E+00 | loss scale: 1.0 | grad norm: 1.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2


global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2


global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:38:24] iteration       99/     200 | consumed samples:        28512 | elapsed time per iteration (ms): 3924.5 | learning rate: 2.475000E-05 | global batch size:   288 | lm loss: 4.990711E+00 | loss scale: 1.0 | grad norm: 1.254 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2


global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:38:28] iteration      100/     200 | consumed samples:        28800 | elapsed time per iteration (ms): 3918.5 | learning rate: 2.500000E-05 | global batch size:   288 | lm loss: 4.875418E+00 | loss scale: 1.0 | grad norm: 1.646 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:38:32] iteration      101/     200 | consumed samples:        29088 | elapsed time per iteration (ms): 3918.0 | learning rate: 2.525000E-05 | global batch size:   288 | lm loss: 4.889658E+00 | loss scale: 1.0 | grad norm: 1.643 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2



global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2


global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2


global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 6, local rank 6, ddp group rank 1/2global rank 4, local rank 4, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:38:36] iteration      102/     200 | consumed samples:        29376 | elapsed time per iteration (ms): 3921.2 | learning rate: 2.550000E-05 | global batch size:   288 | lm loss: 4.790158E+00 | loss scale: 1.0 | grad norm: 1.180 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2


global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 1, local rank 1, ddp group rank 0/2

global rank 3, local rank 3, ddp group rank 1/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:38:40] iteration      103/     200 | consumed samples:        29664 | elapsed time per iteration (ms): 3924.9 | learning rate: 2.575000E-05 | global batch size:   288 | lm loss: 4.840342E+00 | loss scale: 1.0 | grad norm: 1.538 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2global rank 1, local rank 1, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:38:44] iteration      104/     200 | consumed samples:        29952 | elapsed time per iteration (ms): 3921.7 | learning rate: 2.600000E-05 | global batch size:   288 | lm loss: 4.849878E+00 | loss scale: 1.0 | grad norm: 1.296 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:38:47] iteration      105/     200 | consumed samples:        30240 | elapsed time per iteration (ms): 3924.2 | learning rate: 2.625000E-05 | global batch size:   288 | lm loss: 4.917206E+00 | loss scale: 1.0 | grad norm: 1.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:38:51] iteration      106/     200 | consumed samples:        30528 | elapsed time per iteration (ms): 3924.0 | learning rate: 2.650000E-05 | global batch size:   288 | lm loss: 4.870014E+00 | loss scale: 1.0 | grad norm: 1.302 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:38:55] iteration      107/     200 | consumed samples:        30816 | elapsed time per iteration (ms): 3930.4 | learning rate: 2.675000E-05 | global batch size:   288 | lm loss: 4.787824E+00 | loss scale: 1.0 | grad norm: 1.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 7, local rank 7, ddp group rank 1/2

global rank 5, local rank 5, ddp group rank 0/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2TP USE NCCL

DP USE NCCLglobal rank 1, local rank 1, ddp group rank 0/2

DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:38:59] iteration      108/     200 | consumed samples:        31104 | elapsed time per iteration (ms): 3923.5 | learning rate: 2.700000E-05 | global batch size:   288 | lm loss: 4.818059E+00 | loss scale: 1.0 | grad norm: 1.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:39:03] iteration      109/     200 | consumed samples:        31392 | elapsed time per iteration (ms): 3929.7 | learning rate: 2.725000E-05 | global batch size:   288 | lm loss: 4.820296E+00 | loss scale: 1.0 | grad norm: 1.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:39:07] iteration      110/     200 | consumed samples:        31680 | elapsed time per iteration (ms): 3922.9 | learning rate: 2.750000E-05 | global batch size:   288 | lm loss: 4.812537E+00 | loss scale: 1.0 | grad norm: 1.748 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2


global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCLTP USE NCCL

global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:39:11] iteration      111/     200 | consumed samples:        31968 | elapsed time per iteration (ms): 3921.9 | learning rate: 2.775000E-05 | global batch size:   288 | lm loss: 4.700621E+00 | loss scale: 1.0 | grad norm: 1.364 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:39:15] iteration      112/     200 | consumed samples:        32256 | elapsed time per iteration (ms): 3924.7 | learning rate: 2.800000E-05 | global batch size:   288 | lm loss: 4.730004E+00 | loss scale: 1.0 | grad norm: 1.829 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:39:19] iteration      113/     200 | consumed samples:        32544 | elapsed time per iteration (ms): 3927.2 | learning rate: 2.825000E-05 | global batch size:   288 | lm loss: 4.675940E+00 | loss scale: 1.0 | grad norm: 1.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCLTP USE NCCL

global rank 5, local rank 5, ddp group rank 0/2global rank 6, local rank 6, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:39:23] iteration      114/     200 | consumed samples:        32832 | elapsed time per iteration (ms): 3926.0 | learning rate: 2.850000E-05 | global batch size:   288 | lm loss: 4.709419E+00 | loss scale: 1.0 | grad norm: 1.344 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:39:27] iteration      115/     200 | consumed samples:        33120 | elapsed time per iteration (ms): 3918.5 | learning rate: 2.875000E-05 | global batch size:   288 | lm loss: 4.698572E+00 | loss scale: 1.0 | grad norm: 1.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 5, local rank 5, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:39:31] iteration      116/     200 | consumed samples:        33408 | elapsed time per iteration (ms): 3925.4 | learning rate: 2.900000E-05 | global batch size:   288 | lm loss: 4.703171E+00 | loss scale: 1.0 | grad norm: 1.118 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 4, local rank 4, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:39:35] iteration      117/     200 | consumed samples:        33696 | elapsed time per iteration (ms): 3926.5 | learning rate: 2.925000E-05 | global batch size:   288 | lm loss: 4.556504E+00 | loss scale: 1.0 | grad norm: 1.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:39:39] iteration      118/     200 | consumed samples:        33984 | elapsed time per iteration (ms): 3931.4 | learning rate: 2.950000E-05 | global batch size:   288 | lm loss: 4.618665E+00 | loss scale: 1.0 | grad norm: 1.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:39:42] iteration      119/     200 | consumed samples:        34272 | elapsed time per iteration (ms): 3924.8 | learning rate: 2.975000E-05 | global batch size:   288 | lm loss: 4.599573E+00 | loss scale: 1.0 | grad norm: 1.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2


global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2


TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:39:46] iteration      120/     200 | consumed samples:        34560 | elapsed time per iteration (ms): 3927.8 | learning rate: 3.000000E-05 | global batch size:   288 | lm loss: 4.631994E+00 | loss scale: 1.0 | grad norm: 1.552 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:39:50] iteration      121/     200 | consumed samples:        34848 | elapsed time per iteration (ms): 3928.5 | learning rate: 3.025000E-05 | global batch size:   288 | lm loss: 4.613649E+00 | loss scale: 1.0 | grad norm: 1.372 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:39:54] iteration      122/     200 | consumed samples:        35136 | elapsed time per iteration (ms): 3929.3 | learning rate: 3.050000E-05 | global batch size:   288 | lm loss: 4.523847E+00 | loss scale: 1.0 | grad norm: 1.741 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 0, local rank 0, ddp group rank 0/2

global rank 2, local rank 2, ddp group rank 1/2DP USE NCCL

DP USE NCCL
 [2024-10-02 15:39:58] iteration      123/     200 | consumed samples:        35424 | elapsed time per iteration (ms): 3922.9 | learning rate: 3.075000E-05 | global batch size:   288 | lm loss: 4.648630E+00 | loss scale: 1.0 | grad norm: 1.266 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2


global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:40:02] iteration      124/     200 | consumed samples:        35712 | elapsed time per iteration (ms): 3924.0 | learning rate: 3.100000E-05 | global batch size:   288 | lm loss: 4.571566E+00 | loss scale: 1.0 | grad norm: 1.359 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:40:06] iteration      125/     200 | consumed samples:        36000 | elapsed time per iteration (ms): 3920.3 | learning rate: 3.125000E-05 | global batch size:   288 | lm loss: 4.498240E+00 | loss scale: 1.0 | grad norm: 1.198 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2


global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:40:10] iteration      126/     200 | consumed samples:        36288 | elapsed time per iteration (ms): 3928.1 | learning rate: 3.150000E-05 | global batch size:   288 | lm loss: 4.390650E+00 | loss scale: 1.0 | grad norm: 1.659 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:40:14] iteration      127/     200 | consumed samples:        36576 | elapsed time per iteration (ms): 3927.6 | learning rate: 3.175000E-05 | global batch size:   288 | lm loss: 4.618145E+00 | loss scale: 1.0 | grad norm: 1.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2


global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:40:18] iteration      128/     200 | consumed samples:        36864 | elapsed time per iteration (ms): 3931.0 | learning rate: 3.200000E-05 | global batch size:   288 | lm loss: 4.446513E+00 | loss scale: 1.0 | grad norm: 1.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2


TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:40:22] iteration      129/     200 | consumed samples:        37152 | elapsed time per iteration (ms): 3928.6 | learning rate: 3.225000E-05 | global batch size:   288 | lm loss: 4.491488E+00 | loss scale: 1.0 | grad norm: 1.530 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:40:26] iteration      130/     200 | consumed samples:        37440 | elapsed time per iteration (ms): 3925.3 | learning rate: 3.250000E-05 | global batch size:   288 | lm loss: 4.518919E+00 | loss scale: 1.0 | grad norm: 1.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:40:30] iteration      131/     200 | consumed samples:        37728 | elapsed time per iteration (ms): 3926.5 | learning rate: 3.275000E-05 | global batch size:   288 | lm loss: 4.469779E+00 | loss scale: 1.0 | grad norm: 2.239 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:40:33] iteration      132/     200 | consumed samples:        38016 | elapsed time per iteration (ms): 3927.9 | learning rate: 3.300000E-05 | global batch size:   288 | lm loss: 4.443451E+00 | loss scale: 1.0 | grad norm: 1.532 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:40:37] iteration      133/     200 | consumed samples:        38304 | elapsed time per iteration (ms): 3925.1 | learning rate: 3.325000E-05 | global batch size:   288 | lm loss: 4.456006E+00 | loss scale: 1.0 | grad norm: 2.041 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:40:41] iteration      134/     200 | consumed samples:        38592 | elapsed time per iteration (ms): 3923.1 | learning rate: 3.350000E-05 | global batch size:   288 | lm loss: 4.508679E+00 | loss scale: 1.0 | grad norm: 1.292 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2


global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2


global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCLTP USE NCCL

global rank 5, local rank 5, ddp group rank 0/2global rank 6, local rank 6, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:40:45] iteration      135/     200 | consumed samples:        38880 | elapsed time per iteration (ms): 3924.7 | learning rate: 3.375000E-05 | global batch size:   288 | lm loss: 4.393364E+00 | loss scale: 1.0 | grad norm: 2.173 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
TP USE NCCLDP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:40:49] iteration      136/     200 | consumed samples:        39168 | elapsed time per iteration (ms): 3920.6 | learning rate: 3.400000E-05 | global batch size:   288 | lm loss: 4.393409E+00 | loss scale: 1.0 | grad norm: 1.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 4, local rank 4, ddp group rank 0/2global rank 7, local rank 7, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:40:53] iteration      137/     200 | consumed samples:        39456 | elapsed time per iteration (ms): 3935.0 | learning rate: 3.425000E-05 | global batch size:   288 | lm loss: 4.349100E+00 | loss scale: 1.0 | grad norm: 1.599 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 5, local rank 5, ddp group rank 0/2

global rank 7, local rank 7, ddp group rank 1/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:40:57] iteration      138/     200 | consumed samples:        39744 | elapsed time per iteration (ms): 3922.4 | learning rate: 3.450000E-05 | global batch size:   288 | lm loss: 4.492240E+00 | loss scale: 1.0 | grad norm: 1.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:41:01] iteration      139/     200 | consumed samples:        40032 | elapsed time per iteration (ms): 3928.9 | learning rate: 3.475000E-05 | global batch size:   288 | lm loss: 4.443648E+00 | loss scale: 1.0 | grad norm: 1.118 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:41:05] iteration      140/     200 | consumed samples:        40320 | elapsed time per iteration (ms): 3925.1 | learning rate: 3.500000E-05 | global batch size:   288 | lm loss: 4.463270E+00 | loss scale: 1.0 | grad norm: 1.769 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:41:09] iteration      141/     200 | consumed samples:        40608 | elapsed time per iteration (ms): 3927.3 | learning rate: 3.525000E-05 | global batch size:   288 | lm loss: 4.446476E+00 | loss scale: 1.0 | grad norm: 1.551 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
TP USE NCCLDP USE NCCL

global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:41:13] iteration      142/     200 | consumed samples:        40896 | elapsed time per iteration (ms): 3930.2 | learning rate: 3.550000E-05 | global batch size:   288 | lm loss: 4.447890E+00 | loss scale: 1.0 | grad norm: 1.248 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 1, local rank 1, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:41:17] iteration      143/     200 | consumed samples:        41184 | elapsed time per iteration (ms): 3925.6 | learning rate: 3.575000E-05 | global batch size:   288 | lm loss: 4.284264E+00 | loss scale: 1.0 | grad norm: 1.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2


global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:41:21] iteration      144/     200 | consumed samples:        41472 | elapsed time per iteration (ms): 3922.4 | learning rate: 3.600000E-05 | global batch size:   288 | lm loss: 4.226960E+00 | loss scale: 1.0 | grad norm: 1.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:41:25] iteration      145/     200 | consumed samples:        41760 | elapsed time per iteration (ms): 3924.3 | learning rate: 3.625000E-05 | global batch size:   288 | lm loss: 4.389256E+00 | loss scale: 1.0 | grad norm: 1.969 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:41:28] iteration      146/     200 | consumed samples:        42048 | elapsed time per iteration (ms): 3921.3 | learning rate: 3.650000E-05 | global batch size:   288 | lm loss: 4.356191E+00 | loss scale: 1.0 | grad norm: 1.455 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCLTP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:41:32] iteration      147/     200 | consumed samples:        42336 | elapsed time per iteration (ms): 3926.7 | learning rate: 3.675000E-05 | global batch size:   288 | lm loss: 4.293620E+00 | loss scale: 1.0 | grad norm: 1.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:41:36] iteration      148/     200 | consumed samples:        42624 | elapsed time per iteration (ms): 3930.8 | learning rate: 3.700000E-05 | global batch size:   288 | lm loss: 4.207398E+00 | loss scale: 1.0 | grad norm: 1.446 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2


global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 4, local rank 4, ddp group rank 0/2global rank 7, local rank 7, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 2, local rank 2, ddp group rank 1/2

global rank 3, local rank 3, ddp group rank 1/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:41:40] iteration      149/     200 | consumed samples:        42912 | elapsed time per iteration (ms): 3925.7 | learning rate: 3.725000E-05 | global batch size:   288 | lm loss: 4.354743E+00 | loss scale: 1.0 | grad norm: 1.673 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 3, local rank 3, ddp group rank 1/2

global rank 1, local rank 1, ddp group rank 0/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:41:44] iteration      150/     200 | consumed samples:        43200 | elapsed time per iteration (ms): 3921.5 | learning rate: 3.750000E-05 | global batch size:   288 | lm loss: 4.213952E+00 | loss scale: 1.0 | grad norm: 1.640 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2


global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:41:48] iteration      151/     200 | consumed samples:        43488 | elapsed time per iteration (ms): 3927.5 | learning rate: 3.775000E-05 | global batch size:   288 | lm loss: 4.275403E+00 | loss scale: 1.0 | grad norm: 1.135 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:41:52] iteration      152/     200 | consumed samples:        43776 | elapsed time per iteration (ms): 3925.8 | learning rate: 3.800000E-05 | global batch size:   288 | lm loss: 4.251925E+00 | loss scale: 1.0 | grad norm: 1.530 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:41:56] iteration      153/     200 | consumed samples:        44064 | elapsed time per iteration (ms): 3929.5 | learning rate: 3.825000E-05 | global batch size:   288 | lm loss: 4.176833E+00 | loss scale: 1.0 | grad norm: 1.311 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:42:00] iteration      154/     200 | consumed samples:        44352 | elapsed time per iteration (ms): 3925.0 | learning rate: 3.850000E-05 | global batch size:   288 | lm loss: 4.230537E+00 | loss scale: 1.0 | grad norm: 1.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCLTP USE NCCL

global rank 5, local rank 5, ddp group rank 0/2global rank 6, local rank 6, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:42:04] iteration      155/     200 | consumed samples:        44640 | elapsed time per iteration (ms): 3923.7 | learning rate: 3.875000E-05 | global batch size:   288 | lm loss: 4.164176E+00 | loss scale: 1.0 | grad norm: 1.605 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:42:08] iteration      156/     200 | consumed samples:        44928 | elapsed time per iteration (ms): 3927.5 | learning rate: 3.900000E-05 | global batch size:   288 | lm loss: 4.111667E+00 | loss scale: 1.0 | grad norm: 1.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2


global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:42:12] iteration      157/     200 | consumed samples:        45216 | elapsed time per iteration (ms): 3927.7 | learning rate: 3.925000E-05 | global batch size:   288 | lm loss: 4.228560E+00 | loss scale: 1.0 | grad norm: 1.335 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:42:16] iteration      158/     200 | consumed samples:        45504 | elapsed time per iteration (ms): 3928.6 | learning rate: 3.950000E-05 | global batch size:   288 | lm loss: 4.193139E+00 | loss scale: 1.0 | grad norm: 1.680 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2


global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:42:19] iteration      159/     200 | consumed samples:        45792 | elapsed time per iteration (ms): 3918.3 | learning rate: 3.975000E-05 | global batch size:   288 | lm loss: 4.118892E+00 | loss scale: 1.0 | grad norm: 1.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2


global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:42:23] iteration      160/     200 | consumed samples:        46080 | elapsed time per iteration (ms): 3915.6 | learning rate: 4.000000E-05 | global batch size:   288 | lm loss: 4.095117E+00 | loss scale: 1.0 | grad norm: 1.883 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:42:27] iteration      161/     200 | consumed samples:        46368 | elapsed time per iteration (ms): 3926.3 | learning rate: 4.025000E-05 | global batch size:   288 | lm loss: 4.137789E+00 | loss scale: 1.0 | grad norm: 1.370 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2


global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
TP USE NCCLDP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:42:31] iteration      162/     200 | consumed samples:        46656 | elapsed time per iteration (ms): 3925.2 | learning rate: 4.050000E-05 | global batch size:   288 | lm loss: 4.123133E+00 | loss scale: 1.0 | grad norm: 1.659 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2


global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:42:35] iteration      163/     200 | consumed samples:        46944 | elapsed time per iteration (ms): 3925.0 | learning rate: 4.075000E-05 | global batch size:   288 | lm loss: 4.048588E+00 | loss scale: 1.0 | grad norm: 1.340 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2


global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2



TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:42:39] iteration      164/     200 | consumed samples:        47232 | elapsed time per iteration (ms): 3920.5 | learning rate: 4.100000E-05 | global batch size:   288 | lm loss: 4.182728E+00 | loss scale: 1.0 | grad norm: 1.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2


global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2



global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2


TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 0, local rank 0, ddp group rank 0/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:42:43] iteration      165/     200 | consumed samples:        47520 | elapsed time per iteration (ms): 3922.7 | learning rate: 4.125000E-05 | global batch size:   288 | lm loss: 4.109974E+00 | loss scale: 1.0 | grad norm: 1.167 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 4, local rank 4, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
TP USE NCCLDP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:42:47] iteration      166/     200 | consumed samples:        47808 | elapsed time per iteration (ms): 3926.5 | learning rate: 4.150000E-05 | global batch size:   288 | lm loss: 4.121336E+00 | loss scale: 1.0 | grad norm: 1.147 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2global rank 1, local rank 1, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:42:51] iteration      167/     200 | consumed samples:        48096 | elapsed time per iteration (ms): 3923.8 | learning rate: 4.175000E-05 | global batch size:   288 | lm loss: 4.178672E+00 | loss scale: 1.0 | grad norm: 1.808 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2


global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2


global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 0, local rank 0, ddp group rank 0/2global rank 2, local rank 2, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:42:55] iteration      168/     200 | consumed samples:        48384 | elapsed time per iteration (ms): 3920.0 | learning rate: 4.200000E-05 | global batch size:   288 | lm loss: 4.105105E+00 | loss scale: 1.0 | grad norm: 1.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2


global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:42:59] iteration      169/     200 | consumed samples:        48672 | elapsed time per iteration (ms): 3927.2 | learning rate: 4.225000E-05 | global batch size:   288 | lm loss: 4.062643E+00 | loss scale: 1.0 | grad norm: 1.789 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:43:03] iteration      170/     200 | consumed samples:        48960 | elapsed time per iteration (ms): 3925.1 | learning rate: 4.250000E-05 | global batch size:   288 | lm loss: 4.120533E+00 | loss scale: 1.0 | grad norm: 1.185 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 6, local rank 6, ddp group rank 1/2global rank 4, local rank 4, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

 [2024-10-02 15:43:07] iteration      171/     200 | consumed samples:        49248 | elapsed time per iteration (ms): 3921.7 | learning rate: 4.275000E-05 | global batch size:   288 | lm loss: 4.052972E+00 | loss scale: 1.0 | grad norm: 1.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2


global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 4, local rank 4, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:43:11] iteration      172/     200 | consumed samples:        49536 | elapsed time per iteration (ms): 3926.1 | learning rate: 4.300000E-05 | global batch size:   288 | lm loss: 4.012832E+00 | loss scale: 1.0 | grad norm: 1.460 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2


global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:43:14] iteration      173/     200 | consumed samples:        49824 | elapsed time per iteration (ms): 3928.8 | learning rate: 4.325000E-05 | global batch size:   288 | lm loss: 3.980909E+00 | loss scale: 1.0 | grad norm: 1.842 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2


global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:43:18] iteration      174/     200 | consumed samples:        50112 | elapsed time per iteration (ms): 3928.8 | learning rate: 4.350000E-05 | global batch size:   288 | lm loss: 3.978157E+00 | loss scale: 1.0 | grad norm: 1.256 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:43:22] iteration      175/     200 | consumed samples:        50400 | elapsed time per iteration (ms): 3927.8 | learning rate: 4.375000E-05 | global batch size:   288 | lm loss: 4.014110E+00 | loss scale: 1.0 | grad norm: 1.297 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2


global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2


global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2


global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCLTP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:43:26] iteration      176/     200 | consumed samples:        50688 | elapsed time per iteration (ms): 3919.8 | learning rate: 4.400000E-05 | global batch size:   288 | lm loss: 4.011066E+00 | loss scale: 1.0 | grad norm: 1.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2global rank 1, local rank 1, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:43:30] iteration      177/     200 | consumed samples:        50976 | elapsed time per iteration (ms): 3924.8 | learning rate: 4.425000E-05 | global batch size:   288 | lm loss: 3.977738E+00 | loss scale: 1.0 | grad norm: 1.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:43:34] iteration      178/     200 | consumed samples:        51264 | elapsed time per iteration (ms): 3922.1 | learning rate: 4.450000E-05 | global batch size:   288 | lm loss: 4.025400E+00 | loss scale: 1.0 | grad norm: 1.290 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 5, local rank 5, ddp group rank 0/2global rank 7, local rank 7, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 1, local rank 1, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:43:38] iteration      179/     200 | consumed samples:        51552 | elapsed time per iteration (ms): 3929.4 | learning rate: 4.475000E-05 | global batch size:   288 | lm loss: 3.928231E+00 | loss scale: 1.0 | grad norm: 1.263 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:43:42] iteration      180/     200 | consumed samples:        51840 | elapsed time per iteration (ms): 3927.1 | learning rate: 4.500000E-05 | global batch size:   288 | lm loss: 3.975663E+00 | loss scale: 1.0 | grad norm: 2.181 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:43:46] iteration      181/     200 | consumed samples:        52128 | elapsed time per iteration (ms): 3921.9 | learning rate: 4.525000E-05 | global batch size:   288 | lm loss: 3.967279E+00 | loss scale: 1.0 | grad norm: 1.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:43:50] iteration      182/     200 | consumed samples:        52416 | elapsed time per iteration (ms): 3922.6 | learning rate: 4.550000E-05 | global batch size:   288 | lm loss: 3.970668E+00 | loss scale: 1.0 | grad norm: 1.777 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:43:54] iteration      183/     200 | consumed samples:        52704 | elapsed time per iteration (ms): 3924.0 | learning rate: 4.575000E-05 | global batch size:   288 | lm loss: 4.084272E+00 | loss scale: 1.0 | grad norm: 1.161 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2


global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:43:58] iteration      184/     200 | consumed samples:        52992 | elapsed time per iteration (ms): 3922.8 | learning rate: 4.600000E-05 | global batch size:   288 | lm loss: 4.007906E+00 | loss scale: 1.0 | grad norm: 3.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:44:02] iteration      185/     200 | consumed samples:        53280 | elapsed time per iteration (ms): 3918.0 | learning rate: 4.625000E-05 | global batch size:   288 | lm loss: 3.956139E+00 | loss scale: 1.0 | grad norm: 1.958 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:44:05] iteration      186/     200 | consumed samples:        53568 | elapsed time per iteration (ms): 3924.3 | learning rate: 4.650000E-05 | global batch size:   288 | lm loss: 3.921301E+00 | loss scale: 1.0 | grad norm: 2.104 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:44:09] iteration      187/     200 | consumed samples:        53856 | elapsed time per iteration (ms): 3926.8 | learning rate: 4.675000E-05 | global batch size:   288 | lm loss: 4.036071E+00 | loss scale: 1.0 | grad norm: 1.577 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2


global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:44:13] iteration      188/     200 | consumed samples:        54144 | elapsed time per iteration (ms): 3925.5 | learning rate: 4.700000E-05 | global batch size:   288 | lm loss: 3.967073E+00 | loss scale: 1.0 | grad norm: 1.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2


global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:44:17] iteration      189/     200 | consumed samples:        54432 | elapsed time per iteration (ms): 3931.6 | learning rate: 4.725000E-05 | global batch size:   288 | lm loss: 3.995003E+00 | loss scale: 1.0 | grad norm: 1.810 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
global rank 3, local rank 3, ddp group rank 1/2
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
DP USE NCCL
DP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:44:21] iteration      190/     200 | consumed samples:        54720 | elapsed time per iteration (ms): 3924.5 | learning rate: 4.750000E-05 | global batch size:   288 | lm loss: 3.907914E+00 | loss scale: 1.0 | grad norm: 1.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:44:25] iteration      191/     200 | consumed samples:        55008 | elapsed time per iteration (ms): 3925.7 | learning rate: 4.775000E-05 | global batch size:   288 | lm loss: 3.774665E+00 | loss scale: 1.0 | grad norm: 1.261 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 3, local rank 3, ddp group rank 1/2

global rank 1, local rank 1, ddp group rank 0/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:44:29] iteration      192/     200 | consumed samples:        55296 | elapsed time per iteration (ms): 3923.1 | learning rate: 4.800000E-05 | global batch size:   288 | lm loss: 3.924486E+00 | loss scale: 1.0 | grad norm: 1.808 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2


global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2


global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:44:33] iteration      193/     200 | consumed samples:        55584 | elapsed time per iteration (ms): 3925.0 | learning rate: 4.825000E-05 | global batch size:   288 | lm loss: 3.814167E+00 | loss scale: 1.0 | grad norm: 1.365 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2


global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
TP USE NCCLDP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:44:37] iteration      194/     200 | consumed samples:        55872 | elapsed time per iteration (ms): 3923.8 | learning rate: 4.850000E-05 | global batch size:   288 | lm loss: 3.869812E+00 | loss scale: 1.0 | grad norm: 1.922 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2


global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2


TP USE NCCLTP USE NCCL

global rank 6, local rank 6, ddp group rank 1/2global rank 5, local rank 5, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:44:41] iteration      195/     200 | consumed samples:        56160 | elapsed time per iteration (ms): 3925.0 | learning rate: 4.875000E-05 | global batch size:   288 | lm loss: 3.774476E+00 | loss scale: 1.0 | grad norm: 1.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2


global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:44:45] iteration      196/     200 | consumed samples:        56448 | elapsed time per iteration (ms): 3922.4 | learning rate: 4.900000E-05 | global batch size:   288 | lm loss: 3.794249E+00 | loss scale: 1.0 | grad norm: 1.224 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 1, local rank 1, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:44:49] iteration      197/     200 | consumed samples:        56736 | elapsed time per iteration (ms): 3926.3 | learning rate: 4.925000E-05 | global batch size:   288 | lm loss: 3.976551E+00 | loss scale: 1.0 | grad norm: 1.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:44:53] iteration      198/     200 | consumed samples:        57024 | elapsed time per iteration (ms): 3924.1 | learning rate: 4.950000E-05 | global batch size:   288 | lm loss: 3.797987E+00 | loss scale: 1.0 | grad norm: 1.284 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:44:56] iteration      199/     200 | consumed samples:        57312 | elapsed time per iteration (ms): 3925.4 | learning rate: 4.975000E-05 | global batch size:   288 | lm loss: 3.823698E+00 | loss scale: 1.0 | grad norm: 0.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:45:00] iteration      200/     200 | consumed samples:        57600 | elapsed time per iteration (ms): 3929.7 | learning rate: 5.000000E-05 | global batch size:   288 | lm loss: 3.938845E+00 | loss scale: 1.0 | grad norm: 1.766 | number of skipped iterations:   0 | number of nan iterations:   0 |
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_inference /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 55 
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING] due to: 
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/kn/cknl7dfvzapwvdm23xe52hkik7t4lm2yb3tkmbvrsixjtt565otq.py", line 67, in <module>
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/3/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:45:01,503] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_inference /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 55 
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING] due to: 
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/tx/ctxebgbejg6ugj3rmxl6hpf5qhgt7s6imqqokaj5fjpxjookkzpm.py", line 67, in <module>
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/1/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:45:01,522] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_inference /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 55 
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING] due to: 
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/mo/cmora7qoruvc65kpgm3hytvsjmd7z7txf23g3uiszei2hctxs6ox.py", line 67, in <module>
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/2/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:45:01,529] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_inference /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 55 
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING] due to: 
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/mf/cmfqy62vr5rs4ugrvwifxfnb4kuics5r3qchmxtadblruc5n3cfx.py", line 67, in <module>
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/0/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:45:01,539] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_inference /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 55 
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING] due to: 
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/55/c55pn7jutcuzydj6tl6dyrs3bbmyadjmhzjdl3k5umyh37qwkft7.py", line 67, in <module>
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/7/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:45:02,227] torch._dynamo.convert_frame: [WARNING] 
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_inference /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 55 
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING] due to: 
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/bu/cbuo4jplcyug7ksc6hctyqwolo4p4cenksqiclqtcuryz3v7ocin.py", line 67, in <module>
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/5/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:45:02,243] torch._dynamo.convert_frame: [WARNING] 
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_inference /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 55 
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING] due to: 
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/57/c57pxgyns532elri3bezdbgb4mcttu63lx5zfiva2xdlbk7tkn2z.py", line 67, in <module>
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/6/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:45:02,270] torch._dynamo.convert_frame: [WARNING] 
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_inference /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 55 
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING] due to: 
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/sp/cspxktkf5hjwsrz5nnncv7bruyvplz4beawnth72rsxj6dl2stzu.py", line 67, in <module>
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/4/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:45:02,325] torch._dynamo.convert_frame: [WARNING] 
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
(min, max) time across ranks (ms):
    evaluate .......................................: (14659.38, 14822.45)
-----------------------------------------------------------------------------------------------
 validation loss at iteration 200 | lm loss value: 3.836122E+00 | lm loss PPL: 4.634540E+01 | 
-----------------------------------------------------------------------------------------------
[after training is done] datetime: 2024-10-02 15:45:15 
saving checkpoint at iteration     200 to /workspace/Megatron-LM/experiments/codeparrot-small in torch_dist format
  successfully saved checkpoint from iteration     200 to /workspace/Megatron-LM/experiments/codeparrot-small
Evaluating on 2880 samples
Evaluating iter 1/10
Evaluating iter 2/10
Evaluating iter 3/10
Evaluating iter 4/10
Evaluating iter 5/10
Evaluating iter 6/10
Evaluating iter 7/10
Evaluating iter 8/10
Evaluating iter 9/10
Evaluating iter 10/10
(min, max) time across ranks (ms):
    evaluate .......................................: (13265.48, 13427.38)
-----------------------------------------------------------------------------------------------------------------
 validation loss at iteration 200 on validation set | lm loss value: 3.815792E+00 | lm loss PPL: 4.541271E+01 | 
-----------------------------------------------------------------------------------------------------------------
Evaluating on 2880 samples
Evaluating iter 1/10
Evaluating iter 2/10
Evaluating iter 3/10
Evaluating iter 4/10
Evaluating iter 5/10
Evaluating iter 6/10
Evaluating iter 7/10
Evaluating iter 8/10
Evaluating iter 9/10
Evaluating iter 10/10
(min, max) time across ranks (ms):
    evaluate .......................................: (13257.85, 13420.68)
-----------------------------------------------------------------------------------------------------------
 validation loss at iteration 200 on test set | lm loss value: 3.886096E+00 | lm loss PPL: 4.872029E+01 | 
-----------------------------------------------------------------------------------------------------------
