/usr/local/lib/python3.10/dist-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2024-10-02 15:03:47,219] torch.distributed.run: [WARNING] 
[2024-10-02 15:03:47,219] torch.distributed.run: [WARNING] *****************************************
[2024-10-02 15:03:47,219] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-10-02 15:03:47,219] torch.distributed.run: [WARNING] *****************************************
using world size: 8, data-parallel size: 2, context-parallel size: 1, tensor-model-parallel size: 2, encoder-tensor-model-parallel size: 0, pipeline-model-parallel size: 2, encoder-pipeline-model-parallel size: 0
WARNING: Please specify --split when using --data-path. Using legacy default value of "969, 30, 1"
WARNING: Setting args.overlap_p2p_comm to False since non-interleaved schedule does not support overlapping p2p communication
using torch.float32 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. False
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  add_qkv_bias .................................... False
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  align_grad_reduce ............................... True
  align_param_gather .............................. False
  app_tag_run_name ................................ None
  app_tag_run_version ............................. 0.0.0
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... False
  apply_residual_connection_post_layernorm ........ False
  apply_rope_fusion ............................... True
  async_save ...................................... None
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  auto_detect_ckpt_format ......................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ False
  bias_dropout_fusion ............................. True
  bias_gelu_fusion ................................ True
  bias_swiglu_fusion .............................. True
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  calculate_per_token_loss ........................ False
  check_for_nan_in_loss_and_grad .................. True
  check_weight_hash_across_dp_replicas_interval ... None
  ckpt_assume_constant_structure .................. False
  ckpt_convert_format ............................. None
  ckpt_convert_save ............................... None
  ckpt_convert_update_legacy_dist_opt_format ...... False
  ckpt_format ..................................... torch_dist
  ckpt_fully_parallel_load ........................ False
  ckpt_fully_parallel_save ........................ True
  ckpt_fully_parallel_save_deprecated ............. False
  ckpt_step ....................................... None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  clone_scatter_output_in_embedding ............... True
  config_logger_dir ............................... 
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  context_parallel_size ........................... 1
  create_attention_mask_in_dataloader ............. True
  cross_entropy_loss_fusion ....................... False
  data_cache_path ................................. None
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 2
  data_path ....................................... ['codeparrot_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  ddp_average_in_collective ....................... False
  ddp_bucket_size ................................. None
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  decoupled_lr .................................... None
  decoupled_min_lr ................................ None
  decrease_batch_size_if_needed ................... False
  defer_embedding_wgrad_compute ................... False
  deprecated_use_mcore_models ..................... False
  deterministic_mode .............................. False
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  disable_straggler_on_startup .................... False
  dist_ckpt_format_deprecated ..................... None
  dist_ckpt_strictness ............................ assume_ok_unexpected
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  empty_unused_memory_level ....................... 0
  enable_ft_package ............................... False
  enable_one_logger ............................... True
  encoder_num_layers .............................. 12
  encoder_pipeline_model_parallel_size ............ 0
  encoder_seq_length .............................. 1024
  encoder_tensor_model_parallel_size .............. 0
  end_weight_decay ................................ 0.1
  eod_mask_loss ................................... False
  eval_interval ................................... 200
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  expert_model_parallel_size ...................... 1
  ffn_hidden_size ................................. 3072
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8 ............................................. None
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 72
  gradient_accumulation_fusion .................... True
  group_query_attention ........................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 768
  hybrid_attention_ratio .......................... 0.0
  hybrid_mlp_ratio ................................ 0.0
  hybrid_override_pattern ......................... None
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  kv_channels ..................................... 64
  lazy_mpu_init ................................... None
  load ............................................ /workspace/Megatron-LM/experiments/codeparrot-small
  local_rank ...................................... 0
  log_interval .................................... 1
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_progress .................................... False
  log_straggler ................................... False
  log_throughput .................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  logging_level ................................... None
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.0005
  lr_decay_iters .................................. 150000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. None
  lr_warmup_init .................................. 0.0
  lr_warmup_iters ................................. 2000
  lr_warmup_samples ............................... 0
  lr_wsd_decay_iters .............................. None
  lr_wsd_decay_samples ............................ None
  lr_wsd_decay_style .............................. exponential
  make_vocab_size_divisible_by .................... 128
  manual_gc ....................................... False
  manual_gc_eval .................................. True
  manual_gc_interval .............................. 0
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... True
  max_position_embeddings ......................... 1024
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... gpt2-merges.txt
  micro_batch_size ................................ 9
  min_loss_scale .................................. 1.0
  min_lr .......................................... 0.0
  mmap_bin_files .................................. True
  mock_data ....................................... False
  moe_aux_loss_coeff .............................. 0.0
  moe_expert_capacity_factor ...................... None
  moe_extended_tp ................................. False
  moe_grouped_gemm ................................ False
  moe_input_jitter_eps ............................ None
  moe_layer_recompute ............................. False
  moe_pad_expert_input_to_capacity ................ False
  moe_per_layer_logging ........................... False
  moe_router_load_balancing_type .................. aux_loss
  moe_router_pre_softmax .......................... False
  moe_router_topk ................................. 2
  moe_token_dispatcher_type ....................... allgather
  moe_token_drop_policy ........................... probs
  moe_z_loss_coeff ................................ None
  nccl_communicator_config_path ................... None
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  non_persistent_ckpt_type ........................ None
  non_persistent_global_ckpt_dir .................. None
  non_persistent_save_interval .................... None
  norm_epsilon .................................... 1e-05
  normalization ................................... LayerNorm
  num_attention_heads ............................. 12
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_dataset_builder_threads ..................... 1
  num_experts ..................................... None
  num_layers ...................................... 12
  num_layers_per_virtual_pipeline_stage ........... None
  num_query_groups ................................ 1
  num_workers ..................................... 2
  one_logger_async ................................ False
  one_logger_project .............................. megatron-lm
  one_logger_run_name ............................. None
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_grad_reduce ............................. False
  overlap_p2p_comm ................................ False
  overlap_param_gather ............................ False
  overlap_param_gather_with_optimizer_step ........ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.float32
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 2
  pipeline_model_parallel_split_rank .............. None
  position_embedding_type ......................... learned_absolute
  pretrained_checkpoint ........................... None
  profile ......................................... False
  profile_ranks ................................... [0]
  profile_step_end ................................ 12
  profile_step_start .............................. 10
  qk_layernorm .................................... False
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ None
  renormalize_blend_weights ....................... False
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_attention_gate ............................ 1
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_project_dir ............................... None
  retro_verify_neighbor_count ..................... True
  rotary_base ..................................... 10000
  rotary_interleaved .............................. False
  rotary_percent .................................. 1.0
  rotary_seq_len_interpolation_factor ............. None
  s3_cache_path ................................... None
  sample_rate ..................................... 1.0
  save ............................................ /workspace/Megatron-LM/experiments/codeparrot-small
  save_interval ................................... 2000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 1024
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  skip_train ...................................... False
  skipped_train_samples ........................... 0
  spec ............................................ None
  split ........................................... 969, 30, 1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.1
  straggler_ctrlr_port ............................ 65535
  straggler_minmax_count .......................... 1
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 2
  tensorboard_dir ................................. experiments/tensorboard
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  test_mode ....................................... False
  tiktoken_num_special_tokens ..................... 1000
  tiktoken_pattern ................................ None
  tiktoken_special_tokens ......................... None
  timing_log_level ................................ 0
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  tp_comm_bulk_dgrad .............................. True
  tp_comm_bulk_wgrad .............................. True
  tp_comm_overlap ................................. False
  tp_comm_overlap_ag .............................. True
  tp_comm_overlap_cfg ............................. None
  tp_comm_overlap_rs .............................. True
  tp_comm_overlap_rs_dgrad ........................ False
  tp_comm_split_ag ................................ True
  tp_comm_split_rs ................................ True
  train_data_path ................................. None
  train_iters ..................................... 200
  train_samples ................................... None
  train_sync_interval ............................. None
  transformer_impl ................................ transformer_engine
  transformer_pipeline_model_parallel_size ........ 2
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_cpu_initialization .......................... None
  use_dist_ckpt ................................... True
  use_dist_ckpt_deprecated ........................ False
  use_distributed_optimizer ....................... False
  use_flash_attn .................................. False
  use_legacy_models ............................... False
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  use_tp_pp_dp_mapping ............................ False
  valid_data_path ................................. None
  variable_seq_lengths ............................ False
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... gpt2-vocab.json
  vocab_size ...................................... None
  wandb_exp_name .................................. 
  wandb_project ................................... 
  wandb_save_dir .................................. 
  weight_decay .................................... 0.1
  weight_decay_incr_style ......................... constant
  wgrad_deferral_limit ............................ 0
  world_size ...................................... 8
  yaml_cfg ........................................ None
-------------------- end of arguments ---------------------
INFO:megatron.core.num_microbatches_calculator:setting number of microbatches to constant 4
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 175 dummy tokens (new size: 50432)
> initializing torch distributed ...
> setting tensorboard ...
WARNING: one_logger package is required to enable e2e metrics tracking. please go to https://confluence.nvidia.com/display/MLWFO/Package+Repositories for details to install it
> initialized tensor model parallel with size 2
> initialized pipeline model parallel with size 2
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/workspace/Megatron-LM/megatron/core/datasets'
make: Nothing to be done for 'default'.
make: Leaving directory '/workspace/Megatron-LM/megatron/core/datasets'
>>> done with dataset index builder. Compilation time: 0.039 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
>>> done with compiling and loading fused kernels. Compilation time: 0.778 seconds
Parameters: type(args): <class 'argparse.Namespace'>
num_layers: 12
encoder_num_layers: 12
decoder_num_layers: None
hidden_size: 768
ffn_hidden_size: 3072
num_attention_heads: 12
kv_channels: 64
group_query_attention: False
num_query_groups: 1
max_position_embeddings: 1024
position_embedding_type: learned_absolute
use_rotary_position_embeddings: False
rotary_base: 10000
rotary_percent: 1.0
rotary_interleaved: False
rotary_seq_len_interpolation_factor: None
add_position_embedding: True
make_vocab_size_divisible_by: 128
normalization: LayerNorm
norm_epsilon: 1e-05
apply_layernorm_1p: False
apply_residual_connection_post_layernorm: False
openai_gelu: False
squared_relu: False
swiglu: False
onnx_safe: None
bert_binary_head: True
untie_embeddings_and_output_weights: False
attention_dropout: 0.1
hidden_dropout: 0.1
weight_decay: 0.1
start_weight_decay: 0.1
end_weight_decay: 0.1
weight_decay_incr_style: constant
clip_grad: 1.0
adam_beta1: 0.9
adam_beta2: 0.999
[rank6]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
adam_eps: 1e-08[rank1]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank2]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank4]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())

[rank5]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
sgd_momentum: 0.9[rank7]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())

micro_batch_size: 9
global_batch_size: 72
rampup_batch_size: None
decrease_batch_size_if_needed: False
recompute_granularity: None
check_for_nan_in_loss_and_grad: True
distribute_saved_activations: False
recompute_method: None
recompute_num_layers: None
clone_scatter_output_in_embedding: True
profile: False
profile_step_start: 10
profile_step_end: 12
[rank3]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
profile_ranks: [0]
tp_comm_overlap: False
tp_comm_overlap_cfg: None
tp_comm_overlap_ag: True
tp_comm_overlap_rs: True
tp_comm_overlap_rs_dgrad: False
tp_comm_bulk_dgrad: True
tp_comm_bulk_wgrad: True
use_cpu_initialization: None
empty_unused_memory_level: 0
deterministic_mode: False
check_weight_hash_across_dp_replicas_interval: None
calculate_per_token_loss: False
train_sync_interval: None
train_iters: 200
train_samples: None
log_interval: 1
exit_interval: None
exit_duration_in_mins: None
exit_signal_handler: False
tensorboard_dir: experiments/tensorboard
masked_softmax_fusion: True
bias_gelu_fusion: True
bias_swiglu_fusion: True
bias_dropout_fusion: True
apply_rope_fusion: True
cross_entropy_loss_fusion: False
use_flash_attn: False
add_bias_linear: True
add_qkv_bias: False
optimizer: adam
dataloader_type: single
async_tensor_model_parallel_allreduce: False
no_persist_layer_norm: False
sequence_parallel: False
gradient_accumulation_fusion: True
deprecated_use_mcore_models: False
use_legacy_models: False
manual_gc: False
manual_gc_interval: 0
manual_gc_eval: True
tp_comm_split_ag: True
tp_comm_split_rs: True
seed: 1234
data_parallel_random_init: False
init_method_std: 0.02
init_method_xavier_uniform: False
lr: 0.0005
lr_decay_style: cosine
lr_wsd_decay_style: exponential
lr_decay_iters: 150000
lr_decay_samples: None
lr_wsd_decay_samples: None
lr_wsd_decay_iters: None
lr_warmup_fraction: None
lr_warmup_iters: 2000
lr_warmup_samples: 0
lr_warmup_init: 0.0
min_lr: 0.0
override_opt_param_scheduler: False
use_checkpoint_opt_param_scheduler: False
decoupled_lr: None
decoupled_min_lr: None
save: /workspace/Megatron-LM/experiments/codeparrot-small
save_interval: 2000
no_save_optim: None
no_save_rng: None
load: /workspace/Megatron-LM/experiments/codeparrot-small
no_load_optim: None
no_load_rng: None
non_persistent_save_interval: None
non_persistent_ckpt_type: None
non_persistent_global_ckpt_dir: None
finetune: False
pretrained_checkpoint: None
ckpt_step: None
perform_initialization: True
use_checkpoint_args: False
exit_on_missing_checkpoint: False
use_dist_ckpt_deprecated: False
auto_detect_ckpt_format: False
dist_ckpt_format_deprecated: None
ckpt_format: torch_dist
ckpt_convert_format: None
ckpt_convert_save: None
ckpt_convert_update_legacy_dist_opt_format: False
ckpt_fully_parallel_save_deprecated: False
ckpt_fully_parallel_save: True
async_save: None
ckpt_fully_parallel_load: False
ckpt_assume_constant_structure: False
dist_ckpt_strictness: assume_ok_unexpected
fp16: False
bf16: False
loss_scale: None
initial_loss_scale: 4294967296
min_loss_scale: 1.0
loss_scale_window: 1000
hysteresis: 2
fp32_residual_connection: False
apply_query_key_layer_scaling: False
attention_softmax_in_fp32: False
accumulate_allreduce_grads_in_fp32: False
fp16_lm_cross_entropy: False
tensor_model_parallel_size: 2
encoder_tensor_model_parallel_size: 0
pipeline_model_parallel_size: 2
encoder_pipeline_model_parallel_size: 0
pipeline_model_parallel_split_rank: None
num_layers_per_virtual_pipeline_stage: None
overlap_p2p_comm: False
distributed_backend: nccl
distributed_timeout_minutes: 10
overlap_grad_reduce: False
defer_embedding_wgrad_compute: False
wgrad_deferral_limit: 0
align_grad_reduce: True
ddp_bucket_size: None
ddp_average_in_collective: False
overlap_param_gather: False
overlap_param_gather_with_optimizer_step: False
align_param_gather: False
scatter_gather_tensors_in_pipeline: True
use_ring_exchange_p2p: False
local_rank: 0
lazy_mpu_init: None
standalone_embedding_stage: False
use_distributed_optimizer: False
context_parallel_size: 1
nccl_communicator_config_path: None
use_tp_pp_dp_mapping: False
eval_iters: 10
eval_interval: 200
test_mode: False
skip_train: False
data_path: ['codeparrot_content_document']
renormalize_blend_weights: False
split: 969, 30, 1
train_data_path: None
valid_data_path: None
test_data_path: None
data_cache_path: None
mmap_bin_files: True
mock_data: False
vocab_size: None
vocab_file: gpt2-vocab.json
merge_file: gpt2-merges.txt
vocab_extra_ids: 0
seq_length: 1024
encoder_seq_length: 1024
decoder_seq_length: None
retriever_seq_length: 256
sample_rate: 1.0
mask_prob: 0.15
short_seq_prob: 0.1
num_workers: 2
tokenizer_type: GPT2BPETokenizer
tokenizer_model: None
tiktoken_pattern: None
tiktoken_num_special_tokens: 1000
tiktoken_special_tokens: None
reset_position_ids: False
reset_attention_mask: False
eod_mask_loss: False
create_attention_mask_in_dataloader: True
num_dataset_builder_threads: 1
s3_cache_path: None
adlr_autoresume: False
adlr_autoresume_interval: 1000
ict_head_size: None
biencoder_projection_dim: 0
biencoder_shared_query_context_model: False
ict_load: None
bert_load: None
titles_data_path: None
query_in_block_prob: 0.1
use_one_sent_docs: False
evidence_data_path: None
retriever_report_topk_accuracies: []
retriever_score_scaling: False
block_data_path: None
embedding_path: None
indexer_batch_size: 128
indexer_log_interval: 1000
num_classes: 1000
img_h: 224
img_w: 224
num_channels: 3
patch_dim: 16
classes_fraction: 1.0
data_per_class_fraction: 1.0
data_sharding: True
head_lr_mult: 1.0
vision_pretraining: False
vision_pretraining_type: classify
vision_backbone_type: vit
swin_backbone_type: tiny
mask_type: random
mask_factor: 1.0
iter_per_epoch: 1250
dino_local_img_size: 96
dino_local_crops_number: 10
dino_head_hidden_size: 2048
dino_bottleneck_size: 256
dino_freeze_last_layer: 1
dino_norm_last_layer: False
dino_warmup_teacher_temp: 0.04
dino_teacher_temp: 0.07
dino_warmup_teacher_temp_epochs: 30
qk_layernorm: False
expert_model_parallel_size: 1
num_experts: None
moe_router_load_balancing_type: aux_loss
moe_router_topk: 2
moe_router_pre_softmax: False
moe_grouped_gemm: False
moe_aux_loss_coeff: 0.0
moe_z_loss_coeff: None
moe_input_jitter_eps: None
moe_token_dispatcher_type: allgather
moe_per_layer_logging: False
moe_expert_capacity_factor: None
moe_pad_expert_input_to_capacity: False
moe_token_drop_policy: probs
moe_layer_recompute: False
moe_extended_tp: False
log_params_norm: False
log_num_zeros_in_grad: False
log_throughput: False
log_progress: False
timing_log_level: 0
barrier_with_L1_time: True
timing_log_option: minmax
tensorboard_log_interval: 1
tensorboard_queue_size: 1000
log_timers_to_tensorboard: False
log_loss_scale_to_tensorboard: True
log_validation_ppl_to_tensorboard: False
log_memory_to_tensorboard: False
log_world_size_to_tensorboard: False
wandb_project: 
wandb_exp_name: 
wandb_save_dir: 
logging_level: None
log_straggler: False
disable_straggler_on_startup: False
straggler_ctrlr_port: 65535
straggler_minmax_count: 1
inference_batch_times_seqlen_threshold: 512
max_tokens_to_oom: 12000
output_bert_embeddings: False
bert_embedder_type: megatron
fp8: None
fp8_margin: 0
fp8_interval: 1
fp8_amax_history_len: 1
fp8_amax_compute_algo: most_recent
fp8_wgrad: True
transformer_impl: transformer_engine
retro_project_dir: None
retro_add_retriever: False
retro_cyclic_train_iters: None
retro_encoder_layers: 2
retro_encoder_hidden_dropout: 0.1
retro_encoder_attention_dropout: 0.1
retro_num_neighbors: 2
retro_num_retrieved_chunks: 2
retro_attention_gate: 1
retro_verify_neighbor_count: True
spec: None
hybrid_attention_ratio: 0.0
hybrid_mlp_ratio: 0.0
hybrid_override_pattern: None
yaml_cfg: None
enable_one_logger: True
one_logger_project: megatron-lm
one_logger_run_name: None
one_logger_async: False
app_tag_run_name: None
app_tag_run_version: 0.0.0
enable_ft_package: False
config_logger_dir: 
rank: 0
world_size: 8
use_dist_ckpt: True
transformer_pipeline_model_parallel_size: 2
data_parallel_size: 2
virtual_pipeline_model_parallel_size: None
params_dtype: torch.float32
consumed_train_samples: 0
skipped_train_samples: 0
consumed_valid_samples: 0
variable_seq_lengths: False
padded_vocab_size: 50432
Parameters Done
[rank0]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 16 
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING] due to: 
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/ff/cffjx2zvxx4nsx5ytzh62qq36pvyqxufnw3eosbcvyclsd244yzx.py", line 86, in <module>
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/5/b827059804d55bbe7aa604785b046124/triton_.so: undefined symbol: cuLaunchKernel
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:03:59,243] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 16 
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING] due to: 
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/vi/cviura3hwal56bylixyor73sawaac7jtfphjfe6fg54z36nq4exf.py", line 86, in <module>
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/2/b827059804d55bbe7aa604785b046124/triton_.so: undefined symbol: cuLaunchKernel
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 16 
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING] due to: 
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/7v/c7vw6y2nud5j7nkiiq3qny7atmj6rnxdfofzunxdbt4vssksnsak.py", line 86, in <module>
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/4/b827059804d55bbe7aa604785b046124/triton_.so: undefined symbol: cuLaunchKernel
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:03:59,258] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 16 
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING] due to: 
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/5u/c5uybc7pp3tkul53fpphsnvfcavfjqcy5f5pnxpj6lmhnhcjenc2.py", line 86, in <module>
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/6/b827059804d55bbe7aa604785b046124/triton_.so: undefined symbol: cuLaunchKernel
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:03:59,271] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 16 
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING] due to: 
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/6f/c6fti2yeoeefg4sx4qzldpazhruehzeyznkiumshsfmm63qgx3wq.py", line 86, in <module>
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/1/b827059804d55bbe7aa604785b046124/triton_.so: undefined symbol: cuLaunchKernel
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:03:59,295] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 16 
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING] due to: 
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/ef/cefocaq3aytipqcwixoi5uq23stpar53sjlrn72txjekouzd6lye.py", line 86, in <module>
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/0/b827059804d55bbe7aa604785b046124/triton_.so: undefined symbol: cuLaunchKernel
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:03:59,299] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 16 
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING] due to: 
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/7a/c7ae63o2lmtevsuqvud3xyek2nxnsglqwpxiqt3q2drenyw23wxn.py", line 86, in <module>
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/3/b827059804d55bbe7aa604785b046124/triton_.so: undefined symbol: cuLaunchKernel
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:03:59,332] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 16 
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING] due to: 
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/bu/cbuuhmmlcwhycd5fwn2plxj724h4c4f2y6xthke6weriv46i45m2.py", line 86, in <module>
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/7/b827059804d55bbe7aa604785b046124/triton_.so: undefined symbol: cuLaunchKernel
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:03:59,342] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_train /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 48 
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING] due to: 
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/m6/cm6bj2guiucyvhouwiyplggucma7jq5kjos3e3husxp4adje6gng.py", line 78, in <module>
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/5/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:04:00,253] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_train /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 48 
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING] due to: 
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/oz/coz75hpylyhqt2tmw5rtd4migc6zoqewofinuo3y32xtovxoyysw.py", line 78, in <module>
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/4/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:04:00,255] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_train /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 48 
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING] due to: 
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/cr/ccrhdxxyp5j3eoybahnzr7sblw5mvcyv4uaxoca42hc3bnmg7zpd.py", line 78, in <module>
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/2/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:04:00,262] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_train /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 48 
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING] due to: 
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/3e/c3e7wl6l4mgojgz2dbujbd55fl4zcodw7xcsbqt5ngzxb4dd7g4w.py", line 78, in <module>
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/1/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:04:00,276] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_train /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 48 
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING] due to: 
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/kv/ckvaqiusv77retsdtfokn7k2isaeygwht7hd54zgkscioqdxosdn.py", line 78, in <module>
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/0/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:04:00,288] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_train /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 48 
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING] due to: 
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/7a/c7az7vw2abhzacxndlj3qbowds5stwrizwyltu2zwa2fri2xpkf2.py", line 78, in <module>
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/6/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:04:00,289] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_train /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 48 
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING] due to: 
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/2r/c2rdm77cyl6tch4hem5o2ezqnf5uwfm3ifs44ogyawn6rquqgxrd.py", line 78, in <module>
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/3/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:04:00,344] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_train /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 48 
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING] due to: 
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/kk/ckkgo2v56ok5hwy37vcisd2krumxwy7fnp756qcjfl463uszwu2s.py", line 78, in <module>
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/7/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:04:00,346] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT _bias_dropout_add_func /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 9 
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING] due to: 
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/m6/cm6bj2guiucyvhouwiyplggucma7jq5kjos3e3husxp4adje6gng.py", line 78, in <module>
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/5/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:04:00,786] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT _bias_dropout_add_func /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 9 
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING] due to: 
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/oz/coz75hpylyhqt2tmw5rtd4migc6zoqewofinuo3y32xtovxoyysw.py", line 78, in <module>
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/4/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:04:00,803] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT _bias_dropout_add_func /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 9 
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING] due to: 
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/cr/ccrhdxxyp5j3eoybahnzr7sblw5mvcyv4uaxoca42hc3bnmg7zpd.py", line 78, in <module>
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/2/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:04:00,812] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT _bias_dropout_add_func /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 9 
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING] due to: 
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/3e/c3e7wl6l4mgojgz2dbujbd55fl4zcodw7xcsbqt5ngzxb4dd7g4w.py", line 78, in <module>
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/1/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:04:00,821] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT _bias_dropout_add_func /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 9 
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING] due to: 
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/7a/c7az7vw2abhzacxndlj3qbowds5stwrizwyltu2zwa2fri2xpkf2.py", line 78, in <module>
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/6/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:04:00,840] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT _bias_dropout_add_func /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 9 
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING] due to: 
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/kv/ckvaqiusv77retsdtfokn7k2isaeygwht7hd54zgkscioqdxosdn.py", line 78, in <module>
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/0/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:04:00,847] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT _bias_dropout_add_func /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 9 
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING] due to: 
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/2r/c2rdm77cyl6tch4hem5o2ezqnf5uwfm3ifs44ogyawn6rquqgxrd.py", line 78, in <module>
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/3/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:04:00,899] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT _bias_dropout_add_func /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 9 
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING] due to: 
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/kk/ckkgo2v56ok5hwy37vcisd2krumxwy7fnp756qcjfl463uszwu2s.py", line 78, in <module>
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/7/916c863ffa0fcd5ae1d4680b203cbf1d/triton_.so: undefined symbol: cuLaunchKernel
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:04:00,900] torch._dynamo.convert_frame: [WARNING] 
time to initialize megatron (seconds): 5.392
[after megatron is initialized] datetime: 2024-10-02 15:04:00 
building GPT model ...
use_te: True, HAVE_TE: True
use_te: True, HAVE_TE: True
use_te: True, HAVE_TE: Trueuse_te: True, HAVE_TE: Trueuse_te: True, HAVE_TE: Trueuse_te: True, HAVE_TE: True
use_te: True, HAVE_TE: True


use_te: True, HAVE_TE: True

/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/base.py:643: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/base.py:643: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/base.py:643: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/base.py:643: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/base.py:643: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/base.py:643: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/base.py:643: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/base.py:643: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
 > number of parameters on (tensor, pipeline) model parallel rank (0, 1): 40644864
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 41429760
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
Params for bucket 1 (40644864 elements):
	decoder.layers.2.mlp.linear_fc2.bias
	decoder.layers.2.self_attention.linear_qkv.bias
	decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.4.self_attention.linear_proj.bias
	decoder.layers.3.mlp.linear_fc1.weight
	decoder.layers.1.self_attention.linear_qkv.bias
	decoder.layers.5.mlp.linear_fc2.weight
	decoder.layers.5.mlp.linear_fc1.bias
	decoder.layers.4.self_attention.linear_qkv.weight
	decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.2.mlp.linear_fc1.layer_norm_weight
	decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.0.self_attention.linear_proj.weight
	decoder.layers.1.self_attention.linear_qkv.weight
	decoder.layers.5.self_attention.linear_qkv.weight
	decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.3.mlp.linear_fc1.layer_norm_weight
	decoder.layers.3.self_attention.linear_proj.bias
	decoder.layers.2.self_attention.linear_proj.bias
	decoder.layers.5.mlp.linear_fc1.layer_norm_bias
	decoder.layers.5.self_attention.linear_qkv.bias
	decoder.layers.3.mlp.linear_fc2.bias
	decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.0.mlp.linear_fc1.layer_norm_bias
	decoder.final_layernorm.weight
	decoder.layers.5.mlp.linear_fc1.layer_norm_weight
	decoder.layers.4.mlp.linear_fc1.layer_norm_bias
	decoder.layers.3.mlp.linear_fc1.bias
	decoder.layers.3.self_attention.linear_qkv.weight
	decoder.layers.0.mlp.linear_fc2.weight
	decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.0.self_attention.linear_qkv.weight
	decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.5.self_attention.linear_proj.weight
	decoder.layers.4.mlp.linear_fc2.weight
	decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.2.mlp.linear_fc1.bias
	decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.1.self_attention.linear_proj.weight
	decoder.layers.0.mlp.linear_fc1.weight
	decoder.layers.0.self_attention.linear_proj.bias
	decoder.layers.1.mlp.linear_fc2.bias
	decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.4.mlp.linear_fc1.weight
	decoder.layers.1.mlp.linear_fc2.weight
	decoder.layers.1.mlp.linear_fc1.weight
	decoder.layers.1.self_attention.linear_proj.bias
	decoder.layers.0.mlp.linear_fc1.layer_norm_weight
	decoder.layers.1.mlp.linear_fc1.bias
	output_layer.weight
	decoder.layers.5.self_attention.linear_proj.bias
	decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.3.self_attention.linear_qkv.bias
	decoder.layers.2.self_attention.linear_qkv.weight
	decoder.layers.0.mlp.linear_fc2.bias
	decoder.final_layernorm.bias
	decoder.layers.4.mlp.linear_fc1.layer_norm_weight
	decoder.layers.4.self_attention.linear_proj.weight
	decoder.layers.2.mlp.linear_fc1.layer_norm_bias
	decoder.layers.0.self_attention.linear_qkv.bias
	decoder.layers.5.mlp.linear_fc1.weight
	decoder.layers.4.mlp.linear_fc2.bias
	decoder.layers.4.self_attention.linear_qkv.bias
	decoder.layers.3.mlp.linear_fc1.layer_norm_bias
	decoder.layers.2.mlp.linear_fc2.weight
	decoder.layers.1.mlp.linear_fc1.layer_norm_weight
	decoder.layers.0.mlp.linear_fc1.bias
	decoder.layers.5.mlp.linear_fc2.bias
	decoder.layers.3.self_attention.linear_proj.weight
	decoder.layers.2.self_attention.linear_proj.weight
	decoder.layers.4.mlp.linear_fc1.bias
	decoder.layers.3.mlp.linear_fc2.weight
	decoder.layers.2.mlp.linear_fc1.weight
	decoder.layers.1.mlp.linear_fc1.layer_norm_bias
wrap_with_ddp: True
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None, average_in_collective=False)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
Params for bucket 1 (41429760 elements):
	decoder.layers.3.mlp.linear_fc1.weight
	decoder.layers.1.mlp.linear_fc2.weight
	decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.4.self_attention.linear_qkv.bias
	decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.2.self_attention.linear_qkv.bias
	decoder.layers.0.mlp.linear_fc2.weight
	decoder.layers.4.mlp.linear_fc2.bias
	decoder.layers.3.mlp.linear_fc1.layer_norm_weight
	decoder.layers.3.self_attention.linear_proj.bias
	decoder.layers.0.mlp.linear_fc1.bias
	embedding.word_embeddings.weight
	decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.5.mlp.linear_fc2.bias
	decoder.layers.5.mlp.linear_fc2.weight
	decoder.layers.5.mlp.linear_fc1.weight
	decoder.layers.4.self_attention.linear_proj.weight
	decoder.layers.3.mlp.linear_fc1.layer_norm_bias
	decoder.layers.2.mlp.linear_fc1.layer_norm_weight
	decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.1.mlp.linear_fc1.layer_norm_weight
	decoder.layers.2.self_attention.linear_proj.bias
	decoder.layers.0.self_attention.linear_proj.weight
	decoder.layers.1.self_attention.linear_qkv.weight
	decoder.layers.4.mlp.linear_fc1.bias
	decoder.layers.4.mlp.linear_fc1.layer_norm_weight
	decoder.layers.3.self_attention.linear_qkv.weight
	decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.5.self_attention.linear_proj.bias
	decoder.layers.5.self_attention.linear_proj.weight
	decoder.layers.2.mlp.linear_fc1.bias
	decoder.layers.2.mlp.linear_fc1.weight
	decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
	decoder.layers.3.mlp.linear_fc1.bias
	decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.1.mlp.linear_fc1.layer_norm_bias
	decoder.layers.1.self_attention.linear_qkv.bias
	decoder.layers.0.self_attention.linear_qkv.weight
	decoder.layers.5.mlp.linear_fc1.layer_norm_bias
	decoder.layers.4.self_attention.linear_proj.bias
	decoder.layers.3.mlp.linear_fc2.weight
	decoder.layers.2.mlp.linear_fc2.weight
	decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.1.self_attention.linear_proj.weight
	decoder.layers.0.mlp.linear_fc1.layer_norm_bias
	decoder.layers.0.self_attention.linear_proj.bias
	embedding.position_embeddings.weight
	decoder.layers.5.self_attention.linear_qkv.weight
	decoder.layers.4.mlp.linear_fc1.layer_norm_bias
	decoder.layers.3.self_attention.linear_qkv.bias
	decoder.layers.2.self_attention.linear_proj.weight
	decoder.layers.1.mlp.linear_fc1.weight
	decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.0.mlp.linear_fc2.bias
	decoder.layers.2.mlp.linear_fc2.bias
	decoder.layers.2.self_attention.linear_qkv.weight
	decoder.layers.1.self_attention.linear_proj.bias
	decoder.layers.0.self_attention.linear_qkv.bias
	decoder.layers.2.mlp.linear_fc1.layer_norm_bias
	decoder.layers.1.mlp.linear_fc2.bias
	decoder.layers.5.mlp.linear_fc1.layer_norm_weight
	decoder.layers.5.self_attention.linear_qkv.bias
	decoder.layers.4.mlp.linear_fc2.weight
	decoder.layers.4.mlp.linear_fc1.weight
	decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.3.mlp.linear_fc2.bias
	decoder.layers.3.self_attention.linear_proj.weight
	decoder.layers.0.mlp.linear_fc1.weight
	decoder.layers.4.self_attention.linear_qkv.weight
	decoder.layers.1.mlp.linear_fc1.bias
	decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
	decoder.layers.5.mlp.linear_fc1.bias
	decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.optimizer:Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0005, min_lr=0.0, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.1, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, overlap_param_gather_with_optimizer_step=False, align_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x2b0b37d6c520>, config_logger_dir='')
INFO:megatron.core.optimizer_param_scheduler:> learning rate decay style: cosine
 > number of parameters on (tensor, pipeline) model parallel rank (1, 0): 41429760
 > number of parameters on (tensor, pipeline) model parallel rank (1, 1): 40644864
WARNING: could not find the metadata file /workspace/Megatron-LM/experiments/codeparrot-small/latest_checkpointed_iteration.txt
    will not load any checkpoints and will start from random
(min, max) time across ranks (ms):
    load-checkpoint ................................: (4.09, 4.10)
[after model, optimizer, and learning rate scheduler are built] datetime: 2024-10-02 15:04:01 
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      14400
    validation: 1440
    test:       720
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.969), (0.969, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
INFO:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(14400, 1440, 720), and config=GPTDatasetConfig(random_seed=1234, sequence_length=1024, blend=(['codeparrot_content_document'], None), blend_per_split=[None, None, None], renormalize_blend_weights=False, split='969, 30, 1', split_matrix=[(0, 0.969), (0.969, 0.999), (0.999, 1.0)], num_dataset_builder_threads=1, path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x2b0b37d6cb20>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, s3_cache_path=None)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from codeparrot_content_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 5300000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 5300000
INFO:megatron.core.datasets.gpt_dataset:Build and save the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 23120956
INFO:megatron.core.datasets.gpt_dataset:> total number of epochs: 1
INFO:megatron.core.datasets.gpt_dataset:Build and save the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 695029
INFO:megatron.core.datasets.gpt_dataset:> total number of epochs: 1
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 28468bbe0f1ff61a56006615d3d8e16c-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 28468bbe0f1ff61a56006615d3d8e16c-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 28468bbe0f1ff61a56006615d3d8e16c-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 23384
> finished creating GPT datasets ...
[after dataloaders are built] datetime: 2024-10-02 15:04:05 
done with setup ...
training ...
(min, max) time across ranks (ms):
    model-and-optimizer-setup ......................: (184.79, 206.92)
    train/valid/test-data-iterators-setup ..........: (3836.74, 4029.74)
[before the start of training step] datetime: 2024-10-02 15:04:05 
[rank5]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank4]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank7]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank6]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank3]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank2]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank1]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank3]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank0]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank2]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank1]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank0]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:711: UserWarning: When using async grad allreduce it is recommended to set the environment variable CUDA_DEVICE_MAX_CONNECTIONS to 1 for maximum speedup
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:711: UserWarning: When using async grad allreduce it is recommended to set the environment variable CUDA_DEVICE_MAX_CONNECTIONS to 1 for maximum speedup
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:711: UserWarning: When using async grad allreduce it is recommended to set the environment variable CUDA_DEVICE_MAX_CONNECTIONS to 1 for maximum speedup
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:711: UserWarning: When using async grad allreduce it is recommended to set the environment variable CUDA_DEVICE_MAX_CONNECTIONS to 1 for maximum speedup
  warnings.warn(
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu_back /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 25 
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING] due to: 
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2073, in aot_dispatch_base
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     compiled_fw = compiler(fw_module, updated_flat_args)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/se/csemn6g6ygawzy2jdit7wuy35n5vobb3yocexgx4zngzoro2xwdk.py", line 106, in <module>
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/7/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:04:07,777] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu_back /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 25 
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING] due to: 
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2073, in aot_dispatch_base
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     compiled_fw = compiler(fw_module, updated_flat_args)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/m2/cm253utnwa3zrb5g2esspxfene3f7gyga7xfkeu5iydz76z5elq5.py", line 106, in <module>
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/4/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:04:07,783] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu_back /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 25 
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING] due to: 
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2073, in aot_dispatch_base
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     compiled_fw = compiler(fw_module, updated_flat_args)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/ou/couezynusvn4ztpufeghszseh2acbciq63rpxera43risxkpbji3.py", line 106, in <module>
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/5/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:04:07,784] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu_back /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 25 
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING] due to: 
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2073, in aot_dispatch_base
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     compiled_fw = compiler(fw_module, updated_flat_args)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/kl/cklzdoeueccgkq5ksyn6kqbfkgojuq2ylps3ciwtex6naopyvngi.py", line 106, in <module>
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/6/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:04:07,796] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank4]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank6]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
[rank7]:[W ProcessGroupNCCL.cpp:2302] Warning: 0TORCH_NCCL_AVOID_RECORD_STREAMS=1 has no effect for point-to-point collectives. (function operator())
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu_back /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 25 
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING] due to: 
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2073, in aot_dispatch_base
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     compiled_fw = compiler(fw_module, updated_flat_args)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/qq/cqqbl2vjmk733ymvllh757mqlhkkgw6cpcyfqrnh3bm7u2lqnqoy.py", line 106, in <module>
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/1/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:04:08,785] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu_back /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 25 
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING] due to: 
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2073, in aot_dispatch_base
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     compiled_fw = compiler(fw_module, updated_flat_args)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/6q/c6qpa5lvhuzelckofsqeaswu3ypgaoiayfc55dunoft7kmqusljs.py", line 106, in <module>
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/3/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:04:08,809] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu_back /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 25 
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING] due to: 
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2073, in aot_dispatch_base
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     compiled_fw = compiler(fw_module, updated_flat_args)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/hs/chsnwl6fvpdls7l74kg644jjmb72huu637ontyeqf43wmh2srznh.py", line 106, in <module>
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/0/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:04:08,839] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_gelu_back /workspace/Megatron-LM/megatron/core/fusions/fused_bias_gelu.py line 25 
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING] due to: 
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2073, in aot_dispatch_base
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     compiled_fw = compiler(fw_module, updated_flat_args)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/nq/cnqv6er7774n7viqywplwsxbdoeedqvmwf2h2k2ufnpexayevie3.py", line 106, in <module>
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/2/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:04:08,846] torch._dynamo.convert_frame: [WARNING] 
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:09] iteration        1/     200 | consumed samples:           72 | elapsed time per iteration (ms): 4698.0 | learning rate: 2.500000E-07 | global batch size:    72 | lm loss: 1.076727E+01 | loss scale: 1.0 | grad norm: 85.401 | number of skipped iterations:   0 | number of nan iterations:   0 |Number of parameters in transformer layers in billions:  0.08

Number of parameters in embedding layers in billions: 0.04
Total number of parameters in billions: 0.12
Number of parameters in most loaded shard in billions: 0.0406
Number of parameters in other shards in billions: 0.0212
Theoretical memory footprints: weight and optimizer=697.10 MB
[Rank 5] (after 1 iterations) memory (MB) | allocated: 1242.1552734375 | max allocated: 6565.85107421875 | reserved: 7336.0 | max reserved: 7336.0[Rank 1] (after 1 iterations) memory (MB) | allocated: 1147.13671875 | max allocated: 10428.08251953125 | reserved: 11342.0 | max reserved: 11342.0
[Rank 4] (after 1 iterations) memory (MB) | allocated: 1026.6552734375 | max allocated: 6539.8505859375 | reserved: 7472.0 | max reserved: 7472.0

[Rank 0] (after 1 iterations) memory (MB) | allocated: 1146.63671875 | max allocated: 10425.08251953125 | reserved: 11380.0 | max reserved: 11380.0
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:11] iteration        2/     200 | consumed samples:          144 | elapsed time per iteration (ms): 1104.2 | learning rate: 5.000000E-07 | global batch size:    72 | lm loss: 1.077849E+01 | loss scale: 1.0 | grad norm: 81.202 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 5, local rank 5, ddp group rank 0/2global rank 7, local rank 7, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:12] iteration        3/     200 | consumed samples:          216 | elapsed time per iteration (ms): 1110.3 | learning rate: 7.500000E-07 | global batch size:    72 | lm loss: 1.073134E+01 | loss scale: 1.0 | grad norm: 77.538 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2


global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 7, local rank 7, ddp group rank 1/2

global rank 5, local rank 5, ddp group rank 0/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:04:13] iteration        4/     200 | consumed samples:          288 | elapsed time per iteration (ms): 1107.3 | learning rate: 1.000000E-06 | global batch size:    72 | lm loss: 1.058559E+01 | loss scale: 1.0 | grad norm: 76.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:14] iteration        5/     200 | consumed samples:          360 | elapsed time per iteration (ms): 1104.7 | learning rate: 1.250000E-06 | global batch size:    72 | lm loss: 1.044961E+01 | loss scale: 1.0 | grad norm: 68.373 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:15] iteration        6/     200 | consumed samples:          432 | elapsed time per iteration (ms): 1109.2 | learning rate: 1.500000E-06 | global batch size:    72 | lm loss: 9.966359E+00 | loss scale: 1.0 | grad norm: 82.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:16] iteration        7/     200 | consumed samples:          504 | elapsed time per iteration (ms): 1107.5 | learning rate: 1.750000E-06 | global batch size:    72 | lm loss: 9.814819E+00 | loss scale: 1.0 | grad norm: 66.552 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:17] iteration        8/     200 | consumed samples:          576 | elapsed time per iteration (ms): 1103.8 | learning rate: 2.000000E-06 | global batch size:    72 | lm loss: 9.541128E+00 | loss scale: 1.0 | grad norm: 57.755 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:18] iteration        9/     200 | consumed samples:          648 | elapsed time per iteration (ms): 1105.6 | learning rate: 2.250000E-06 | global batch size:    72 | lm loss: 9.253361E+00 | loss scale: 1.0 | grad norm: 50.149 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:19] iteration       10/     200 | consumed samples:          720 | elapsed time per iteration (ms): 1102.6 | learning rate: 2.500000E-06 | global batch size:    72 | lm loss: 8.804806E+00 | loss scale: 1.0 | grad norm: 46.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
TP USE NCCLglobal rank 6, local rank 6, ddp group rank 1/2

global rank 7, local rank 7, ddp group rank 1/2DP USE NCCL

DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 5, local rank 5, ddp group rank 0/2

global rank 4, local rank 4, ddp group rank 0/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:21] iteration       11/     200 | consumed samples:          792 | elapsed time per iteration (ms): 1607.4 | learning rate: 2.750000E-06 | global batch size:    72 | lm loss: 8.363843E+00 | loss scale: 1.0 | grad norm: 41.173 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 7, local rank 7, ddp group rank 1/2

global rank 5, local rank 5, ddp group rank 0/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:22] iteration       12/     200 | consumed samples:          864 | elapsed time per iteration (ms): 1110.7 | learning rate: 3.000000E-06 | global batch size:    72 | lm loss: 7.948419E+00 | loss scale: 1.0 | grad norm: 35.741 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 4, local rank 4, ddp group rank 0/2global rank 7, local rank 7, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 2, local rank 2, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:23] iteration       13/     200 | consumed samples:          936 | elapsed time per iteration (ms): 1103.9 | learning rate: 3.250000E-06 | global batch size:    72 | lm loss: 7.929498E+00 | loss scale: 1.0 | grad norm: 26.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:24] iteration       14/     200 | consumed samples:         1008 | elapsed time per iteration (ms): 1100.9 | learning rate: 3.500000E-06 | global batch size:    72 | lm loss: 7.325563E+00 | loss scale: 1.0 | grad norm: 21.670 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2TP USE NCCL

DP USE NCCLglobal rank 4, local rank 4, ddp group rank 0/2

DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:25] iteration       15/     200 | consumed samples:         1080 | elapsed time per iteration (ms): 1105.4 | learning rate: 3.750000E-06 | global batch size:    72 | lm loss: 7.109766E+00 | loss scale: 1.0 | grad norm: 14.640 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:27] iteration       16/     200 | consumed samples:         1152 | elapsed time per iteration (ms): 1109.5 | learning rate: 4.000000E-06 | global batch size:    72 | lm loss: 7.257950E+00 | loss scale: 1.0 | grad norm: 11.257 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2


global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:28] iteration       17/     200 | consumed samples:         1224 | elapsed time per iteration (ms): 1109.6 | learning rate: 4.250000E-06 | global batch size:    72 | lm loss: 7.349308E+00 | loss scale: 1.0 | grad norm: 13.265 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 4, local rank 4, ddp group rank 0/2global rank 5, local rank 5, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:29] iteration       18/     200 | consumed samples:         1296 | elapsed time per iteration (ms): 1115.7 | learning rate: 4.500000E-06 | global batch size:    72 | lm loss: 6.913735E+00 | loss scale: 1.0 | grad norm: 14.601 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:30] iteration       19/     200 | consumed samples:         1368 | elapsed time per iteration (ms): 1111.6 | learning rate: 4.750000E-06 | global batch size:    72 | lm loss: 7.285512E+00 | loss scale: 1.0 | grad norm: 12.813 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:31] iteration       20/     200 | consumed samples:         1440 | elapsed time per iteration (ms): 1251.5 | learning rate: 5.000000E-06 | global batch size:    72 | lm loss: 7.164138E+00 | loss scale: 1.0 | grad norm: 7.714 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:32] iteration       21/     200 | consumed samples:         1512 | elapsed time per iteration (ms): 1112.9 | learning rate: 5.250000E-06 | global batch size:    72 | lm loss: 6.928651E+00 | loss scale: 1.0 | grad norm: 12.226 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:33] iteration       22/     200 | consumed samples:         1584 | elapsed time per iteration (ms): 1110.9 | learning rate: 5.500000E-06 | global batch size:    72 | lm loss: 6.988214E+00 | loss scale: 1.0 | grad norm: 16.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:34] iteration       23/     200 | consumed samples:         1656 | elapsed time per iteration (ms): 1110.4 | learning rate: 5.750000E-06 | global batch size:    72 | lm loss: 6.854879E+00 | loss scale: 1.0 | grad norm: 16.360 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 5, local rank 5, ddp group rank 0/2global rank 4, local rank 4, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 2, local rank 2, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:36] iteration       24/     200 | consumed samples:         1728 | elapsed time per iteration (ms): 1107.5 | learning rate: 6.000000E-06 | global batch size:    72 | lm loss: 6.968601E+00 | loss scale: 1.0 | grad norm: 10.387 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:37] iteration       25/     200 | consumed samples:         1800 | elapsed time per iteration (ms): 1108.8 | learning rate: 6.250000E-06 | global batch size:    72 | lm loss: 6.871386E+00 | loss scale: 1.0 | grad norm: 5.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:38] iteration       26/     200 | consumed samples:         1872 | elapsed time per iteration (ms): 1105.9 | learning rate: 6.500000E-06 | global batch size:    72 | lm loss: 6.686159E+00 | loss scale: 1.0 | grad norm: 6.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2


global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:39] iteration       27/     200 | consumed samples:         1944 | elapsed time per iteration (ms): 1108.2 | learning rate: 6.750000E-06 | global batch size:    72 | lm loss: 6.334611E+00 | loss scale: 1.0 | grad norm: 6.924 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:40] iteration       28/     200 | consumed samples:         2016 | elapsed time per iteration (ms): 1105.7 | learning rate: 7.000000E-06 | global batch size:    72 | lm loss: 6.558491E+00 | loss scale: 1.0 | grad norm: 5.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 2, local rank 2, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:41] iteration       29/     200 | consumed samples:         2088 | elapsed time per iteration (ms): 1100.0 | learning rate: 7.250000E-06 | global batch size:    72 | lm loss: 6.590058E+00 | loss scale: 1.0 | grad norm: 4.284 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:42] iteration       30/     200 | consumed samples:         2160 | elapsed time per iteration (ms): 1105.4 | learning rate: 7.500000E-06 | global batch size:    72 | lm loss: 6.558754E+00 | loss scale: 1.0 | grad norm: 5.819 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:43] iteration       31/     200 | consumed samples:         2232 | elapsed time per iteration (ms): 1105.3 | learning rate: 7.750000E-06 | global batch size:    72 | lm loss: 6.858221E+00 | loss scale: 1.0 | grad norm: 4.899 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:44] iteration       32/     200 | consumed samples:         2304 | elapsed time per iteration (ms): 1107.2 | learning rate: 8.000000E-06 | global batch size:    72 | lm loss: 6.370781E+00 | loss scale: 1.0 | grad norm: 3.612 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:46] iteration       33/     200 | consumed samples:         2376 | elapsed time per iteration (ms): 1104.3 | learning rate: 8.250000E-06 | global batch size:    72 | lm loss: 6.070593E+00 | loss scale: 1.0 | grad norm: 3.924 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCLTP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:47] iteration       34/     200 | consumed samples:         2448 | elapsed time per iteration (ms): 1101.4 | learning rate: 8.500000E-06 | global batch size:    72 | lm loss: 6.293202E+00 | loss scale: 1.0 | grad norm: 4.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:48] iteration       35/     200 | consumed samples:         2520 | elapsed time per iteration (ms): 1104.2 | learning rate: 8.750000E-06 | global batch size:    72 | lm loss: 6.467164E+00 | loss scale: 1.0 | grad norm: 3.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:49] iteration       36/     200 | consumed samples:         2592 | elapsed time per iteration (ms): 1100.1 | learning rate: 9.000000E-06 | global batch size:    72 | lm loss: 6.237164E+00 | loss scale: 1.0 | grad norm: 2.575 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:50] iteration       37/     200 | consumed samples:         2664 | elapsed time per iteration (ms): 1103.7 | learning rate: 9.250000E-06 | global batch size:    72 | lm loss: 6.202723E+00 | loss scale: 1.0 | grad norm: 3.265 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 1, local rank 1, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:51] iteration       38/     200 | consumed samples:         2736 | elapsed time per iteration (ms): 1100.6 | learning rate: 9.500000E-06 | global batch size:    72 | lm loss: 6.334580E+00 | loss scale: 1.0 | grad norm: 2.863 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:52] iteration       39/     200 | consumed samples:         2808 | elapsed time per iteration (ms): 1104.5 | learning rate: 9.750000E-06 | global batch size:    72 | lm loss: 5.907776E+00 | loss scale: 1.0 | grad norm: 2.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:53] iteration       40/     200 | consumed samples:         2880 | elapsed time per iteration (ms): 1102.2 | learning rate: 1.000000E-05 | global batch size:    72 | lm loss: 5.949427E+00 | loss scale: 1.0 | grad norm: 2.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:54] iteration       41/     200 | consumed samples:         2952 | elapsed time per iteration (ms): 1099.5 | learning rate: 1.025000E-05 | global batch size:    72 | lm loss: 5.998664E+00 | loss scale: 1.0 | grad norm: 2.131 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:55] iteration       42/     200 | consumed samples:         3024 | elapsed time per iteration (ms): 1096.4 | learning rate: 1.050000E-05 | global batch size:    72 | lm loss: 6.086780E+00 | loss scale: 1.0 | grad norm: 1.868 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:57] iteration       43/     200 | consumed samples:         3096 | elapsed time per iteration (ms): 1101.8 | learning rate: 1.075000E-05 | global batch size:    72 | lm loss: 5.938154E+00 | loss scale: 1.0 | grad norm: 2.338 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2


global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2


TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:58] iteration       44/     200 | consumed samples:         3168 | elapsed time per iteration (ms): 1105.5 | learning rate: 1.100000E-05 | global batch size:    72 | lm loss: 5.992712E+00 | loss scale: 1.0 | grad norm: 2.142 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 4, local rank 4, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:04:59] iteration       45/     200 | consumed samples:         3240 | elapsed time per iteration (ms): 1104.2 | learning rate: 1.125000E-05 | global batch size:    72 | lm loss: 5.842859E+00 | loss scale: 1.0 | grad norm: 1.769 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:00] iteration       46/     200 | consumed samples:         3312 | elapsed time per iteration (ms): 1101.3 | learning rate: 1.150000E-05 | global batch size:    72 | lm loss: 5.949588E+00 | loss scale: 1.0 | grad norm: 2.049 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:01] iteration       47/     200 | consumed samples:         3384 | elapsed time per iteration (ms): 1103.6 | learning rate: 1.175000E-05 | global batch size:    72 | lm loss: 5.960723E+00 | loss scale: 1.0 | grad norm: 2.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:02] iteration       48/     200 | consumed samples:         3456 | elapsed time per iteration (ms): 1098.5 | learning rate: 1.200000E-05 | global batch size:    72 | lm loss: 5.930125E+00 | loss scale: 1.0 | grad norm: 1.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2


global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:03] iteration       49/     200 | consumed samples:         3528 | elapsed time per iteration (ms): 1098.1 | learning rate: 1.225000E-05 | global batch size:    72 | lm loss: 5.896634E+00 | loss scale: 1.0 | grad norm: 1.786 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:04] iteration       50/     200 | consumed samples:         3600 | elapsed time per iteration (ms): 1099.9 | learning rate: 1.250000E-05 | global batch size:    72 | lm loss: 5.880773E+00 | loss scale: 1.0 | grad norm: 2.115 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 1, local rank 1, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:05] iteration       51/     200 | consumed samples:         3672 | elapsed time per iteration (ms): 1102.0 | learning rate: 1.275000E-05 | global batch size:    72 | lm loss: 5.767033E+00 | loss scale: 1.0 | grad norm: 1.805 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2


global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 4, local rank 4, ddp group rank 0/2global rank 7, local rank 7, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:06] iteration       52/     200 | consumed samples:         3744 | elapsed time per iteration (ms): 1097.9 | learning rate: 1.300000E-05 | global batch size:    72 | lm loss: 5.885943E+00 | loss scale: 1.0 | grad norm: 1.693 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 5, local rank 5, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:08] iteration       53/     200 | consumed samples:         3816 | elapsed time per iteration (ms): 1104.1 | learning rate: 1.325000E-05 | global batch size:    72 | lm loss: 5.867264E+00 | loss scale: 1.0 | grad norm: 1.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2


global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 4, local rank 4, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:09] iteration       54/     200 | consumed samples:         3888 | elapsed time per iteration (ms): 1103.3 | learning rate: 1.350000E-05 | global batch size:    72 | lm loss: 5.754900E+00 | loss scale: 1.0 | grad norm: 1.677 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 5, local rank 5, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:10] iteration       55/     200 | consumed samples:         3960 | elapsed time per iteration (ms): 1099.4 | learning rate: 1.375000E-05 | global batch size:    72 | lm loss: 6.021527E+00 | loss scale: 1.0 | grad norm: 1.697 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:11] iteration       56/     200 | consumed samples:         4032 | elapsed time per iteration (ms): 1104.0 | learning rate: 1.400000E-05 | global batch size:    72 | lm loss: 5.790205E+00 | loss scale: 1.0 | grad norm: 1.697 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2


TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 7, local rank 7, ddp group rank 1/2

global rank 4, local rank 4, ddp group rank 0/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:12] iteration       57/     200 | consumed samples:         4104 | elapsed time per iteration (ms): 1102.6 | learning rate: 1.425000E-05 | global batch size:    72 | lm loss: 5.756729E+00 | loss scale: 1.0 | grad norm: 1.816 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 4, local rank 4, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 2, local rank 2, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:13] iteration       58/     200 | consumed samples:         4176 | elapsed time per iteration (ms): 1101.4 | learning rate: 1.450000E-05 | global batch size:    72 | lm loss: 6.068718E+00 | loss scale: 1.0 | grad norm: 1.600 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:14] iteration       59/     200 | consumed samples:         4248 | elapsed time per iteration (ms): 1103.2 | learning rate: 1.475000E-05 | global batch size:    72 | lm loss: 5.685299E+00 | loss scale: 1.0 | grad norm: 1.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:15] iteration       60/     200 | consumed samples:         4320 | elapsed time per iteration (ms): 1102.5 | learning rate: 1.500000E-05 | global batch size:    72 | lm loss: 5.760309E+00 | loss scale: 1.0 | grad norm: 2.149 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:16] iteration       61/     200 | consumed samples:         4392 | elapsed time per iteration (ms): 1100.5 | learning rate: 1.525000E-05 | global batch size:    72 | lm loss: 5.617449E+00 | loss scale: 1.0 | grad norm: 1.671 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2


global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:17] iteration       62/     200 | consumed samples:         4464 | elapsed time per iteration (ms): 1104.2 | learning rate: 1.550000E-05 | global batch size:    72 | lm loss: 5.561297E+00 | loss scale: 1.0 | grad norm: 1.574 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 4, local rank 4, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:19] iteration       63/     200 | consumed samples:         4536 | elapsed time per iteration (ms): 1100.5 | learning rate: 1.575000E-05 | global batch size:    72 | lm loss: 5.433081E+00 | loss scale: 1.0 | grad norm: 1.936 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:20] iteration       64/     200 | consumed samples:         4608 | elapsed time per iteration (ms): 1102.1 | learning rate: 1.600000E-05 | global batch size:    72 | lm loss: 5.705309E+00 | loss scale: 1.0 | grad norm: 2.130 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:21] iteration       65/     200 | consumed samples:         4680 | elapsed time per iteration (ms): 1102.9 | learning rate: 1.625000E-05 | global batch size:    72 | lm loss: 5.775369E+00 | loss scale: 1.0 | grad norm: 1.700 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:22] iteration       66/     200 | consumed samples:         4752 | elapsed time per iteration (ms): 1101.9 | learning rate: 1.650000E-05 | global batch size:    72 | lm loss: 5.582780E+00 | loss scale: 1.0 | grad norm: 4.928 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:23] iteration       67/     200 | consumed samples:         4824 | elapsed time per iteration (ms): 1103.5 | learning rate: 1.675000E-05 | global batch size:    72 | lm loss: 5.425777E+00 | loss scale: 1.0 | grad norm: 2.339 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:24] iteration       68/     200 | consumed samples:         4896 | elapsed time per iteration (ms): 1100.3 | learning rate: 1.700000E-05 | global batch size:    72 | lm loss: 5.772641E+00 | loss scale: 1.0 | grad norm: 4.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 5, local rank 5, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:25] iteration       69/     200 | consumed samples:         4968 | elapsed time per iteration (ms): 1102.1 | learning rate: 1.725000E-05 | global batch size:    72 | lm loss: 5.654859E+00 | loss scale: 1.0 | grad norm: 2.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:26] iteration       70/     200 | consumed samples:         5040 | elapsed time per iteration (ms): 1105.1 | learning rate: 1.750000E-05 | global batch size:    72 | lm loss: 5.499913E+00 | loss scale: 1.0 | grad norm: 6.724 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:27] iteration       71/     200 | consumed samples:         5112 | elapsed time per iteration (ms): 1103.2 | learning rate: 1.775000E-05 | global batch size:    72 | lm loss: 5.462347E+00 | loss scale: 1.0 | grad norm: 6.385 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 5, local rank 5, ddp group rank 0/2

global rank 4, local rank 4, ddp group rank 0/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:29] iteration       72/     200 | consumed samples:         5184 | elapsed time per iteration (ms): 1108.9 | learning rate: 1.800000E-05 | global batch size:    72 | lm loss: 5.599603E+00 | loss scale: 1.0 | grad norm: 1.692 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 5, local rank 5, ddp group rank 0/2global rank 7, local rank 7, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:30] iteration       73/     200 | consumed samples:         5256 | elapsed time per iteration (ms): 1108.1 | learning rate: 1.825000E-05 | global batch size:    72 | lm loss: 5.527011E+00 | loss scale: 1.0 | grad norm: 5.234 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
TP USE NCCLDP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:31] iteration       74/     200 | consumed samples:         5328 | elapsed time per iteration (ms): 1101.0 | learning rate: 1.850000E-05 | global batch size:    72 | lm loss: 5.403494E+00 | loss scale: 1.0 | grad norm: 4.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:32] iteration       75/     200 | consumed samples:         5400 | elapsed time per iteration (ms): 1103.8 | learning rate: 1.875000E-05 | global batch size:    72 | lm loss: 5.430689E+00 | loss scale: 1.0 | grad norm: 1.597 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 5, local rank 5, ddp group rank 0/2global rank 7, local rank 7, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:33] iteration       76/     200 | consumed samples:         5472 | elapsed time per iteration (ms): 1101.6 | learning rate: 1.900000E-05 | global batch size:    72 | lm loss: 5.246331E+00 | loss scale: 1.0 | grad norm: 3.228 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:34] iteration       77/     200 | consumed samples:         5544 | elapsed time per iteration (ms): 1104.3 | learning rate: 1.925000E-05 | global batch size:    72 | lm loss: 5.402408E+00 | loss scale: 1.0 | grad norm: 1.791 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:35] iteration       78/     200 | consumed samples:         5616 | elapsed time per iteration (ms): 1105.6 | learning rate: 1.950000E-05 | global batch size:    72 | lm loss: 5.689306E+00 | loss scale: 1.0 | grad norm: 2.224 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:36] iteration       79/     200 | consumed samples:         5688 | elapsed time per iteration (ms): 1099.4 | learning rate: 1.975000E-05 | global batch size:    72 | lm loss: 5.270377E+00 | loss scale: 1.0 | grad norm: 1.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 3, local rank 3, ddp group rank 1/2

global rank 1, local rank 1, ddp group rank 0/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:37] iteration       80/     200 | consumed samples:         5760 | elapsed time per iteration (ms): 1102.2 | learning rate: 2.000000E-05 | global batch size:    72 | lm loss: 5.645644E+00 | loss scale: 1.0 | grad norm: 2.240 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2


TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:38] iteration       81/     200 | consumed samples:         5832 | elapsed time per iteration (ms): 1104.9 | learning rate: 2.025000E-05 | global batch size:    72 | lm loss: 5.330190E+00 | loss scale: 1.0 | grad norm: 2.186 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 1, local rank 1, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:40] iteration       82/     200 | consumed samples:         5904 | elapsed time per iteration (ms): 1105.2 | learning rate: 2.050000E-05 | global batch size:    72 | lm loss: 5.356420E+00 | loss scale: 1.0 | grad norm: 2.151 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:41] iteration       83/     200 | consumed samples:         5976 | elapsed time per iteration (ms): 1101.2 | learning rate: 2.075000E-05 | global batch size:    72 | lm loss: 5.236629E+00 | loss scale: 1.0 | grad norm: 1.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2


global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:42] iteration       84/     200 | consumed samples:         6048 | elapsed time per iteration (ms): 1101.8 | learning rate: 2.100000E-05 | global batch size:    72 | lm loss: 5.230271E+00 | loss scale: 1.0 | grad norm: 2.596 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:43] iteration       85/     200 | consumed samples:         6120 | elapsed time per iteration (ms): 1103.8 | learning rate: 2.125000E-05 | global batch size:    72 | lm loss: 5.276147E+00 | loss scale: 1.0 | grad norm: 1.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:44] iteration       86/     200 | consumed samples:         6192 | elapsed time per iteration (ms): 1105.0 | learning rate: 2.150000E-05 | global batch size:    72 | lm loss: 5.459686E+00 | loss scale: 1.0 | grad norm: 2.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCLTP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:45] iteration       87/     200 | consumed samples:         6264 | elapsed time per iteration (ms): 1101.6 | learning rate: 2.175000E-05 | global batch size:    72 | lm loss: 5.277607E+00 | loss scale: 1.0 | grad norm: 1.726 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:46] iteration       88/     200 | consumed samples:         6336 | elapsed time per iteration (ms): 1104.1 | learning rate: 2.200000E-05 | global batch size:    72 | lm loss: 5.598561E+00 | loss scale: 1.0 | grad norm: 2.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:47] iteration       89/     200 | consumed samples:         6408 | elapsed time per iteration (ms): 1102.2 | learning rate: 2.225000E-05 | global batch size:    72 | lm loss: 5.351219E+00 | loss scale: 1.0 | grad norm: 1.889 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 2, local rank 2, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:48] iteration       90/     200 | consumed samples:         6480 | elapsed time per iteration (ms): 1102.4 | learning rate: 2.250000E-05 | global batch size:    72 | lm loss: 5.478277E+00 | loss scale: 1.0 | grad norm: 1.728 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 3, local rank 3, ddp group rank 1/2

global rank 1, local rank 1, ddp group rank 0/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:49] iteration       91/     200 | consumed samples:         6552 | elapsed time per iteration (ms): 1106.7 | learning rate: 2.275000E-05 | global batch size:    72 | lm loss: 5.346704E+00 | loss scale: 1.0 | grad norm: 2.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2


global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 5, local rank 5, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:51] iteration       92/     200 | consumed samples:         6624 | elapsed time per iteration (ms): 1105.3 | learning rate: 2.300000E-05 | global batch size:    72 | lm loss: 5.120162E+00 | loss scale: 1.0 | grad norm: 1.919 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 1, local rank 1, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:52] iteration       93/     200 | consumed samples:         6696 | elapsed time per iteration (ms): 1104.3 | learning rate: 2.325000E-05 | global batch size:    72 | lm loss: 5.155523E+00 | loss scale: 1.0 | grad norm: 2.327 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 2, local rank 2, ddp group rank 1/2TP USE NCCL


global rank 3, local rank 3, ddp group rank 1/2DP USE NCCLglobal rank 1, local rank 1, ddp group rank 0/2


DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:53] iteration       94/     200 | consumed samples:         6768 | elapsed time per iteration (ms): 1106.4 | learning rate: 2.350000E-05 | global batch size:    72 | lm loss: 5.069351E+00 | loss scale: 1.0 | grad norm: 1.736 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:54] iteration       95/     200 | consumed samples:         6840 | elapsed time per iteration (ms): 1103.1 | learning rate: 2.375000E-05 | global batch size:    72 | lm loss: 4.996991E+00 | loss scale: 1.0 | grad norm: 2.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:55] iteration       96/     200 | consumed samples:         6912 | elapsed time per iteration (ms): 1104.1 | learning rate: 2.400000E-05 | global batch size:    72 | lm loss: 4.957432E+00 | loss scale: 1.0 | grad norm: 1.692 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:56] iteration       97/     200 | consumed samples:         6984 | elapsed time per iteration (ms): 1105.1 | learning rate: 2.425000E-05 | global batch size:    72 | lm loss: 5.354021E+00 | loss scale: 1.0 | grad norm: 2.114 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 5, local rank 5, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:57] iteration       98/     200 | consumed samples:         7056 | elapsed time per iteration (ms): 1104.4 | learning rate: 2.450000E-05 | global batch size:    72 | lm loss: 5.328141E+00 | loss scale: 1.0 | grad norm: 1.818 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2global rank 1, local rank 1, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:05:58] iteration       99/     200 | consumed samples:         7128 | elapsed time per iteration (ms): 1101.8 | learning rate: 2.475000E-05 | global batch size:    72 | lm loss: 5.087218E+00 | loss scale: 1.0 | grad norm: 1.695 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2


global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 0, local rank 0, ddp group rank 0/2

global rank 2, local rank 2, ddp group rank 1/2DP USE NCCL

DP USE NCCL
 [2024-10-02 15:05:59] iteration      100/     200 | consumed samples:         7200 | elapsed time per iteration (ms): 1103.1 | learning rate: 2.500000E-05 | global batch size:    72 | lm loss: 5.188906E+00 | loss scale: 1.0 | grad norm: 1.677 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2


global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2TP USE NCCL

DP USE NCCLglobal rank 3, local rank 3, ddp group rank 1/2

DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:01] iteration      101/     200 | consumed samples:         7272 | elapsed time per iteration (ms): 1104.7 | learning rate: 2.525000E-05 | global batch size:    72 | lm loss: 5.037149E+00 | loss scale: 1.0 | grad norm: 1.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2


global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:02] iteration      102/     200 | consumed samples:         7344 | elapsed time per iteration (ms): 1102.2 | learning rate: 2.550000E-05 | global batch size:    72 | lm loss: 5.293651E+00 | loss scale: 1.0 | grad norm: 1.578 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:03] iteration      103/     200 | consumed samples:         7416 | elapsed time per iteration (ms): 1105.7 | learning rate: 2.575000E-05 | global batch size:    72 | lm loss: 4.898143E+00 | loss scale: 1.0 | grad norm: 1.691 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 5, local rank 5, ddp group rank 0/2global rank 7, local rank 7, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:04] iteration      104/     200 | consumed samples:         7488 | elapsed time per iteration (ms): 1103.8 | learning rate: 2.600000E-05 | global batch size:    72 | lm loss: 4.856731E+00 | loss scale: 1.0 | grad norm: 1.763 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2


global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:05] iteration      105/     200 | consumed samples:         7560 | elapsed time per iteration (ms): 1101.4 | learning rate: 2.625000E-05 | global batch size:    72 | lm loss: 4.814528E+00 | loss scale: 1.0 | grad norm: 1.800 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
TP USE NCCLDP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 2, local rank 2, ddp group rank 1/2

global rank 1, local rank 1, ddp group rank 0/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:06] iteration      106/     200 | consumed samples:         7632 | elapsed time per iteration (ms): 1103.0 | learning rate: 2.650000E-05 | global batch size:    72 | lm loss: 4.965734E+00 | loss scale: 1.0 | grad norm: 1.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:07] iteration      107/     200 | consumed samples:         7704 | elapsed time per iteration (ms): 1105.0 | learning rate: 2.675000E-05 | global batch size:    72 | lm loss: 4.998988E+00 | loss scale: 1.0 | grad norm: 1.986 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCLTP USE NCCL

global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:08] iteration      108/     200 | consumed samples:         7776 | elapsed time per iteration (ms): 1104.0 | learning rate: 2.700000E-05 | global batch size:    72 | lm loss: 5.071041E+00 | loss scale: 1.0 | grad norm: 1.659 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:09] iteration      109/     200 | consumed samples:         7848 | elapsed time per iteration (ms): 1103.3 | learning rate: 2.725000E-05 | global batch size:    72 | lm loss: 5.220529E+00 | loss scale: 1.0 | grad norm: 1.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:10] iteration      110/     200 | consumed samples:         7920 | elapsed time per iteration (ms): 1106.3 | learning rate: 2.750000E-05 | global batch size:    72 | lm loss: 5.150922E+00 | loss scale: 1.0 | grad norm: 1.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:12] iteration      111/     200 | consumed samples:         7992 | elapsed time per iteration (ms): 1102.7 | learning rate: 2.775000E-05 | global batch size:    72 | lm loss: 4.987018E+00 | loss scale: 1.0 | grad norm: 1.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2


global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:13] iteration      112/     200 | consumed samples:         8064 | elapsed time per iteration (ms): 1107.9 | learning rate: 2.800000E-05 | global batch size:    72 | lm loss: 4.931995E+00 | loss scale: 1.0 | grad norm: 2.329 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:14] iteration      113/     200 | consumed samples:         8136 | elapsed time per iteration (ms): 1101.8 | learning rate: 2.825000E-05 | global batch size:    72 | lm loss: 4.754607E+00 | loss scale: 1.0 | grad norm: 2.148 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:15] iteration      114/     200 | consumed samples:         8208 | elapsed time per iteration (ms): 1103.4 | learning rate: 2.850000E-05 | global batch size:    72 | lm loss: 4.928166E+00 | loss scale: 1.0 | grad norm: 2.223 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 2, local rank 2, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:16] iteration      115/     200 | consumed samples:         8280 | elapsed time per iteration (ms): 1102.0 | learning rate: 2.875000E-05 | global batch size:    72 | lm loss: 4.933816E+00 | loss scale: 1.0 | grad norm: 2.052 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:17] iteration      116/     200 | consumed samples:         8352 | elapsed time per iteration (ms): 1101.8 | learning rate: 2.900000E-05 | global batch size:    72 | lm loss: 4.816642E+00 | loss scale: 1.0 | grad norm: 1.814 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:18] iteration      117/     200 | consumed samples:         8424 | elapsed time per iteration (ms): 1101.0 | learning rate: 2.925000E-05 | global batch size:    72 | lm loss: 4.994825E+00 | loss scale: 1.0 | grad norm: 1.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:19] iteration      118/     200 | consumed samples:         8496 | elapsed time per iteration (ms): 1100.3 | learning rate: 2.950000E-05 | global batch size:    72 | lm loss: 4.846049E+00 | loss scale: 1.0 | grad norm: 1.588 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:20] iteration      119/     200 | consumed samples:         8568 | elapsed time per iteration (ms): 1100.4 | learning rate: 2.975000E-05 | global batch size:    72 | lm loss: 4.823818E+00 | loss scale: 1.0 | grad norm: 1.715 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:21] iteration      120/     200 | consumed samples:         8640 | elapsed time per iteration (ms): 1103.3 | learning rate: 3.000000E-05 | global batch size:    72 | lm loss: 4.862490E+00 | loss scale: 1.0 | grad norm: 1.835 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 4, local rank 4, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
TP USE NCCLDP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:23] iteration      121/     200 | consumed samples:         8712 | elapsed time per iteration (ms): 1104.1 | learning rate: 3.025000E-05 | global batch size:    72 | lm loss: 4.763276E+00 | loss scale: 1.0 | grad norm: 1.829 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 5, local rank 5, ddp group rank 0/2

global rank 4, local rank 4, ddp group rank 0/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:24] iteration      122/     200 | consumed samples:         8784 | elapsed time per iteration (ms): 1103.4 | learning rate: 3.050000E-05 | global batch size:    72 | lm loss: 4.549246E+00 | loss scale: 1.0 | grad norm: 1.634 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:25] iteration      123/     200 | consumed samples:         8856 | elapsed time per iteration (ms): 1105.0 | learning rate: 3.075000E-05 | global batch size:    72 | lm loss: 4.562367E+00 | loss scale: 1.0 | grad norm: 1.715 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:26] iteration      124/     200 | consumed samples:         8928 | elapsed time per iteration (ms): 1102.0 | learning rate: 3.100000E-05 | global batch size:    72 | lm loss: 4.468884E+00 | loss scale: 1.0 | grad norm: 1.386 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:27] iteration      125/     200 | consumed samples:         9000 | elapsed time per iteration (ms): 1103.0 | learning rate: 3.125000E-05 | global batch size:    72 | lm loss: 4.815997E+00 | loss scale: 1.0 | grad norm: 1.602 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 4, local rank 4, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCLTP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2global rank 1, local rank 1, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:28] iteration      126/     200 | consumed samples:         9072 | elapsed time per iteration (ms): 1107.1 | learning rate: 3.150000E-05 | global batch size:    72 | lm loss: 4.765180E+00 | loss scale: 1.0 | grad norm: 1.716 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 2, local rank 2, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:29] iteration      127/     200 | consumed samples:         9144 | elapsed time per iteration (ms): 1105.0 | learning rate: 3.175000E-05 | global batch size:    72 | lm loss: 4.547143E+00 | loss scale: 1.0 | grad norm: 1.360 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:06:30] iteration      128/     200 | consumed samples:         9216 | elapsed time per iteration (ms): 1106.2 | learning rate: 3.200000E-05 | global batch size:    72 | lm loss: 4.874841E+00 | loss scale: 1.0 | grad norm: 2.101 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:31] iteration      129/     200 | consumed samples:         9288 | elapsed time per iteration (ms): 1102.6 | learning rate: 3.225000E-05 | global batch size:    72 | lm loss: 4.632052E+00 | loss scale: 1.0 | grad norm: 1.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2global rank 2, local rank 2, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:33] iteration      130/     200 | consumed samples:         9360 | elapsed time per iteration (ms): 1104.1 | learning rate: 3.250000E-05 | global batch size:    72 | lm loss: 4.519464E+00 | loss scale: 1.0 | grad norm: 1.618 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:34] iteration      131/     200 | consumed samples:         9432 | elapsed time per iteration (ms): 1104.4 | learning rate: 3.275000E-05 | global batch size:    72 | lm loss: 4.672279E+00 | loss scale: 1.0 | grad norm: 1.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:35] iteration      132/     200 | consumed samples:         9504 | elapsed time per iteration (ms): 1105.2 | learning rate: 3.300000E-05 | global batch size:    72 | lm loss: 4.602935E+00 | loss scale: 1.0 | grad norm: 1.281 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:36] iteration      133/     200 | consumed samples:         9576 | elapsed time per iteration (ms): 1101.8 | learning rate: 3.325000E-05 | global batch size:    72 | lm loss: 4.407891E+00 | loss scale: 1.0 | grad norm: 1.165 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:37] iteration      134/     200 | consumed samples:         9648 | elapsed time per iteration (ms): 1104.7 | learning rate: 3.350000E-05 | global batch size:    72 | lm loss: 4.605408E+00 | loss scale: 1.0 | grad norm: 1.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 5, local rank 5, ddp group rank 0/2global rank 7, local rank 7, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:38] iteration      135/     200 | consumed samples:         9720 | elapsed time per iteration (ms): 1105.0 | learning rate: 3.375000E-05 | global batch size:    72 | lm loss: 4.367666E+00 | loss scale: 1.0 | grad norm: 1.196 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 4, local rank 4, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:39] iteration      136/     200 | consumed samples:         9792 | elapsed time per iteration (ms): 1103.1 | learning rate: 3.400000E-05 | global batch size:    72 | lm loss: 4.691450E+00 | loss scale: 1.0 | grad norm: 1.562 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:40] iteration      137/     200 | consumed samples:         9864 | elapsed time per iteration (ms): 1103.5 | learning rate: 3.425000E-05 | global batch size:    72 | lm loss: 4.451070E+00 | loss scale: 1.0 | grad norm: 2.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 5, local rank 5, ddp group rank 0/2global rank 4, local rank 4, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
TP USE NCCLglobal rank 2, local rank 2, ddp group rank 1/2

global rank 3, local rank 3, ddp group rank 1/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:41] iteration      138/     200 | consumed samples:         9936 | elapsed time per iteration (ms): 1104.2 | learning rate: 3.450000E-05 | global batch size:    72 | lm loss: 4.442699E+00 | loss scale: 1.0 | grad norm: 1.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:42] iteration      139/     200 | consumed samples:        10008 | elapsed time per iteration (ms): 1104.5 | learning rate: 3.475000E-05 | global batch size:    72 | lm loss: 4.553433E+00 | loss scale: 1.0 | grad norm: 1.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:44] iteration      140/     200 | consumed samples:        10080 | elapsed time per iteration (ms): 1104.5 | learning rate: 3.500000E-05 | global batch size:    72 | lm loss: 4.671319E+00 | loss scale: 1.0 | grad norm: 1.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:45] iteration      141/     200 | consumed samples:        10152 | elapsed time per iteration (ms): 1103.9 | learning rate: 3.525000E-05 | global batch size:    72 | lm loss: 4.543223E+00 | loss scale: 1.0 | grad norm: 1.891 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:46] iteration      142/     200 | consumed samples:        10224 | elapsed time per iteration (ms): 1103.5 | learning rate: 3.550000E-05 | global batch size:    72 | lm loss: 4.385708E+00 | loss scale: 1.0 | grad norm: 1.744 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:47] iteration      143/     200 | consumed samples:        10296 | elapsed time per iteration (ms): 1100.1 | learning rate: 3.575000E-05 | global batch size:    72 | lm loss: 4.447261E+00 | loss scale: 1.0 | grad norm: 1.998 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 1, local rank 1, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:48] iteration      144/     200 | consumed samples:        10368 | elapsed time per iteration (ms): 1102.0 | learning rate: 3.600000E-05 | global batch size:    72 | lm loss: 4.387099E+00 | loss scale: 1.0 | grad norm: 1.293 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:49] iteration      145/     200 | consumed samples:        10440 | elapsed time per iteration (ms): 1101.8 | learning rate: 3.625000E-05 | global batch size:    72 | lm loss: 4.333090E+00 | loss scale: 1.0 | grad norm: 2.148 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:50] iteration      146/     200 | consumed samples:        10512 | elapsed time per iteration (ms): 1102.7 | learning rate: 3.650000E-05 | global batch size:    72 | lm loss: 4.558823E+00 | loss scale: 1.0 | grad norm: 1.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
TP USE NCCLDP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:51] iteration      147/     200 | consumed samples:        10584 | elapsed time per iteration (ms): 1103.2 | learning rate: 3.675000E-05 | global batch size:    72 | lm loss: 4.346234E+00 | loss scale: 1.0 | grad norm: 1.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 5, local rank 5, ddp group rank 0/2

global rank 7, local rank 7, ddp group rank 1/2DP USE NCCLTP USE NCCL


DP USE NCCLglobal rank 4, local rank 4, ddp group rank 0/2

DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2TP USE NCCL

DP USE NCCLglobal rank 3, local rank 3, ddp group rank 1/2

DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:52] iteration      148/     200 | consumed samples:        10656 | elapsed time per iteration (ms): 1105.1 | learning rate: 3.700000E-05 | global batch size:    72 | lm loss: 4.310524E+00 | loss scale: 1.0 | grad norm: 1.113 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2global rank 1, local rank 1, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:53] iteration      149/     200 | consumed samples:        10728 | elapsed time per iteration (ms): 1104.0 | learning rate: 3.725000E-05 | global batch size:    72 | lm loss: 4.418185E+00 | loss scale: 1.0 | grad norm: 2.721 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:55] iteration      150/     200 | consumed samples:        10800 | elapsed time per iteration (ms): 1103.6 | learning rate: 3.750000E-05 | global batch size:    72 | lm loss: 4.311666E+00 | loss scale: 1.0 | grad norm: 1.954 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:56] iteration      151/     200 | consumed samples:        10872 | elapsed time per iteration (ms): 1103.8 | learning rate: 3.775000E-05 | global batch size:    72 | lm loss: 4.117513E+00 | loss scale: 1.0 | grad norm: 1.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:57] iteration      152/     200 | consumed samples:        10944 | elapsed time per iteration (ms): 1103.3 | learning rate: 3.800000E-05 | global batch size:    72 | lm loss: 4.162783E+00 | loss scale: 1.0 | grad norm: 1.770 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 2, local rank 2, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:58] iteration      153/     200 | consumed samples:        11016 | elapsed time per iteration (ms): 1103.5 | learning rate: 3.825000E-05 | global batch size:    72 | lm loss: 4.477809E+00 | loss scale: 1.0 | grad norm: 1.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2


global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 5, local rank 5, ddp group rank 0/2global rank 7, local rank 7, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:06:59] iteration      154/     200 | consumed samples:        11088 | elapsed time per iteration (ms): 1103.8 | learning rate: 3.850000E-05 | global batch size:    72 | lm loss: 4.532130E+00 | loss scale: 1.0 | grad norm: 1.316 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:00] iteration      155/     200 | consumed samples:        11160 | elapsed time per iteration (ms): 1104.3 | learning rate: 3.875000E-05 | global batch size:    72 | lm loss: 4.344849E+00 | loss scale: 1.0 | grad norm: 1.191 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2


global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 5, local rank 5, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:01] iteration      156/     200 | consumed samples:        11232 | elapsed time per iteration (ms): 1100.8 | learning rate: 3.900000E-05 | global batch size:    72 | lm loss: 4.382971E+00 | loss scale: 1.0 | grad norm: 1.807 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 7, local rank 7, ddp group rank 1/2

global rank 4, local rank 4, ddp group rank 0/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:02] iteration      157/     200 | consumed samples:        11304 | elapsed time per iteration (ms): 1100.4 | learning rate: 3.925000E-05 | global batch size:    72 | lm loss: 4.278554E+00 | loss scale: 1.0 | grad norm: 1.332 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 5, local rank 5, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:03] iteration      158/     200 | consumed samples:        11376 | elapsed time per iteration (ms): 1103.8 | learning rate: 3.950000E-05 | global batch size:    72 | lm loss: 4.306674E+00 | loss scale: 1.0 | grad norm: 1.450 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:05] iteration      159/     200 | consumed samples:        11448 | elapsed time per iteration (ms): 1103.8 | learning rate: 3.975000E-05 | global batch size:    72 | lm loss: 4.106630E+00 | loss scale: 1.0 | grad norm: 1.163 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 5, local rank 5, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
global rank 1, local rank 1, ddp group rank 0/2
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
DP USE NCCL
DP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:06] iteration      160/     200 | consumed samples:        11520 | elapsed time per iteration (ms): 1101.6 | learning rate: 4.000000E-05 | global batch size:    72 | lm loss: 4.215193E+00 | loss scale: 1.0 | grad norm: 1.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
TP USE NCCLDP USE NCCL

global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 4, local rank 4, ddp group rank 0/2

global rank 7, local rank 7, ddp group rank 1/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:07] iteration      161/     200 | consumed samples:        11592 | elapsed time per iteration (ms): 1103.3 | learning rate: 4.025000E-05 | global batch size:    72 | lm loss: 4.170051E+00 | loss scale: 1.0 | grad norm: 1.733 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:08] iteration      162/     200 | consumed samples:        11664 | elapsed time per iteration (ms): 1104.3 | learning rate: 4.050000E-05 | global batch size:    72 | lm loss: 3.986936E+00 | loss scale: 1.0 | grad norm: 1.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:09] iteration      163/     200 | consumed samples:        11736 | elapsed time per iteration (ms): 1105.7 | learning rate: 4.075000E-05 | global batch size:    72 | lm loss: 4.041672E+00 | loss scale: 1.0 | grad norm: 2.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 7, local rank 7, ddp group rank 1/2

global rank 5, local rank 5, ddp group rank 0/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 1, local rank 1, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:10] iteration      164/     200 | consumed samples:        11808 | elapsed time per iteration (ms): 1104.6 | learning rate: 4.100000E-05 | global batch size:    72 | lm loss: 4.375815E+00 | loss scale: 1.0 | grad norm: 1.696 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2


global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 5, local rank 5, ddp group rank 0/2global rank 7, local rank 7, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:11] iteration      165/     200 | consumed samples:        11880 | elapsed time per iteration (ms): 1101.8 | learning rate: 4.125000E-05 | global batch size:    72 | lm loss: 4.441473E+00 | loss scale: 1.0 | grad norm: 1.898 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:12] iteration      166/     200 | consumed samples:        11952 | elapsed time per iteration (ms): 1108.2 | learning rate: 4.150000E-05 | global batch size:    72 | lm loss: 4.200747E+00 | loss scale: 1.0 | grad norm: 1.728 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:13] iteration      167/     200 | consumed samples:        12024 | elapsed time per iteration (ms): 1104.0 | learning rate: 4.175000E-05 | global batch size:    72 | lm loss: 4.263517E+00 | loss scale: 1.0 | grad norm: 1.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 4, local rank 4, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:14] iteration      168/     200 | consumed samples:        12096 | elapsed time per iteration (ms): 1104.9 | learning rate: 4.200000E-05 | global batch size:    72 | lm loss: 4.197561E+00 | loss scale: 1.0 | grad norm: 1.841 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2


global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2


global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:16] iteration      169/     200 | consumed samples:        12168 | elapsed time per iteration (ms): 1102.7 | learning rate: 4.225000E-05 | global batch size:    72 | lm loss: 4.193800E+00 | loss scale: 1.0 | grad norm: 1.446 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:17] iteration      170/     200 | consumed samples:        12240 | elapsed time per iteration (ms): 1104.5 | learning rate: 4.250000E-05 | global batch size:    72 | lm loss: 4.338878E+00 | loss scale: 1.0 | grad norm: 1.589 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2TP USE NCCL

DP USE NCCLglobal rank 2, local rank 2, ddp group rank 1/2

DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:18] iteration      171/     200 | consumed samples:        12312 | elapsed time per iteration (ms): 1177.4 | learning rate: 4.275000E-05 | global batch size:    72 | lm loss: 3.960656E+00 | loss scale: 1.0 | grad norm: 1.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:19] iteration      172/     200 | consumed samples:        12384 | elapsed time per iteration (ms): 1103.6 | learning rate: 4.300000E-05 | global batch size:    72 | lm loss: 4.164945E+00 | loss scale: 1.0 | grad norm: 1.348 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:20] iteration      173/     200 | consumed samples:        12456 | elapsed time per iteration (ms): 1102.8 | learning rate: 4.325000E-05 | global batch size:    72 | lm loss: 4.225999E+00 | loss scale: 1.0 | grad norm: 1.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 2, local rank 2, ddp group rank 1/2global rank 0, local rank 0, ddp group rank 0/2

DP USE NCCLDP USE NCCL

 [2024-10-02 15:07:21] iteration      174/     200 | consumed samples:        12528 | elapsed time per iteration (ms): 1105.1 | learning rate: 4.350000E-05 | global batch size:    72 | lm loss: 4.123433E+00 | loss scale: 1.0 | grad norm: 1.301 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2


global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:22] iteration      175/     200 | consumed samples:        12600 | elapsed time per iteration (ms): 1101.3 | learning rate: 4.375000E-05 | global batch size:    72 | lm loss: 4.101777E+00 | loss scale: 1.0 | grad norm: 1.098 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2


global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:07:23] iteration      176/     200 | consumed samples:        12672 | elapsed time per iteration (ms): 1100.6 | learning rate: 4.400000E-05 | global batch size:    72 | lm loss: 3.980322E+00 | loss scale: 1.0 | grad norm: 1.332 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
global rank 2, local rank 2, ddp group rank 1/2
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
DP USE NCCL
DP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:24] iteration      177/     200 | consumed samples:        12744 | elapsed time per iteration (ms): 1105.5 | learning rate: 4.425000E-05 | global batch size:    72 | lm loss: 4.093828E+00 | loss scale: 1.0 | grad norm: 1.268 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:26] iteration      178/     200 | consumed samples:        12816 | elapsed time per iteration (ms): 1102.2 | learning rate: 4.450000E-05 | global batch size:    72 | lm loss: 4.032526E+00 | loss scale: 1.0 | grad norm: 1.458 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:27] iteration      179/     200 | consumed samples:        12888 | elapsed time per iteration (ms): 1103.3 | learning rate: 4.475000E-05 | global batch size:    72 | lm loss: 4.003448E+00 | loss scale: 1.0 | grad norm: 1.254 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:28] iteration      180/     200 | consumed samples:        12960 | elapsed time per iteration (ms): 1104.0 | learning rate: 4.500000E-05 | global batch size:    72 | lm loss: 4.184669E+00 | loss scale: 1.0 | grad norm: 1.274 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCLTP USE NCCL

global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:29] iteration      181/     200 | consumed samples:        13032 | elapsed time per iteration (ms): 1102.1 | learning rate: 4.525000E-05 | global batch size:    72 | lm loss: 3.913305E+00 | loss scale: 1.0 | grad norm: 1.212 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2


global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:30] iteration      182/     200 | consumed samples:        13104 | elapsed time per iteration (ms): 1104.2 | learning rate: 4.550000E-05 | global batch size:    72 | lm loss: 4.191617E+00 | loss scale: 1.0 | grad norm: 1.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:31] iteration      183/     200 | consumed samples:        13176 | elapsed time per iteration (ms): 1102.2 | learning rate: 4.575000E-05 | global batch size:    72 | lm loss: 3.981998E+00 | loss scale: 1.0 | grad norm: 1.273 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
TP USE NCCLglobal rank 5, local rank 5, ddp group rank 0/2

global rank 7, local rank 7, ddp group rank 1/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:32] iteration      184/     200 | consumed samples:        13248 | elapsed time per iteration (ms): 1103.7 | learning rate: 4.600000E-05 | global batch size:    72 | lm loss: 4.027468E+00 | loss scale: 1.0 | grad norm: 1.057 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:33] iteration      185/     200 | consumed samples:        13320 | elapsed time per iteration (ms): 1102.2 | learning rate: 4.625000E-05 | global batch size:    72 | lm loss: 4.106845E+00 | loss scale: 1.0 | grad norm: 2.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:34] iteration      186/     200 | consumed samples:        13392 | elapsed time per iteration (ms): 1104.2 | learning rate: 4.650000E-05 | global batch size:    72 | lm loss: 4.001265E+00 | loss scale: 1.0 | grad norm: 1.660 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2global rank 4, local rank 4, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:07:36] iteration      187/     200 | consumed samples:        13464 | elapsed time per iteration (ms): 1102.6 | learning rate: 4.675000E-05 | global batch size:    72 | lm loss: 3.997607E+00 | loss scale: 1.0 | grad norm: 1.156 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2


global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:37] iteration      188/     200 | consumed samples:        13536 | elapsed time per iteration (ms): 1101.2 | learning rate: 4.700000E-05 | global batch size:    72 | lm loss: 3.873571E+00 | loss scale: 1.0 | grad norm: 1.810 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 4, local rank 4, ddp group rank 0/2global rank 6, local rank 6, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
 [2024-10-02 15:07:38] iteration      189/     200 | consumed samples:        13608 | elapsed time per iteration (ms): 1100.7 | learning rate: 4.725000E-05 | global batch size:    72 | lm loss: 3.904840E+00 | loss scale: 1.0 | grad norm: 1.611 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 5, local rank 5, ddp group rank 0/2global rank 7, local rank 7, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 1, local rank 1, ddp group rank 0/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:39] iteration      190/     200 | consumed samples:        13680 | elapsed time per iteration (ms): 1102.5 | learning rate: 4.750000E-05 | global batch size:    72 | lm loss: 3.971541E+00 | loss scale: 1.0 | grad norm: 1.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 4, local rank 4, ddp group rank 0/2global rank 7, local rank 7, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:40] iteration      191/     200 | consumed samples:        13752 | elapsed time per iteration (ms): 1102.0 | learning rate: 4.775000E-05 | global batch size:    72 | lm loss: 3.891364E+00 | loss scale: 1.0 | grad norm: 1.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:41] iteration      192/     200 | consumed samples:        13824 | elapsed time per iteration (ms): 1104.5 | learning rate: 4.800000E-05 | global batch size:    72 | lm loss: 3.870024E+00 | loss scale: 1.0 | grad norm: 1.360 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 0, local rank 0, ddp group rank 0/2global rank 2, local rank 2, ddp group rank 1/2

DP USE NCCLDP USE NCCL

 [2024-10-02 15:07:42] iteration      193/     200 | consumed samples:        13896 | elapsed time per iteration (ms): 1103.5 | learning rate: 4.825000E-05 | global batch size:    72 | lm loss: 3.936500E+00 | loss scale: 1.0 | grad norm: 1.060 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 6, local rank 6, tp group rank 0/2

global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
TP USE NCCLDP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2TP USE NCCL

DP USE NCCLTP USE NCCLglobal rank 1, local rank 1, ddp group rank 0/2


global rank 2, local rank 2, ddp group rank 1/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:43] iteration      194/     200 | consumed samples:        13968 | elapsed time per iteration (ms): 1103.3 | learning rate: 4.850000E-05 | global batch size:    72 | lm loss: 4.025179E+00 | loss scale: 1.0 | grad norm: 1.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 7, local rank 7, ddp group rank 1/2
global rank 5, local rank 5, ddp group rank 0/2DP USE NCCL

DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:44] iteration      195/     200 | consumed samples:        14040 | elapsed time per iteration (ms): 1105.7 | learning rate: 4.875000E-05 | global batch size:    72 | lm loss: 4.015335E+00 | loss scale: 1.0 | grad norm: 1.196 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2global rank 4, local rank 4, tp group rank 0/2

global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 4, local rank 4, tp group rank 0/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 1, local rank 1, ddp group rank 0/2global rank 3, local rank 3, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:45] iteration      196/     200 | consumed samples:        14112 | elapsed time per iteration (ms): 1104.2 | learning rate: 4.900000E-05 | global batch size:    72 | lm loss: 4.033412E+00 | loss scale: 1.0 | grad norm: 1.758 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2global rank 6, local rank 6, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2

global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:47] iteration      197/     200 | consumed samples:        14184 | elapsed time per iteration (ms): 1103.5 | learning rate: 4.925000E-05 | global batch size:    72 | lm loss: 3.870164E+00 | loss scale: 1.0 | grad norm: 1.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2global rank 5, local rank 5, tp group rank 1/2

global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL

global rank 3, local rank 3, ddp group rank 1/2global rank 2, local rank 2, ddp group rank 1/2

DP USE NCCLDP USE NCCL

TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:48] iteration      198/     200 | consumed samples:        14256 | elapsed time per iteration (ms): 1104.4 | learning rate: 4.950000E-05 | global batch size:    72 | lm loss: 3.892979E+00 | loss scale: 1.0 | grad norm: 1.322 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCLTP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
global rank 1, local rank 1, ddp group rank 0/2
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
DP USE NCCL
DP USE NCCL

TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:49] iteration      199/     200 | consumed samples:        14328 | elapsed time per iteration (ms): 1105.2 | learning rate: 4.975000E-05 | global batch size:    72 | lm loss: 3.964577E+00 | loss scale: 1.0 | grad norm: 1.283 | number of skipped iterations:   0 | number of nan iterations:   0 |
global rank 4, local rank 4, tp group rank 0/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 5, local rank 5, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2

global rank 5, local rank 5, tp group rank 1/2
global rank 6, local rank 6, tp group rank 0/2
global rank 7, local rank 7, tp group rank 1/2
global rank 4, local rank 4, tp group rank 0/2
global rank 5, local rank 5, tp group rank 1/2
TP USE NCCL
global rank 6, local rank 6, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 7, local rank 7, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 5, local rank 5, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 4, local rank 4, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 3, local rank 3, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 2, local rank 2, ddp group rank 1/2
DP USE NCCL
TP USE NCCL
global rank 1, local rank 1, ddp group rank 0/2
DP USE NCCL
TP USE NCCL
global rank 0, local rank 0, ddp group rank 0/2
DP USE NCCL
 [2024-10-02 15:07:50] iteration      200/     200 | consumed samples:        14400 | elapsed time per iteration (ms): 1104.6 | learning rate: 5.000000E-05 | global batch size:    72 | lm loss: 4.036838E+00 | loss scale: 1.0 | grad norm: 1.323 | number of skipped iterations:   0 | number of nan iterations:   0 |
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_inference /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 55 
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING] due to: 
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/3k/c3k3xk6khgm26lofoqhifp3vhb3r2njvknmz2yrigsfwbgabj2ie.py", line 67, in <module>
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/1/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING] 
[rank1]:[2024-10-02 15:07:51,028] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_inference /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 55 
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING] due to: 
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/kk/ckksrvzt7pshgsy7rspg4kh343wt2rbpfx6st457uzehxjxtjbgs.py", line 67, in <module>
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/2/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING] 
[rank2]:[2024-10-02 15:07:51,039] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_inference /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 55 
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING] due to: 
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/mg/cmgkiuwbgbo5etlvv6cj4b5ckifipb6ydgq4p6ybtpjs7pukt4ct.py", line 67, in <module>
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/3/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING] 
[rank3]:[2024-10-02 15:07:51,043] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_inference /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 55 
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING] due to: 
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/ak/cakru7ev7vx7my7ojepysczosztxjqighqfqkquzmzhaafr7a3fw.py", line 67, in <module>
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/0/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING] 
[rank0]:[2024-10-02 15:07:51,051] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_inference /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 55 
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING] due to: 
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/ho/cho3lsivwf64htz6v7xorkjtkdnbhcsqn6cbywihe3a2ojan2mts.py", line 67, in <module>
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/7/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING] 
[rank7]:[2024-10-02 15:07:51,688] torch._dynamo.convert_frame: [WARNING] 
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_inference /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 55 
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING] due to: 
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/nq/cnqaoinr3p3u3nhb2rcoq4sahmqdibnl5fdycoa5el2s4zaqsbpi.py", line 67, in <module>
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/5/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING] 
[rank5]:[2024-10-02 15:07:51,708] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_inference /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 55 
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING] due to: 
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/k7/ck7ug7di6nemjwmykg3bib6hllhwaxxqmajgqmk6afc2o3xqm7o7.py", line 67, in <module>
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/4/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING] 
[rank4]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT bias_dropout_add_fused_inference /workspace/Megatron-LM/megatron/core/fusions/fused_bias_dropout.py line 55 
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING] due to: 
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 701, in _convert_frame
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 408, in _convert_frame_assert
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return _compile(
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 625, in _compile
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 542, in compile_inner
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py", line 1033, in transform_code_object
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 149, in _fn
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py", line 507, in transform
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     tracer.run()
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2192, in run
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     super().run()
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 819, in run
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     and self.step()
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 782, in step
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py", line 2307, in RETURN_VALUE
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     self.output.compile_subgraph(
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 893, in compile_subgraph
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1041, in compile_and_call_fx_graph
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     compiled_fn = self.call_user_compiler(gm)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1112, in call_user_compiler
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py", line 1093, in call_user_compiler
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(gm, self.example_inputs())
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py", line 117, in debug_wrapper
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     compiled_gm = compiler_fn(gm, example_inputs)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1616, in __call__
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return compile_fx(model_, inputs_, config_patches=self.config)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1226, in compile_fx
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return aot_autograd(
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py", line 55, in compiler_fn
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     cg = aot_module_simplified(gm, example_inputs, **kwargs)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4837, in aot_module_simplified
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     compiled_fn = create_aot_dispatcher_function(
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 4376, in create_aot_dispatcher_function
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2724, in aot_wrapper_dedupe
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, leaf_flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 2911, in aot_wrapper_synthetic_base
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return compiler_fn(flat_fn, flat_args, aot_config, fw_metadata=fw_metadata)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py", line 3743, in aot_dispatch_autograd
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     compiled_fw_func = aot_config.fw_compiler(
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 1159, in fw_compiler_base
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return inner_compile(
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     inner_compiled_fn = compiler_fn(gm, example_inputs)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py", line 303, in inner
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/contextlib.py", line 79, in inner
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return func(*args, **kwds)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 390, in compile_fx_inner
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     compiled_graph = fx_codegen_and_compile(
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py", line 615, in fx_codegen_and_compile
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     compiled_fn = graph.compile_to_fn()
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 1000, in compile_to_fn
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return self.compile_to_module().call
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 221, in time_wrapper
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py", line 955, in compile_to_module
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     mod = PyCodeCache.load_by_key_path(
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 1868, in load_by_key_path
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     exec(code, mod.__dict__, mod.__dict__)
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/tmp/torchinductor_scz1075/yb/cyb7aiupin23xi7yjeyswtologrvl75nvy4lrseh6kz7sfx2m47s.py", line 67, in <module>
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     async_compile.wait(globals())
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2445, in wait
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     scope[key] = result.result()
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py", line 2288, in result
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     self.future.result()
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 458, in result
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     return self.__get_result()
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]   File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING]     raise self._exception
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING] ImportError: /tmp/torchinductor_scz1075/triton/6/0fc9530414e9123b279980a7454bcc7a/triton_.so: undefined symbol: cuLaunchKernel
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING] 
[rank6]:[2024-10-02 15:07:51,711] torch._dynamo.convert_frame: [WARNING] 
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
/workspace/Megatron-LM/megatron/core/tensor_parallel/layers.py:684: UserWarning: async_grad_allreduce is deprecated, not in use anymore and will be fully removed with 0.10.0. Please use allreduce_dgrad instead.
  warnings.warn(
(min, max) time across ranks (ms):
    evaluate .......................................: (4709.15, 4802.69)
-----------------------------------------------------------------------------------------------
 validation loss at iteration 200 | lm loss value: 3.877626E+00 | lm loss PPL: 4.830939E+01 | 
-----------------------------------------------------------------------------------------------
[after training is done] datetime: 2024-10-02 15:07:55 
saving checkpoint at iteration     200 to /workspace/Megatron-LM/experiments/codeparrot-small in torch_dist format
  successfully saved checkpoint from iteration     200 to /workspace/Megatron-LM/experiments/codeparrot-small
Evaluating on 720 samples
Evaluating iter 1/10
Evaluating iter 2/10
Evaluating iter 3/10
Evaluating iter 4/10
Evaluating iter 5/10
Evaluating iter 6/10
Evaluating iter 7/10
Evaluating iter 8/10
Evaluating iter 9/10
Evaluating iter 10/10
(min, max) time across ranks (ms):
    evaluate .......................................: (3372.88, 3455.81)
-----------------------------------------------------------------------------------------------------------------
 validation loss at iteration 200 on validation set | lm loss value: 3.985696E+00 | lm loss PPL: 5.382273E+01 | 
-----------------------------------------------------------------------------------------------------------------
Evaluating on 720 samples
Evaluating iter 1/10
Evaluating iter 2/10
Evaluating iter 3/10
Evaluating iter 4/10
Evaluating iter 5/10
Evaluating iter 6/10
Evaluating iter 7/10
Evaluating iter 8/10
Evaluating iter 9/10
Evaluating iter 10/10
(min, max) time across ranks (ms):
    evaluate .......................................: (3363.75, 3446.75)
-----------------------------------------------------------------------------------------------------------
 validation loss at iteration 200 on test set | lm loss value: 3.994581E+00 | lm loss PPL: 5.430308E+01 | 
-----------------------------------------------------------------------------------------------------------
