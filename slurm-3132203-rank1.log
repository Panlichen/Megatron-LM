/HOME/scz1075/.conda/envs/torch221_cuda121/lib/python3.10/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2024-10-19 17:12:55,603] torch.distributed.run: [WARNING] 
[2024-10-19 17:12:55,603] torch.distributed.run: [WARNING] *****************************************
[2024-10-19 17:12:55,603] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-10-19 17:12:55,603] torch.distributed.run: [WARNING] *****************************************
WARNING: TensorBoard writing requested but is not available (are you using PyTorch 1.1.0 or later?), no TensorBoard logs will be written.
WARNING: one_logger package is required to enable e2e metrics tracking. please go to https://confluence.nvidia.com/display/MLWFO/Package+Repositories for details to install it
[rank14]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank9]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank12]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank11]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank10]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank13]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank15]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank8]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
use_te: True, HAVE_TE: True
use_te: True, HAVE_TE: True
use_te: True, HAVE_TE: Trueuse_te: True, HAVE_TE: True

use_te: True, HAVE_TE: True
use_te: True, HAVE_TE: True
use_te: True, HAVE_TE: True
use_te: True, HAVE_TE: True
/HOME/scz1075/.conda/envs/torch221_cuda121/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/HOME/scz1075/.conda/envs/torch221_cuda121/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/HOME/scz1075/.conda/envs/torch221_cuda121/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/HOME/scz1075/.conda/envs/torch221_cuda121/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/HOME/scz1075/.conda/envs/torch221_cuda121/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/HOME/scz1075/.conda/envs/torch221_cuda121/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/HOME/scz1075/.conda/envs/torch221_cuda121/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/HOME/scz1075/.conda/envs/torch221_cuda121/lib/python3.10/site-packages/transformer_engine/pytorch/attention.py:3051: UserWarning: window_size should be (-1, 0) or (>=0, 0) for attn_mask_type=causal
  warnings.warn(
/HOME/scz1075/.conda/envs/torch221_cuda121/lib/python3.10/site-packages/transformer_engine/pytorch/module/base.py:710: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/HOME/scz1075/.conda/envs/torch221_cuda121/lib/python3.10/site-packages/transformer_engine/pytorch/module/base.py:710: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/HOME/scz1075/.conda/envs/torch221_cuda121/lib/python3.10/site-packages/transformer_engine/pytorch/module/base.py:710: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/HOME/scz1075/.conda/envs/torch221_cuda121/lib/python3.10/site-packages/transformer_engine/pytorch/module/base.py:710: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/HOME/scz1075/.conda/envs/torch221_cuda121/lib/python3.10/site-packages/transformer_engine/pytorch/module/base.py:710: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/HOME/scz1075/.conda/envs/torch221_cuda121/lib/python3.10/site-packages/transformer_engine/pytorch/module/base.py:710: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/HOME/scz1075/.conda/envs/torch221_cuda121/lib/python3.10/site-packages/transformer_engine/pytorch/module/base.py:710: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
/HOME/scz1075/.conda/envs/torch221_cuda121/lib/python3.10/site-packages/transformer_engine/pytorch/module/base.py:710: UserWarning: To guarantee overlapping TP and SP collectives with the backwardGEMMs, set environment variable CUDA_DEVICE_MAX_CONNECTIONS = 1
  warnings.warn(
 > number of parameters on (tensor, pipeline) model parallel rank (0, 1): 40644864
 > number of parameters on (tensor, pipeline) model parallel rank (1, 1): 40644864
(min, max) time across ranks (ms):
    load-checkpoint ................................: (4.99, 9.42)
srun: Job step aborted: Waiting up to 62 seconds for job step to finish.
slurmstepd: error: *** STEP 3132203.0 ON g0063 CANCELLED AT 2024-10-19T17:17:20 ***
[2024-10-19 17:17:20,968] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGTERM death signal, shutting down workers
[2024-10-19 17:17:20,968] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3431 closing signal SIGTERM
[2024-10-19 17:17:20,971] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3432 closing signal SIGTERM
[2024-10-19 17:17:20,982] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3433 closing signal SIGTERM
[2024-10-19 17:17:20,990] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3434 closing signal SIGTERM
